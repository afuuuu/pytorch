{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>[-2.89027214e-01 -4.38273013e-01 -3.22299331e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0</td>\n",
       "      <td>[-7.12146819e-01 -4.24583733e-01 -1.29917473e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>1</td>\n",
       "      <td>[-2.12954760e-01 -8.21731985e-02 -2.26242959e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>1</td>\n",
       "      <td>[-5.63706942e-02 -3.41074973e-01 -1.33537129e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>0</td>\n",
       "      <td>[-4.71603841e-01 -6.57357454e-01  1.23730779e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>1</td>\n",
       "      <td>[ 1.25624493e-01 -1.17772870e-01  2.84849796e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>1</td>\n",
       "      <td>[-2.85503119e-01 -2.00217754e-01 -7.87503868e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>1</td>\n",
       "      <td>[-1.12773709e-01 -4.28319186e-01 -1.97886527e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>1</td>\n",
       "      <td>[-1.75341040e-01  8.72757733e-02 -1.16240516e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>[-1.70210615e-01 -2.48357415e-01 -4.19242419e-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1802 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0                                                  1\n",
       "25   1  [-2.89027214e-01 -4.38273013e-01 -3.22299331e-...\n",
       "89   0  [-7.12146819e-01 -4.24583733e-01 -1.29917473e-...\n",
       "597  1  [-2.12954760e-01 -8.21731985e-02 -2.26242959e-...\n",
       "153  1  [-5.63706942e-02 -3.41074973e-01 -1.33537129e-...\n",
       "711  0  [-4.71603841e-01 -6.57357454e-01  1.23730779e-...\n",
       "..  ..                                                ...\n",
       "601  1  [ 1.25624493e-01 -1.17772870e-01  2.84849796e-...\n",
       "613  1  [-2.85503119e-01 -2.00217754e-01 -7.87503868e-...\n",
       "492  1  [-1.12773709e-01 -4.28319186e-01 -1.97886527e-...\n",
       "609  1  [-1.75341040e-01  8.72757733e-02 -1.16240516e-...\n",
       "12   0  [-1.70210615e-01 -2.48357415e-01 -4.19242419e-...\n",
       "\n",
       "[1802 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1024)\n",
    "pos_data = pd.read_csv(r'sentence_embedding_list.csv', header=None)\n",
    "neg_data = pd.read_csv(r'sentence_embedding_list_negative.csv', header=None)\n",
    "com_data = pos_data.append(neg_data)\n",
    "raw_data = shuffle(com_data)\n",
    "raw_data.to_csv('suffle.csv', encoding = 'utf-8', header = None, index = False)\n",
    "labels_dataset = raw_data[0]\n",
    "labels_dataset = labels_dataset.tolist()\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv(r'suffle.csv', header=None)\n",
    "dataset = []\n",
    "for data in raw[1].tolist() :\n",
    "    num = re.findall('[0-9e.-0-9+]+',data)\n",
    "    np_num = np.array([float(i) for i in num])\n",
    "    dataset.append(np_num) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=8)\n",
    "train, test = skf.split(dataset, labels_dataset)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for train, test in skf.split(dataset, labels_dataset):\n",
    "    print('Train: %s | test: %s' % (train, test))\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32  #一個撮（批次）的大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先，我們定義索引陣列indices，它相當於對所有dataset中數據的編碼\n",
    "# 然後定義索引indices_train表示測試級的索引，indices_val來表示校驗集數據的索引，indices_test表示測試集的索引\n",
    "indices = range(len(dataset))\n",
    "data_size = len(dataset) // 10\n",
    "indices_train = indices[2 * data_size :]\n",
    "indices_val = indices[: data_size]\n",
    "indices_test = indices[data_size : 2 * data_size]\n",
    "\n",
    "# 根據這些索引，構造三個數據集的SubsetRandomSampler採樣器，它會對索引進行採樣\n",
    "sampler_train = torch.utils.data.sampler.SubsetRandomSampler(indices_train)\n",
    "sampler_val = torch.utils.data.sampler.SubsetRandomSampler(indices_val)\n",
    "sampler_test = torch.utils.data.sampler.SubsetRandomSampler(indices_test)\n",
    "\n",
    "# 根據三個採樣器來定義加載器，注意將sampler_train、sampler_val和sampler_test分別賦值給了train_loader、validation_loader和test_loader\n",
    "#注意:labels集只需用相同定義的sampler就可以採樣\n",
    "\n",
    "train_loader_train = torch.utils.data.DataLoader(dataset= dataset, \n",
    "                                           batch_size= batch_size, \n",
    "                                           sampler = sampler_train)\n",
    "train_loader_labels = torch.utils.data.DataLoader(dataset= labels_dataset, \n",
    "                                           batch_size= batch_size, \n",
    "                                           sampler = sampler_train)\n",
    "\n",
    "validation_loader_test = torch.utils.data.DataLoader(dataset = dataset,\n",
    "                                                batch_size = batch_size,\n",
    "                                                sampler = sampler_val)\n",
    "validation_loader_labels = torch.utils.data.DataLoader(dataset =labels_dataset,\n",
    "                                                batch_size = batch_size,\n",
    "                                                sampler = sampler_val)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          sampler = sampler_test)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          sampler = sampler_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1442"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sampler_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2  #標簽的種類數\n",
    "num_epochs = 100  #訓練的總循環周期\n",
    "\n",
    "size = 768\n",
    "hidden1 = 100\n",
    "hidden2 = 100\n",
    "out = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, size, hidden1, hidden2, num_classes):\n",
    "        # 該函數在創建一個NN對象的時候，即調用如下語句：model=NN()，就會被調用\n",
    "        # 首先調用父類相應的構造函數\n",
    "        super(NN, self).__init__()\n",
    "        \n",
    "        # 其次構造NN需要用到的各個神經模塊。\n",
    "        '''注意，定義組件並沒有真正搭建這些組件，只是把基本建築磚塊先找好'''\n",
    "        \n",
    "        # 全連線層\n",
    "        self.fc1 = nn.Linear(size, hidden1)\n",
    "        self.fc2 = nn.Linear(hidden1, hidden2)\n",
    "        self.fc3 = nn.Linear(hidden2, num_classes) \n",
    "        \n",
    "        #BN\n",
    "        self.bn1 = nn.BatchNorm1d(hidden1)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden2)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = F.dropout(x, training  = self.training)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(self.bn2(x))\n",
    "        x = F.dropout(x, training  = self.training)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        x = F.log_softmax(x, dim = 1)#輸出層為log_softmax，即概率對數值log(p(x))。采用log_softmax可以使得後面的交叉熵計算更快\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN(\n",
      "  (fc1): Linear(in_features=768, out_features=100, bias=True)\n",
      "  (fc2): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (fc3): Linear(in_features=100, out_features=2, bias=True)\n",
      "  (bn1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NN(size, hidden1, hidden2, num_classes)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "引數:  [Parameter containing:\n",
      "tensor([[ 0.0364,  0.0138, -0.0203,  ..., -0.0188,  0.0357,  0.0220],\n",
      "        [-0.0176,  0.0055, -0.0191,  ...,  0.0167, -0.0014,  0.0052],\n",
      "        [-0.0213,  0.0102, -0.0222,  ...,  0.0331,  0.0354, -0.0058],\n",
      "        ...,\n",
      "        [ 0.0042,  0.0344,  0.0148,  ..., -0.0129, -0.0369, -0.0166],\n",
      "        [-0.0022, -0.0056,  0.0042,  ...,  0.0232, -0.0127, -0.0052],\n",
      "        [ 0.0414,  0.0192,  0.0142,  ..., -0.0173,  0.0044, -0.0210]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0174,  0.0209, -0.0394,  0.0160,  0.0142, -0.0124,  0.0214,  0.0087,\n",
      "         0.0392, -0.0297, -0.0267, -0.0166, -0.0292, -0.0350, -0.0484,  0.0008,\n",
      "         0.0238,  0.0117,  0.0141,  0.0168,  0.0160,  0.0066, -0.0281,  0.0384,\n",
      "        -0.0416, -0.0042, -0.0056, -0.0209, -0.0304, -0.0068, -0.0330,  0.0014,\n",
      "         0.0193, -0.0052,  0.0077, -0.0200, -0.0314, -0.0010, -0.0216,  0.0175,\n",
      "        -0.0175, -0.0461,  0.0251, -0.0082, -0.0385,  0.0332, -0.0264, -0.0135,\n",
      "         0.0088, -0.0056, -0.0049,  0.0021, -0.0294, -0.0168, -0.0276,  0.0108,\n",
      "         0.0081, -0.0103,  0.0164,  0.0105, -0.0523, -0.0212,  0.0221, -0.0015,\n",
      "        -0.0228, -0.0537, -0.0130, -0.0420,  0.0114,  0.0197,  0.0055,  0.0101,\n",
      "         0.0097, -0.0091,  0.0225, -0.0159, -0.0262, -0.0135, -0.0123,  0.0130,\n",
      "        -0.0109,  0.0338, -0.0458, -0.0256, -0.0003, -0.0225,  0.0095, -0.0252,\n",
      "        -0.0432,  0.0048,  0.0131, -0.0262,  0.0262, -0.0301, -0.0072,  0.0251,\n",
      "        -0.0113, -0.0297,  0.0207,  0.0088], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0561, -0.0123,  0.0250,  ...,  0.0252,  0.0091, -0.0232],\n",
      "        [ 0.0341, -0.0415, -0.0406,  ..., -0.0180, -0.0799,  0.0134],\n",
      "        [ 0.0434,  0.0460,  0.0030,  ...,  0.0785, -0.0583, -0.0589],\n",
      "        ...,\n",
      "        [-0.0292, -0.0763,  0.0215,  ..., -0.0373, -0.0004, -0.0813],\n",
      "        [-0.0369, -0.0212, -0.0246,  ..., -0.0899,  0.0011,  0.0860],\n",
      "        [-0.0616, -0.0208,  0.0078,  ...,  0.0224,  0.0779, -0.0479]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0298, -0.0413,  0.0035, -0.0955,  0.0454,  0.0239, -0.0832, -0.0389,\n",
      "        -0.0571,  0.0122, -0.1065,  0.0311, -0.0245,  0.0365, -0.0831, -0.0520,\n",
      "         0.0766,  0.0398,  0.0501,  0.0843,  0.0855, -0.1037,  0.0214, -0.0350,\n",
      "        -0.0167, -0.0120,  0.0677,  0.0651,  0.0216,  0.0900, -0.0008, -0.0363,\n",
      "         0.0859, -0.0427,  0.0267,  0.0079, -0.0207, -0.0294, -0.0209, -0.0437,\n",
      "        -0.0548, -0.0257,  0.1005, -0.0491, -0.0398,  0.0454,  0.0841, -0.0449,\n",
      "        -0.0574, -0.1144, -0.0165,  0.0199, -0.0284,  0.0020,  0.0561, -0.0223,\n",
      "        -0.0583,  0.0696, -0.0911,  0.0755, -0.0676, -0.0949,  0.0320,  0.0447,\n",
      "         0.0289, -0.0332,  0.0343,  0.0053,  0.0185, -0.0054,  0.0269, -0.0546,\n",
      "         0.0662, -0.0704, -0.0203,  0.0109, -0.0697, -0.0242, -0.0166,  0.0330,\n",
      "         0.0258,  0.0467,  0.0054, -0.0981,  0.0356,  0.0864, -0.0892,  0.0848,\n",
      "         0.0054, -0.0497, -0.0046, -0.0548, -0.0087,  0.0281, -0.0337,  0.0637,\n",
      "        -0.0692,  0.0659, -0.0505,  0.0700], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0876, -0.0807,  0.0795, -0.0215, -0.0694, -0.0554,  0.0226,  0.0445,\n",
      "          0.0047,  0.0652, -0.0100,  0.0644, -0.0134,  0.0451, -0.0244,  0.0024,\n",
      "         -0.0394,  0.0242,  0.0155,  0.0459,  0.0370,  0.0591,  0.0249,  0.0550,\n",
      "          0.0432,  0.0188, -0.0803, -0.0021,  0.0083, -0.0656, -0.0466,  0.0620,\n",
      "         -0.0798, -0.0766,  0.0094, -0.0753, -0.0837, -0.0586,  0.0680, -0.0635,\n",
      "         -0.0016, -0.0747, -0.0016, -0.0063,  0.0493,  0.0313,  0.0066,  0.0661,\n",
      "         -0.0622, -0.0745, -0.0531,  0.0414, -0.0714, -0.0451, -0.0234, -0.0657,\n",
      "         -0.0051, -0.0372, -0.0230, -0.0253,  0.0284, -0.0846, -0.0199,  0.0201,\n",
      "         -0.0367,  0.0102,  0.0507,  0.0311,  0.0394,  0.0709, -0.0333, -0.0341,\n",
      "          0.0379, -0.0491,  0.0309, -0.0772, -0.0627,  0.0656,  0.0487, -0.0372,\n",
      "         -0.0680,  0.0394,  0.0126, -0.0033,  0.0295,  0.0103, -0.0106,  0.0690,\n",
      "         -0.0881, -0.0708,  0.0335,  0.0282,  0.0510,  0.0378, -0.0142,  0.0799,\n",
      "         -0.0680,  0.0287,  0.0129, -0.0364],\n",
      "        [ 0.0692, -0.0661, -0.0509, -0.0678, -0.0069, -0.0113,  0.0031, -0.0722,\n",
      "         -0.0545, -0.0169, -0.0054,  0.0669,  0.0180,  0.0476,  0.0504, -0.0216,\n",
      "         -0.0736, -0.0463,  0.0742, -0.0017, -0.0405, -0.0095, -0.0162,  0.0255,\n",
      "          0.0622,  0.0575, -0.0107,  0.0041,  0.0279,  0.0194, -0.0689,  0.0917,\n",
      "         -0.0873,  0.0174,  0.0510, -0.0805, -0.0034, -0.0220,  0.0891,  0.0638,\n",
      "         -0.0739, -0.0154,  0.0677,  0.0077, -0.0192,  0.0051, -0.0226,  0.0027,\n",
      "         -0.0244,  0.0029, -0.0058, -0.0200, -0.0324, -0.0112, -0.0041, -0.0497,\n",
      "          0.0397, -0.0128,  0.0199, -0.0474, -0.0250, -0.0853, -0.0372, -0.0175,\n",
      "         -0.0451, -0.0049,  0.0318, -0.0212,  0.0592,  0.0513, -0.0239, -0.0147,\n",
      "         -0.0297, -0.0687,  0.0296, -0.0817,  0.0301,  0.0886,  0.0807,  0.0548,\n",
      "          0.0452, -0.0417,  0.0104,  0.0744, -0.0436,  0.0211,  0.0538,  0.0017,\n",
      "         -0.0607, -0.0464,  0.0133, -0.0686, -0.0381,  0.0413,  0.0148,  0.0152,\n",
      "          0.0181,  0.0937,  0.0304, -0.0515]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.0025, -0.0926], requires_grad=True), Parameter containing:\n",
      "tensor([0.9887, 1.0006, 0.9877, 0.9858, 0.9866, 0.9883, 0.9991, 0.9911, 1.0005,\n",
      "        0.9881, 0.9889, 0.9966, 0.9969, 0.9964, 0.9887, 0.9931, 0.9974, 0.9995,\n",
      "        0.9887, 0.9982, 0.9858, 0.9830, 0.9928, 1.0074, 0.9862, 0.9914, 0.9915,\n",
      "        0.9954, 0.9867, 0.9909, 0.9869, 1.0005, 0.9994, 0.9847, 0.9925, 0.9826,\n",
      "        0.9868, 0.9846, 0.9924, 0.9934, 0.9948, 0.9815, 0.9895, 0.9924, 0.9880,\n",
      "        0.9894, 0.9821, 0.9854, 0.9929, 0.9833, 0.9906, 0.9838, 0.9934, 0.9950,\n",
      "        0.9803, 0.9891, 0.9867, 0.9812, 0.9915, 0.9837, 0.9850, 0.9951, 0.9887,\n",
      "        0.9869, 0.9882, 0.9825, 0.9868, 0.9826, 0.9921, 1.0076, 0.9829, 0.9905,\n",
      "        0.9909, 0.9901, 0.9936, 0.9802, 0.9933, 1.0028, 0.9979, 0.9925, 0.9888,\n",
      "        0.9995, 0.9946, 0.9859, 0.9917, 0.9866, 0.9977, 0.9855, 0.9924, 1.0009,\n",
      "        0.9870, 0.9957, 0.9904, 0.9947, 0.9938, 0.9765, 0.9926, 0.9870, 0.9870,\n",
      "        0.9863], requires_grad=True), Parameter containing:\n",
      "tensor([-1.1109e-02, -1.7210e-03, -3.0078e-03, -1.0294e-02, -9.7612e-03,\n",
      "        -5.4636e-03, -4.4779e-03, -6.7783e-03,  9.6118e-03, -1.0369e-02,\n",
      "        -8.7261e-03, -4.7196e-03,  1.5255e-03, -2.3703e-03, -1.3346e-02,\n",
      "        -1.3160e-02, -3.0605e-03,  9.3469e-03, -4.4266e-03, -8.2455e-03,\n",
      "        -9.5942e-03, -6.9943e-03, -1.8574e-03,  3.8998e-03, -4.4774e-03,\n",
      "        -9.2910e-03, -5.9018e-03, -2.8023e-03, -5.7140e-03, -4.3546e-03,\n",
      "        -1.2256e-02, -1.5316e-03,  2.5042e-04, -1.6801e-02, -5.2141e-03,\n",
      "        -1.7148e-02, -7.5506e-03, -1.6337e-02, -1.0850e-02, -2.0616e-03,\n",
      "        -1.0212e-02, -1.1023e-02, -1.5743e-03, -2.5890e-03, -1.0175e-02,\n",
      "         2.1199e-03, -1.3200e-02, -1.4089e-02, -4.5648e-03, -1.1249e-02,\n",
      "        -8.4526e-03, -7.8898e-03, -8.6252e-04, -2.7235e-03, -1.1075e-02,\n",
      "        -1.0667e-02, -1.5466e-03, -8.3381e-03, -8.4338e-03, -1.1748e-02,\n",
      "        -1.3684e-02, -3.4381e-03, -8.3560e-03, -8.2969e-03, -4.0824e-03,\n",
      "        -1.5846e-02, -6.2425e-03, -1.2324e-02, -5.7864e-03,  1.1642e-02,\n",
      "        -6.7389e-03, -1.8153e-03, -3.1204e-03, -2.2134e-03, -6.8915e-03,\n",
      "        -4.0945e-03, -1.2345e-02,  6.7521e-03,  1.8194e-04, -8.9588e-03,\n",
      "        -6.1492e-03, -2.4695e-03, -8.7721e-03, -3.7989e-03, -7.5299e-03,\n",
      "        -3.5462e-03,  8.8901e-03, -1.3897e-02, -4.4785e-03,  1.1402e-02,\n",
      "        -4.0790e-03, -1.0985e-05, -4.9591e-03, -5.6470e-04, -3.5584e-03,\n",
      "        -6.8793e-03, -2.1533e-03, -1.2138e-02, -2.7387e-03, -1.0943e-02],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([0.9942, 0.9945, 0.9821, 0.9836, 0.9980, 0.9873, 0.9931, 0.9758, 0.9808,\n",
      "        0.9852, 0.9842, 0.9825, 0.9993, 0.9855, 0.9742, 0.9937, 0.9853, 0.9711,\n",
      "        0.9777, 0.9753, 0.9836, 0.9720, 0.9913, 0.9975, 0.9947, 0.9982, 0.9919,\n",
      "        0.9956, 0.9924, 0.9865, 0.9921, 1.0002, 0.9907, 0.9909, 0.9969, 0.9859,\n",
      "        0.9848, 0.9980, 0.9974, 0.9734, 0.9877, 0.9915, 0.9950, 0.9963, 0.9744,\n",
      "        0.9941, 0.9866, 0.9832, 1.0038, 0.9803, 1.0056, 0.9768, 0.9973, 0.9845,\n",
      "        0.9930, 0.9949, 1.0011, 0.9962, 1.0023, 0.9872, 0.9832, 0.9867, 0.9970,\n",
      "        0.9880, 0.9955, 0.9841, 0.9783, 0.9889, 0.9904, 0.9971, 0.9957, 0.9933,\n",
      "        0.9926, 0.9939, 0.9877, 0.9898, 0.9863, 1.0078, 1.0040, 0.9915, 0.9730,\n",
      "        0.9749, 0.9812, 0.9912, 0.9721, 0.9858, 0.9812, 0.9848, 0.9908, 0.9960,\n",
      "        0.9893, 0.9807, 0.9713, 0.9840, 0.9989, 0.9884, 0.9706, 1.0002, 0.9938,\n",
      "        0.9918], requires_grad=True), Parameter containing:\n",
      "tensor([-1.3455e-03, -3.9450e-03, -4.4671e-03, -5.3362e-03,  4.8770e-03,\n",
      "         5.7899e-04, -3.5897e-03, -1.1100e-02, -5.6576e-03, -4.9886e-04,\n",
      "        -9.2716e-03, -1.7331e-02, -9.3489e-04, -6.2982e-03, -1.3664e-02,\n",
      "        -5.7838e-04, -6.9734e-03, -1.7957e-02, -7.0429e-03, -1.0509e-02,\n",
      "        -8.9105e-03, -2.4561e-02, -1.0681e-03, -3.7734e-03, -7.2199e-04,\n",
      "        -1.6189e-04,  1.9166e-03, -2.7028e-03, -3.1377e-03,  1.1711e-03,\n",
      "         4.5799e-03,  2.9593e-03, -5.9008e-03, -9.0456e-03, -2.1375e-03,\n",
      "        -1.0468e-02, -6.1992e-03,  5.5288e-03,  9.4750e-04, -7.4103e-03,\n",
      "        -8.1777e-03,  9.1079e-04,  3.7390e-03, -1.0750e-02, -4.8602e-03,\n",
      "        -2.1614e-03, -7.5929e-03, -3.8842e-03, -1.5587e-03, -1.7750e-02,\n",
      "         9.7433e-03, -1.4287e-02, -4.1606e-03, -5.5135e-03,  1.0533e-03,\n",
      "        -2.1973e-03,  2.2994e-04, -2.8349e-03, -5.6550e-03, -3.3398e-03,\n",
      "        -4.4565e-03, -1.4728e-02, -7.2932e-03, -6.9820e-03, -6.0245e-03,\n",
      "        -6.7101e-03, -1.1411e-02, -1.0425e-02,  7.8507e-05, -1.0283e-03,\n",
      "        -1.4082e-03, -4.4741e-03, -1.3691e-02, -3.2770e-03,  1.7152e-03,\n",
      "        -4.2741e-03, -5.2058e-03,  3.5689e-03,  2.9011e-03,  2.5667e-04,\n",
      "        -8.7330e-03, -8.0363e-03, -9.4705e-03, -3.2834e-03, -1.3959e-02,\n",
      "        -5.3433e-03, -3.9290e-03, -4.0624e-03,  8.8192e-04, -8.5633e-04,\n",
      "        -3.4650e-03, -2.9771e-03, -9.7176e-03, -1.0041e-02,  5.6099e-03,\n",
      "        -5.3565e-03, -1.5272e-02,  4.0363e-03, -1.6047e-03, -9.4012e-03],\n",
      "       requires_grad=True)]\n",
      "第一個引數大小:  torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "params = list(model.parameters())\n",
    "print('引數: ', params)\n",
    "# conv1.weight\n",
    "print('第一個引數大小: ', params[-1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN(size, hidden1, hidden2, num_classes)\n",
    "\n",
    "# 損失函數為交叉熵\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# 優化算法為Adam，可以自動調節學習率\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
    "\n",
    "\n",
    "\n",
    "def rightness(predictions, labels):\n",
    "    \"\"\"计算预测错误率的函数，其中predictions是模型给出的一组预测结果，batch_size行num_classes列的矩阵，labels是数据之中的正确答案\"\"\"\n",
    "    pred = torch.max(predictions.data, 1)[1] # 对于任意一行（一个样本）的输出值的第1个维度，求最大，得到每一行的最大元素的下标\n",
    "    rights = pred.eq(labels.data.view_as(pred)).sum() #将下标与labels中包含的类别进行比较，并累计得到比较正确的数量\n",
    "    return rights, len(labels) #返回正确的数量和这一次一共比较了多少元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0721, -0.4190],\n",
       "        [-0.4938, -0.9423]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, data in enumerate(zip(train_loader_train, train_loader_labels)):\n",
    "    x, y = data\n",
    "    z = torch.tensor(x, requires_grad = True, dtype = torch.float) \n",
    "    \n",
    "model(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3938, -0.3830, -0.0389,  ..., -0.0270,  0.3251,  0.4885],\n",
      "        [ 0.0475, -0.2420, -0.4028,  ..., -0.2092,  0.0156,  0.4131],\n",
      "        [-0.3850, -0.4682,  0.2535,  ..., -0.0760,  0.1846,  0.2591],\n",
      "        ...,\n",
      "        [-0.3633, -0.7579, -0.3822,  ...,  0.4130, -0.1240,  0.0885],\n",
      "        [-0.2959, -0.1518, -0.1805,  ..., -0.0308, -0.2556,  0.5253],\n",
      "        [ 0.0984, -0.1236,  0.0217,  ...,  0.1759, -0.0761,  0.6120]],\n",
      "       dtype=torch.float64) tensor([0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 1])\n",
      "tensor([[-0.2502, -0.3550, -0.2655,  ..., -0.4906,  0.2951,  0.1412],\n",
      "        [ 0.1325, -0.2030, -0.3874,  ...,  0.4411, -0.2838,  0.4935],\n",
      "        [-0.2836, -0.2044, -0.2565,  ..., -0.1048,  0.0946,  0.2902],\n",
      "        ...,\n",
      "        [-0.4115,  0.1867, -0.6660,  ..., -0.2391,  0.2860,  0.7592],\n",
      "        [-0.3012, -0.2645, -0.1858,  ..., -0.1388, -0.2219,  0.4377],\n",
      "        [ 0.0087, -0.5075, -0.0534,  ...,  0.1153,  0.2975, -0.1729]],\n",
      "       dtype=torch.float64) tensor([1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1,\n",
      "        1, 0, 0, 0, 1, 1, 0, 0])\n",
      "tensor([[-0.2717,  0.0251, -0.1277,  ..., -0.0890,  0.1492,  0.3421],\n",
      "        [ 0.1366,  0.0429,  0.2895,  ...,  0.2000, -0.2003,  0.5596],\n",
      "        [-0.3606, -0.0870, -0.1246,  ..., -0.2522,  0.2817,  0.1528],\n",
      "        ...,\n",
      "        [-0.3288, -0.0613, -0.1937,  ..., -0.3570,  0.1753,  0.4496],\n",
      "        [-0.2300, -0.2619, -0.1581,  ..., -0.2234,  0.3060,  0.3041],\n",
      "        [-0.2396,  0.2412, -0.5420,  ...,  0.2193,  0.0813,  0.5696]],\n",
      "       dtype=torch.float64) tensor([0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 1])\n",
      "tensor([[-0.2199,  0.0881, -0.6829,  ..., -0.2804,  0.0435,  0.6504],\n",
      "        [-0.1756,  0.0561, -0.0130,  ...,  0.2064, -0.1000,  0.3723],\n",
      "        [-0.2109, -0.1538, -0.1847,  ..., -0.0815,  0.4250,  0.4856],\n",
      "        ...,\n",
      "        [-0.0231, -0.1327, -0.6550,  ...,  0.1754,  0.1958,  0.7343],\n",
      "        [-0.2808, -0.1401,  0.0075,  ..., -0.1027, -0.1789,  0.4390],\n",
      "        [-0.2073, -0.2899, -0.1294,  ..., -0.3799, -0.2000,  0.1512]],\n",
      "       dtype=torch.float64) tensor([0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1,\n",
      "        1, 0, 1, 0, 1, 1, 1, 1])\n",
      "tensor([[-0.1450,  0.0108,  0.0176,  ..., -0.2326,  0.3626,  0.3007],\n",
      "        [-0.4700, -0.5020, -0.4510,  ...,  0.0760, -0.1765, -0.0555],\n",
      "        [-0.3794, -0.3453, -0.2258,  ..., -0.4986,  0.3000, -0.2126],\n",
      "        ...,\n",
      "        [-0.5039, -0.2559,  0.2545,  ...,  0.1465,  0.1005,  0.3828],\n",
      "        [-0.3095, -0.1505, -0.0363,  ..., -0.1347,  0.0564,  0.2657],\n",
      "        [-0.2836, -0.0495,  0.0227,  ..., -0.3089, -0.0555,  0.6782]],\n",
      "       dtype=torch.float64) tensor([1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1,\n",
      "        1, 1, 0, 0, 0, 0, 1, 0])\n",
      "tensor([[-0.3200,  0.2415,  0.4761,  ..., -0.1491, -0.0923,  0.4988],\n",
      "        [ 0.0328, -0.7069,  0.3038,  ...,  0.3062, -0.1871,  0.6253],\n",
      "        [-0.4401, -0.2437, -0.2705,  ..., -0.1478, -0.0823,  0.4135],\n",
      "        ...,\n",
      "        [-0.3765, -0.1285, -0.1937,  ..., -0.4188,  0.0346,  0.4944],\n",
      "        [-0.1014, -0.1673, -0.1960,  ..., -0.2474, -0.0421,  0.0728],\n",
      "        [-0.1075, -0.1153,  0.1314,  ..., -0.0730,  0.3002,  0.0999]],\n",
      "       dtype=torch.float64) tensor([1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0,\n",
      "        1, 1, 0, 1, 0, 1, 1, 0])\n",
      "tensor([[ 0.0940, -0.2402,  0.0366,  ...,  0.4624,  0.0034,  0.7650],\n",
      "        [-0.3819, -0.0332, -0.1120,  ...,  0.0369, -0.2324,  0.6415],\n",
      "        [-0.7371, -0.6462, -0.6975,  ..., -0.4793,  0.6979,  0.3334],\n",
      "        ...,\n",
      "        [-0.3964, -0.1871, -0.3480,  ...,  0.1251, -0.1403,  0.2663],\n",
      "        [-0.0549,  0.0645,  0.4512,  ...,  0.1061, -0.0528,  0.2767],\n",
      "        [ 0.1680, -0.3458,  0.0516,  ...,  0.1853, -0.0677,  0.1658]],\n",
      "       dtype=torch.float64) tensor([1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 1, 0, 1, 1, 1, 0])\n",
      "tensor([[ 0.0567,  0.3069, -0.7351,  ...,  0.0126,  0.0857,  0.2323],\n",
      "        [-0.6280, -0.4455, -0.2268,  ..., -0.2452,  0.0616,  0.5745],\n",
      "        [-0.2917,  0.3376,  0.1027,  ..., -0.2757, -0.0816,  0.9890],\n",
      "        ...,\n",
      "        [-0.3577, -0.4693, -0.3012,  ...,  0.4071,  0.2700,  0.6114],\n",
      "        [-0.1582,  0.0932, -0.2601,  ...,  0.1525,  0.0304,  0.4002],\n",
      "        [-0.1928, -0.1565, -0.0429,  ..., -0.1095,  0.2895,  0.4073]],\n",
      "       dtype=torch.float64) tensor([0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0,\n",
      "        1, 1, 1, 1, 1, 1, 1, 0])\n",
      "tensor([[-0.0645, -0.3441,  0.0631,  ..., -0.5066, -0.3248,  0.3757],\n",
      "        [-0.2449, -0.5169, -0.7916,  ..., -0.3044,  0.6266,  0.0613],\n",
      "        [-0.5442, -0.3378, -0.0664,  ..., -0.3103, -0.1484,  0.7054],\n",
      "        ...,\n",
      "        [-0.6222, -0.4309, -0.4529,  ..., -0.1881,  0.1972,  0.6426],\n",
      "        [-0.4018, -0.3851,  0.3211,  ...,  0.3316, -0.0402,  0.4100],\n",
      "        [-0.1154,  0.2190, -0.2435,  ...,  0.0359, -0.2482,  0.4648]],\n",
      "       dtype=torch.float64) tensor([1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n",
      "        1, 0, 0, 0, 0, 1, 1, 1])\n",
      "tensor([[-0.0208, -0.0970,  0.0289,  ..., -0.1858,  0.1685,  0.1729],\n",
      "        [ 0.0049,  0.0385, -0.0785,  ..., -0.2003,  0.0316,  0.6547],\n",
      "        [-0.2503, -0.3553, -0.4048,  ...,  0.4678, -0.4549,  0.4954],\n",
      "        ...,\n",
      "        [-0.3218, -0.7376, -0.3699,  ..., -0.0580, -0.4573,  0.7678],\n",
      "        [-0.3887, -0.3810, -0.1404,  ...,  0.0755,  0.1596,  0.6169],\n",
      "        [-0.0679, -0.1452, -0.3172,  ...,  0.0034, -0.3264,  0.4144]],\n",
      "       dtype=torch.float64) tensor([1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1,\n",
      "        1, 1, 1, 0, 1, 0, 1, 1])\n",
      "tensor([[-0.1040, -0.1160,  0.1135,  ..., -0.1030,  0.1156,  0.4710],\n",
      "        [-0.1684, -0.3057, -0.0482,  ..., -0.2616, -0.0362,  0.0215],\n",
      "        [-0.5468,  0.0351, -0.2326,  ...,  0.0218, -0.1191,  0.4427],\n",
      "        ...,\n",
      "        [-0.5814, -0.3789, -0.4519,  ...,  0.0570,  0.4840,  0.3364],\n",
      "        [-0.1419, -0.1501, -0.0405,  ...,  0.1354, -0.0767,  0.2841],\n",
      "        [ 0.0405,  0.0317,  0.2403,  ...,  0.3073, -0.3126,  0.4173]],\n",
      "       dtype=torch.float64) tensor([0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "        0, 1, 0, 1, 0, 1, 1, 1])\n",
      "tensor([[-0.4316, -0.3871, -0.1006,  ..., -0.1481, -0.1357,  0.8152],\n",
      "        [-0.3676, -0.4390, -0.5676,  ...,  0.1116,  0.4701,  0.2667],\n",
      "        [ 0.1917, -0.0508, -0.2437,  ...,  0.3777, -0.0778,  0.4142],\n",
      "        ...,\n",
      "        [-0.0309, -0.5554, -0.1395,  ...,  0.0895,  0.1701,  0.5696],\n",
      "        [-0.4128,  0.1558,  0.1565,  ..., -0.2663,  0.0076,  0.7157],\n",
      "        [ 0.1877,  0.1222,  0.1542,  ..., -0.2494,  0.0379,  0.6676]],\n",
      "       dtype=torch.float64) tensor([1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 1, 1, 0, 0, 0, 0, 0])\n",
      "tensor([[ 0.1998,  0.0095,  0.1125,  ..., -0.1811, -0.0793,  0.4009],\n",
      "        [-0.2199,  0.0881, -0.6829,  ..., -0.2804,  0.0435,  0.6504],\n",
      "        [-0.4773, -0.4657, -0.2977,  ..., -0.2446, -0.1128,  0.4333],\n",
      "        ...,\n",
      "        [-0.4796, -0.2551,  0.0777,  ..., -0.1143, -0.0463,  0.2696],\n",
      "        [-0.6453, -0.1610, -0.0106,  ..., -0.3514,  0.2765,  0.3914],\n",
      "        [-0.5190,  0.1497, -0.1221,  ..., -0.1869, -0.0038,  0.2214]],\n",
      "       dtype=torch.float64) tensor([0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
      "        1, 0, 1, 1, 1, 1, 0, 1])\n",
      "tensor([[-0.2269,  0.0874,  0.0344,  ...,  0.1311,  0.3792,  0.4834],\n",
      "        [-0.4813,  0.1183, -0.0063,  ..., -0.0296, -0.2967,  0.7994],\n",
      "        [-0.3246, -0.3759, -0.1975,  ..., -0.0636, -0.0021,  0.5189],\n",
      "        ...,\n",
      "        [-0.1051, -0.3583, -0.2703,  ...,  0.1869,  0.0349,  0.5967],\n",
      "        [-0.5088, -0.2161, -0.0411,  ..., -0.1590,  0.1260,  0.4625],\n",
      "        [-0.0697,  0.2281,  0.2187,  ..., -0.2540,  0.0547,  0.5173]],\n",
      "       dtype=torch.float64) tensor([1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
      "        0, 1, 0, 1, 1, 1, 0, 0])\n",
      "tensor([[-0.1676, -0.5541, -0.1694,  ...,  0.0425,  0.0520,  0.4820],\n",
      "        [-0.0153, -0.3126, -0.8399,  ...,  0.0145, -0.1578,  0.3082],\n",
      "        [-0.2866, -0.2421, -0.3394,  ..., -0.2312,  0.1961,  0.1667],\n",
      "        ...,\n",
      "        [-0.0832, -0.0981, -0.2942,  ...,  0.0252,  0.1778,  0.3963],\n",
      "        [-0.3681, -0.3624, -0.3073,  ..., -0.0735,  0.1551,  0.2303],\n",
      "        [-0.3921, -0.3519, -0.7561,  ..., -0.7455,  0.2178,  0.6999]],\n",
      "       dtype=torch.float64) tensor([0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
      "        0, 1, 0, 0, 1, 1, 1, 0])\n",
      "tensor([[-0.4521, -0.2005, -0.4036,  ..., -0.0838,  0.0014,  0.1141],\n",
      "        [-0.1105, -0.0329,  0.1319,  ..., -0.6199,  0.3831,  0.1271],\n",
      "        [-0.2240, -0.3119,  0.1845,  ...,  0.1159, -0.0364,  0.9041],\n",
      "        ...,\n",
      "        [-0.1312, -0.3100, -0.3725,  ..., -0.0355,  0.1358,  0.2309],\n",
      "        [-0.3164, -0.5180, -0.1762,  ..., -0.4932, -0.1044,  0.4096],\n",
      "        [-0.1538, -0.1557, -0.2916,  ..., -0.0678,  0.1356, -0.0697]],\n",
      "       dtype=torch.float64) tensor([0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1,\n",
      "        0, 0, 0, 0, 0, 1, 0, 1])\n",
      "tensor([[-0.4411, -0.5145, -0.0857,  ..., -0.1197, -0.2206,  0.3739],\n",
      "        [-0.7675, -0.3305, -0.5958,  ..., -0.5764,  0.2808,  0.3072],\n",
      "        [-0.2758,  0.0412, -0.4050,  ...,  0.2505,  0.1718,  0.2344],\n",
      "        ...,\n",
      "        [-0.2403, -0.0817, -0.0692,  ..., -0.2444,  0.4130,  0.0669],\n",
      "        [-0.7063,  0.2957, -0.1838,  ...,  0.1756,  0.1709,  0.4102],\n",
      "        [ 0.0181, -0.1643,  0.3309,  ...,  0.3933,  0.0131,  0.5277]],\n",
      "       dtype=torch.float64) tensor([1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1,\n",
      "        0, 1, 0, 0, 0, 1, 1, 1])\n",
      "tensor([[-0.1936, -0.2646,  0.0184,  ..., -0.1880,  0.0402,  0.5687],\n",
      "        [-0.6375, -0.3490, -0.3420,  ..., -0.2325,  0.1408,  0.3920],\n",
      "        [-0.1557, -0.2238,  0.0313,  ..., -0.0573, -0.2742,  0.7661],\n",
      "        ...,\n",
      "        [-0.0772, -0.2411,  1.1113,  ...,  0.8143, -0.3136,  0.3846],\n",
      "        [ 0.1086, -0.5537, -0.1813,  ..., -0.3351,  0.1293,  0.3384],\n",
      "        [-0.3505, -0.2201, -0.0383,  ...,  0.0773,  0.1621,  0.5318]],\n",
      "       dtype=torch.float64) tensor([0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
      "        1, 1, 0, 0, 0, 0, 0, 1])\n",
      "tensor([[-0.1205, -0.3005, -0.3237,  ...,  0.1670,  0.0319,  0.3982],\n",
      "        [ 0.1438, -0.1316, -0.5802,  ..., -0.4549,  0.2662,  0.5012],\n",
      "        [-0.4403, -0.1695, -0.1799,  ...,  0.1675, -0.2503,  0.8852],\n",
      "        ...,\n",
      "        [-0.1077, -0.2839,  0.1770,  ..., -0.1046,  0.0061,  0.6396],\n",
      "        [-0.2333, -0.2341, -0.2298,  ...,  0.1159,  0.3947,  0.4312],\n",
      "        [-0.0479,  0.1137,  0.1936,  ...,  0.0523,  0.1360,  0.3902]],\n",
      "       dtype=torch.float64) tensor([0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
      "        0, 0, 1, 1, 1, 0, 0, 0])\n",
      "tensor([[-0.5586,  0.1446, -0.6100,  ..., -0.2586,  0.3385,  0.0423],\n",
      "        [-0.4201, -0.5086, -0.0410,  ...,  0.0800,  0.2495,  0.3995],\n",
      "        [-0.3011, -0.1146, -0.2996,  ..., -0.2521,  0.0141,  0.0316],\n",
      "        ...,\n",
      "        [ 0.0464,  0.0672, -0.0812,  ..., -0.3763, -0.0550,  0.1215],\n",
      "        [ 0.0821, -0.8340,  0.0723,  ...,  0.2650, -0.4454,  1.0801],\n",
      "        [-0.0579, -0.2715, -0.0380,  ..., -0.3321,  0.0154,  0.1066]],\n",
      "       dtype=torch.float64) tensor([0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
      "        0, 1, 1, 0, 0, 1, 1, 0])\n",
      "tensor([[-0.4611, -0.4953, -0.3430,  ...,  0.0075,  0.1432,  0.9239],\n",
      "        [-0.3329, -0.5834, -0.4951,  ..., -0.3005,  0.1988,  0.1311],\n",
      "        [-0.1110, -0.6402,  0.1318,  ..., -0.0042, -0.0071,  0.3839],\n",
      "        ...,\n",
      "        [-0.7791, -0.7970,  0.0631,  ...,  0.2044, -0.1322,  0.7075],\n",
      "        [-0.0796, -0.1197, -0.1392,  ..., -0.0160, -0.1653,  0.7764],\n",
      "        [-0.0035, -0.3268, -0.3058,  ..., -0.3708, -0.0288,  0.2346]],\n",
      "       dtype=torch.float64) tensor([0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
      "        1, 1, 1, 1, 1, 0, 0, 1])\n",
      "tensor([[-0.4823, -0.2166, -0.0539,  ..., -0.1928, -0.2093,  0.2693],\n",
      "        [-0.3177, -0.3928, -0.2801,  ...,  0.0722,  0.3107,  0.3851],\n",
      "        [-0.2199,  0.0881, -0.6829,  ..., -0.2804,  0.0435,  0.6504],\n",
      "        ...,\n",
      "        [-0.0576,  0.3887, -0.0880,  ...,  0.2503,  0.0798,  0.4588],\n",
      "        [-0.1948, -0.5993,  0.0436,  ...,  0.3478, -0.0301,  0.4835],\n",
      "        [ 0.2746, -0.1690,  0.5713,  ...,  0.1286,  0.6878,  0.2906]],\n",
      "       dtype=torch.float64) tensor([0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
      "        0, 1, 1, 1, 1, 0, 1, 1])\n",
      "tensor([[-0.5551, -0.8224, -0.6883,  ..., -0.4670,  0.3601,  0.5612],\n",
      "        [-0.1860, -0.2533, -0.0033,  ...,  0.0652, -0.1735,  0.5283],\n",
      "        [-0.0333,  0.3114,  0.0195,  ...,  0.0127, -0.1085,  0.3254],\n",
      "        ...,\n",
      "        [-0.3319, -0.7127, -0.2911,  ..., -0.0970, -0.0194, -0.4430],\n",
      "        [-0.7303, -0.3187, -0.3226,  ..., -0.1463, -0.5680,  0.6331],\n",
      "        [-0.4695,  0.1025, -0.3263,  ..., -0.0496,  0.1728,  0.3729]],\n",
      "       dtype=torch.float64) tensor([1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0,\n",
      "        0, 1, 1, 0, 1, 0, 0, 1])\n",
      "tensor([[-0.2598,  0.1325, -0.8616,  ..., -0.5755,  0.2740,  0.2615],\n",
      "        [-0.1075, -0.2113, -0.2637,  ...,  0.0382,  0.1687,  0.2851],\n",
      "        [ 0.2357, -0.6819,  0.0313,  ...,  0.0672, -0.1873,  0.4315],\n",
      "        ...,\n",
      "        [-0.4903, -0.5802, -0.3040,  ..., -0.0931,  0.2786,  0.3060],\n",
      "        [-0.3520, -0.5365,  0.0940,  ...,  0.2092,  0.1774,  0.6587],\n",
      "        [-0.1543, -0.0177,  0.0759,  ..., -0.1689,  0.3819,  0.4727]],\n",
      "       dtype=torch.float64) tensor([1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 0, 1])\n",
      "tensor([[ 0.0816, -0.2837,  0.0846,  ...,  0.3690,  0.0852,  0.6338],\n",
      "        [-0.0410, -0.1381,  0.0420,  ..., -0.1939,  0.0293,  0.5145],\n",
      "        [-0.3956,  0.1458, -0.3091,  ..., -0.2332,  0.1498,  0.3229],\n",
      "        ...,\n",
      "        [-0.1221, -0.0628, -0.1076,  ..., -0.2150,  0.1936,  0.3503],\n",
      "        [-0.3917,  0.1928, -0.1760,  ..., -0.1241, -0.0078,  0.4285],\n",
      "        [-0.3424, -0.3102, -0.1328,  ..., -0.2490,  0.4820, -0.0846]],\n",
      "       dtype=torch.float64) tensor([1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0,\n",
      "        1, 1, 1, 0, 1, 0, 1, 0])\n",
      "tensor([[ 0.0165, -0.0119, -0.1854,  ..., -0.3350,  0.1675,  0.2888],\n",
      "        [-0.5262, -0.1319, -0.2736,  ..., -0.1353,  0.3233,  0.3721],\n",
      "        [-0.3747, -0.1925,  0.0560,  ..., -0.0242,  0.1178,  0.6934],\n",
      "        ...,\n",
      "        [-0.4706, -0.3622, -0.6585,  ..., -0.3377,  0.0582,  0.2809],\n",
      "        [-0.4094, -0.1796, -0.1726,  ...,  0.0416, -0.1324,  0.1882],\n",
      "        [-0.1564, -0.0392, -0.1238,  ...,  0.1028,  0.0465,  0.1605]],\n",
      "       dtype=torch.float64) tensor([0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0,\n",
      "        0, 0, 0, 0, 1, 1, 0, 0])\n",
      "tensor([[-0.4000, -0.4191,  0.0136,  ..., -0.1790,  0.2205, -0.0810],\n",
      "        [-0.3005, -0.4155, -0.5347,  ...,  0.0522, -0.1128,  0.5284],\n",
      "        [-0.3696, -0.4021, -0.0699,  ..., -0.2480,  0.3720,  0.1491],\n",
      "        ...,\n",
      "        [-0.3002,  0.1406,  0.1464,  ...,  0.1318, -0.3889,  0.4883],\n",
      "        [ 0.1185,  0.5993, -0.0337,  ..., -0.1572, -0.1994,  0.6431],\n",
      "        [-0.2569, -0.2388, -0.2662,  ..., -0.3022,  0.0228,  0.8991]],\n",
      "       dtype=torch.float64) tensor([1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 0, 1])\n",
      "tensor([[-0.0665, -0.5884, -0.2003,  ...,  0.0831,  0.4587,  0.2049],\n",
      "        [-0.3655, -0.4612, -0.0649,  ..., -0.0193,  0.1001,  0.4287],\n",
      "        [ 0.0016, -0.0896,  0.1195,  ..., -0.1457,  0.0877,  0.5756],\n",
      "        ...,\n",
      "        [ 0.0548, -0.0022,  0.0746,  ..., -0.0522, -0.1037,  0.6016],\n",
      "        [-0.4908, -0.1057, -0.4646,  ..., -0.5739, -0.0677,  0.4684],\n",
      "        [-0.3176,  0.0805, -0.4419,  ...,  0.1440,  0.1504,  0.3226]],\n",
      "       dtype=torch.float64) tensor([0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
      "        0, 0, 1, 0, 1, 0, 1, 0])\n",
      "tensor([[-0.3102,  0.2605, -0.2611,  ...,  0.4830,  0.2683,  0.0937],\n",
      "        [-0.3062, -0.5360, -0.2702,  ..., -0.3254,  0.3582,  0.2336],\n",
      "        [-0.0174, -0.1728, -0.3337,  ...,  0.0792,  0.1215,  0.6039],\n",
      "        ...,\n",
      "        [-0.0989, -0.1985,  0.1777,  ...,  0.2462,  0.0932,  0.1239],\n",
      "        [ 0.0619, -0.1948, -0.1017,  ...,  0.1447,  0.1777,  0.4637],\n",
      "        [-0.1128, -0.4283, -0.1979,  ...,  0.2046,  0.2148,  0.6772]],\n",
      "       dtype=torch.float64) tensor([0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1,\n",
      "        1, 0, 1, 1, 1, 0, 1, 0])\n",
      "tensor([[-0.9479, -0.1786, -0.7479,  ..., -0.1181, -0.0145,  0.8103],\n",
      "        [-0.3699, -0.6506, -0.2184,  ..., -0.1604,  0.2285,  0.3627],\n",
      "        [-0.0546, -0.1521,  0.0710,  ..., -0.0751,  0.1338,  0.4768],\n",
      "        ...,\n",
      "        [-0.4711, -0.3533, -0.1416,  ...,  0.2086, -0.0704,  0.7381],\n",
      "        [-0.3654, -0.2207,  0.0539,  ..., -0.1658, -0.2398,  0.0704],\n",
      "        [-0.0865, -0.3297, -0.3996,  ..., -0.1030,  0.0640,  0.3861]],\n",
      "       dtype=torch.float64) tensor([1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
      "        0, 1, 0, 0, 1, 0, 0, 0])\n",
      "tensor([[-0.3629, -0.0527, -0.1253,  ..., -0.3385,  0.4875,  0.4561],\n",
      "        [-0.2060,  0.0209,  0.0651,  ..., -0.4083,  0.2643, -0.0050],\n",
      "        [-0.6240,  0.0184, -0.0075,  ...,  0.0645, -0.2150,  0.7662],\n",
      "        ...,\n",
      "        [ 0.1361, -0.6612,  0.0675,  ...,  0.2563, -0.0113,  0.8416],\n",
      "        [-0.1310, -0.0819, -0.1740,  ..., -0.1971,  0.1073,  0.3504],\n",
      "        [-0.2575, -0.1094, -0.0217,  ..., -0.2577,  0.3068,  0.5533]],\n",
      "       dtype=torch.float64) tensor([1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0,\n",
      "        0, 1, 1, 0, 1, 1, 0, 1])\n",
      "tensor([[-0.2883, -0.2399, -0.2337,  ..., -0.1975,  0.0811,  0.5695],\n",
      "        [-0.3075, -0.1323, -0.2233,  ..., -0.0474, -0.0086,  0.5182],\n",
      "        [-0.3679, -0.3126, -0.1972,  ..., -0.7341,  0.0071,  0.3186],\n",
      "        ...,\n",
      "        [-0.1167, -0.1424, -0.2256,  ..., -0.1295,  0.1830,  0.4294],\n",
      "        [-0.1030, -0.0141, -0.0767,  ...,  0.5730, -0.0561,  0.4597],\n",
      "        [-0.3276, -0.2205, -0.2045,  ..., -0.0239, -0.3887,  0.4164]],\n",
      "       dtype=torch.float64) tensor([1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
      "        0, 1, 1, 1, 0, 1, 1, 1])\n",
      "tensor([[-4.9589e-01, -6.3138e-01, -2.6047e-01,  ...,  3.2700e-01,\n",
      "          2.2300e-01,  7.9841e-01],\n",
      "        [-4.3387e-01, -2.4175e-01, -6.5718e-01,  ..., -2.5503e-01,\n",
      "          2.7229e-01,  3.1009e-01],\n",
      "        [ 9.3984e-02, -2.4018e-01,  3.6560e-02,  ...,  4.6245e-01,\n",
      "          3.4430e-03,  7.6499e-01],\n",
      "        ...,\n",
      "        [-3.1490e-01, -1.6579e-01, -1.6402e-01,  ..., -3.2896e-01,\n",
      "          6.4268e-04,  2.8075e-01],\n",
      "        [-3.8782e-01, -5.2335e-01, -2.7019e-01,  ..., -6.6644e-02,\n",
      "          1.6740e-01,  6.5303e-01],\n",
      "        [-2.7350e-01, -1.8207e-01, -1.5663e-02,  ..., -9.5985e-02,\n",
      "         -8.2484e-02,  6.8499e-01]], dtype=torch.float64) tensor([0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
      "        0, 1, 1, 0, 1, 1, 1, 0])\n",
      "tensor([[-0.4902, -0.8248, -0.5436,  ...,  0.1312,  0.0527,  0.2831],\n",
      "        [-0.1532, -0.0906, -0.0662,  ..., -0.2703,  0.3579,  0.5764],\n",
      "        [ 0.0216,  0.1916, -0.1645,  ..., -0.3471, -0.0703,  0.3307],\n",
      "        ...,\n",
      "        [-0.3559, -0.3054,  0.2338,  ...,  0.2489, -0.3040,  0.8319],\n",
      "        [-0.3042,  0.2002, -0.4270,  ..., -0.2338,  0.2407,  0.7978],\n",
      "        [-0.5873,  0.0200, -0.2199,  ..., -0.2422, -0.1670,  0.5013]],\n",
      "       dtype=torch.float64) tensor([1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0,\n",
      "        1, 1, 0, 0, 0, 1, 1, 0])\n",
      "tensor([[-1.8403e-01, -4.7565e-01, -2.7092e-01,  ...,  1.6608e-01,\n",
      "          4.0393e-01,  1.4499e-01],\n",
      "        [-2.3201e-01, -3.5044e-01,  4.0084e-01,  ...,  4.2986e-01,\n",
      "         -1.7775e-01,  4.8806e-01],\n",
      "        [-2.7887e-01, -4.0887e-01,  1.3108e-02,  ..., -2.1118e-01,\n",
      "          9.4232e-02,  4.2368e-01],\n",
      "        ...,\n",
      "        [-2.0054e-01, -6.3938e-02, -2.1197e-04,  ..., -1.8469e-01,\n",
      "         -2.8353e-02,  2.0094e-01],\n",
      "        [-2.2902e-01,  7.2140e-02,  1.0145e-01,  ...,  2.0353e-01,\n",
      "         -3.9436e-01,  5.9914e-01],\n",
      "        [-9.5373e-01, -3.4961e-01,  6.3037e-02,  ..., -7.0782e-02,\n",
      "          1.0067e-01,  5.5897e-01]], dtype=torch.float64) tensor([1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0,\n",
      "        0, 1, 0, 1, 0, 0, 0, 0])\n",
      "tensor([[-0.1693, -0.2269,  0.1784,  ..., -0.1958, -0.1212,  0.4303],\n",
      "        [ 0.1414,  0.1932, -0.4173,  ..., -0.2355, -0.3045,  0.4444],\n",
      "        [-0.3687, -0.1855, -0.1101,  ...,  0.1375,  0.0259,  0.9262],\n",
      "        ...,\n",
      "        [-0.6726, -0.5744, -0.2621,  ..., -0.7432, -0.0293,  0.2171],\n",
      "        [-0.0097, -0.3966, -0.6918,  ...,  0.0279,  0.4585,  0.3251],\n",
      "        [-0.5440, -0.3999, -0.1036,  ..., -0.2777,  0.3993,  0.5579]],\n",
      "       dtype=torch.float64) tensor([0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1,\n",
      "        0, 0, 0, 0, 1, 1, 1, 0])\n",
      "tensor([[-0.3742, -0.7444, -0.1120,  ...,  0.0338, -0.0267,  0.4138],\n",
      "        [-0.3504, -0.1801, -0.0773,  ...,  0.0657,  0.2823,  0.1863],\n",
      "        [-0.2106, -0.0328, -0.3551,  ...,  0.1463, -0.1868,  0.3793],\n",
      "        ...,\n",
      "        [-0.1620, -0.0554,  0.0345,  ...,  0.1149, -0.1475,  0.4527],\n",
      "        [-0.0378,  0.0347, -0.0178,  ...,  0.0404, -0.3202,  1.2625],\n",
      "        [-0.3885, -0.1531,  0.3169,  ..., -0.2944, -0.1457,  0.4603]],\n",
      "       dtype=torch.float64) tensor([0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n",
      "        1, 1, 1, 0, 0, 1, 0, 0])\n",
      "tensor([[-0.2970, -0.2696, -0.2563,  ...,  0.1259,  0.1957,  0.5769],\n",
      "        [ 0.0573, -0.1864, -0.1173,  ...,  0.0839,  0.1057,  0.6189],\n",
      "        [-0.3540, -0.3813, -0.0124,  ..., -0.1035, -0.1712,  0.8400],\n",
      "        ...,\n",
      "        [-0.1515, -0.4885, -0.0282,  ...,  0.0158,  0.1853,  0.8324],\n",
      "        [-0.1932,  0.2325,  0.1948,  ..., -0.5019,  0.3313,  0.2525],\n",
      "        [-0.2144, -0.5711, -0.2346,  ..., -0.0106,  0.3848,  0.7451]],\n",
      "       dtype=torch.float64) tensor([0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
      "        1, 1, 0, 1, 0, 1, 0, 1])\n",
      "tensor([[-0.2645, -0.3555, -0.0816,  ...,  0.4266, -0.1453,  0.6738],\n",
      "        [-0.2585, -0.3112,  0.4354,  ...,  0.1201, -0.2544,  0.5657],\n",
      "        [-0.2420, -0.6413, -0.4073,  ..., -0.0889,  0.5253,  0.4885],\n",
      "        ...,\n",
      "        [-0.0051, -0.3002,  0.4897,  ...,  0.1846, -0.0432,  0.7398],\n",
      "        [-0.2806, -0.0635, -0.0221,  ..., -0.2173,  0.2267,  0.3579],\n",
      "        [-0.0290, -0.3144,  0.1413,  ...,  0.2213, -0.1640,  0.6646]],\n",
      "       dtype=torch.float64) tensor([0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1,\n",
      "        0, 1, 1, 1, 0, 0, 1, 1])\n",
      "tensor([[-0.1635,  0.1429, -0.1578,  ..., -0.1344, -0.0631,  0.4102],\n",
      "        [ 0.2772, -0.3575, -0.1410,  ...,  0.7138, -0.0431,  0.5105],\n",
      "        [-0.1327,  0.0408,  0.0295,  ...,  0.0638,  0.1662,  0.2499],\n",
      "        ...,\n",
      "        [ 0.0378, -0.3631, -0.1272,  ..., -0.1222, -0.3745,  0.7063],\n",
      "        [-0.1956,  0.0712, -0.5828,  ..., -0.0498, -0.1996,  0.5980],\n",
      "        [ 0.0324, -0.4248, -0.1005,  ..., -0.1586, -0.0476,  0.0397]],\n",
      "       dtype=torch.float64) tensor([1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
      "        0, 0, 1, 1, 1, 0, 0, 0])\n",
      "tensor([[-0.4536, -0.3214, -0.4202,  ..., -0.1488,  0.0397,  0.0222],\n",
      "        [-0.7827, -0.2682, -0.0894,  ..., -0.5378,  0.0753,  0.4956],\n",
      "        [-0.0696, -0.2717, -0.4123,  ...,  0.0846,  0.1925,  0.3987],\n",
      "        ...,\n",
      "        [ 0.0405, -0.0250, -0.1757,  ...,  0.3985,  0.0208,  0.8621],\n",
      "        [-0.1748, -0.0684, -0.2541,  ..., -0.5684,  0.1942,  0.2857],\n",
      "        [-0.4507, -0.4184, -0.4382,  ..., -0.3402,  0.4862,  0.4388]],\n",
      "       dtype=torch.float64) tensor([0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
      "        1, 1, 0, 0, 0, 1, 0, 1])\n",
      "tensor([[-7.9861e-01, -4.1453e-01, -3.9670e-01,  ..., -2.0908e-01,\n",
      "         -1.0284e-01,  7.0317e-01],\n",
      "        [-2.6449e-01, -1.5114e-01,  3.7925e-04,  ..., -6.4658e-01,\n",
      "          8.4778e-02,  4.1805e-01],\n",
      "        [-1.7312e-01, -7.7463e-01, -5.6808e-01,  ..., -1.1947e-01,\n",
      "          2.7299e-01,  2.9700e-01],\n",
      "        ...,\n",
      "        [ 1.7275e-01, -6.8430e-02, -9.0752e-02,  ..., -2.4793e-01,\n",
      "         -2.0854e-02,  1.7272e-01],\n",
      "        [-6.6409e-02, -1.3842e-01,  3.7532e-01,  ...,  2.5811e-01,\n",
      "         -1.7112e-01,  5.4869e-01],\n",
      "        [-9.5645e-02, -4.4193e-01,  5.0300e-01,  ...,  2.6730e-01,\n",
      "         -1.8384e-01,  7.1884e-01]], dtype=torch.float64) tensor([1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        0, 1, 0, 1, 1, 0, 0, 1])\n",
      "tensor([[-0.3410, -0.2085, -0.2322,  ..., -0.5234, -0.0291,  0.0978],\n",
      "        [-0.3649, -0.2655, -0.1934,  ..., -0.3114, -0.1897,  0.3923],\n",
      "        [-0.1306, -0.3950, -0.3908,  ..., -0.2753,  0.3243,  0.2079],\n",
      "        ...,\n",
      "        [-0.2989, -0.0222, -0.0234,  ..., -0.1943,  0.1508,  0.1284],\n",
      "        [-0.2588, -0.0212,  0.0025,  ..., -0.0279,  0.1332,  0.4375],\n",
      "        [-0.7392, -0.2041, -0.5336,  ..., -0.1845,  0.0882,  0.3159]],\n",
      "       dtype=torch.float64) tensor([0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1,\n",
      "        0, 1, 0, 0, 0, 1, 0, 1])\n",
      "tensor([[-0.5329, -0.3322, -0.0924,  ...,  0.1740,  0.0887,  0.8287],\n",
      "        [-0.2209, -0.2507, -0.7102,  ..., -0.3169,  0.2160,  0.5282],\n",
      "        [-0.3827, -0.4621, -0.2878,  ..., -0.2351,  0.4173,  0.5831],\n",
      "        ...,\n",
      "        [-0.3390,  0.1068, -0.2474,  ...,  0.1037,  0.0667,  0.5552],\n",
      "        [ 0.1043,  0.1132, -0.3819,  ..., -0.1863, -0.0923,  0.0747],\n",
      "        [-0.0688, -0.4124, -0.1129,  ..., -0.2713,  0.0961,  0.2527]],\n",
      "       dtype=torch.float64) tensor([1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0,\n",
      "        1, 1, 1, 1, 0, 1, 0, 0])\n",
      "tensor([[-0.0781, -0.1166, -0.6709,  ...,  0.2520,  0.0092,  0.5391],\n",
      "        [ 0.1569, -0.0948, -0.1248,  ...,  0.1436,  0.0975,  0.2991],\n",
      "        [-0.1411, -0.4492,  0.0757,  ...,  0.1497, -0.1743,  0.4697],\n",
      "        ...,\n",
      "        [-0.0908,  0.1338, -0.0253,  ...,  0.0790, -0.0406,  0.4443],\n",
      "        [-0.2800, -0.4623, -0.1179,  ...,  0.2194, -0.1523,  0.5170],\n",
      "        [-0.3724, -0.1066, -0.3791,  ..., -0.2129, -0.1988,  0.4264]],\n",
      "       dtype=torch.float64) tensor([1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
      "        1, 1, 1, 0, 0, 1, 0, 1])\n",
      "tensor([[-0.0768, -0.3013, -0.5020,  ...,  0.3433,  0.2429,  0.3619],\n",
      "        [ 0.0435, -0.2213, -0.7307,  ..., -0.5114, -0.1385,  0.3635]],\n",
      "       dtype=torch.float64) tensor([1, 0])\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(zip(train_loader_train, train_loader_labels)):\n",
    "    x, y = data\n",
    "    print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(92), 180)\n",
      "訓練周期: 0 [0/1802 (0%)]\tTotal Loss: 0.73\ttraining Loss: 0.73\tval Loss: 0.69\t訓練正確率: 43.75%\t校驗正確率: 51.11%\n",
      "(tensor(92), 180)\n",
      "訓練周期: 0 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 49.43%\t校驗正確率: 51.11%\n",
      "(tensor(90), 180)\n",
      "訓練周期: 0 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 49.11%\t校驗正確率: 50.00%\n",
      "(tensor(90), 180)\n",
      "訓練周期: 0 [960/1802 (65%)]\tTotal Loss: 0.70\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 48.69%\t校驗正確率: 50.00%\n",
      "(tensor(88), 180)\n",
      "訓練周期: 0 [1280/1802 (87%)]\tTotal Loss: 0.70\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 48.17%\t校驗正確率: 48.89%\n",
      "(tensor(92), 180)\n",
      "訓練周期: 1 [0/1802 (0%)]\tTotal Loss: 0.73\ttraining Loss: 0.87\tval Loss: 0.69\t訓練正確率: 46.88%\t校驗正確率: 51.11%\n",
      "(tensor(86), 180)\n",
      "訓練周期: 1 [320/1802 (22%)]\tTotal Loss: 0.73\ttraining Loss: 0.71\tval Loss: 0.69\t訓練正確率: 52.84%\t校驗正確率: 47.78%\n",
      "(tensor(87), 180)\n",
      "訓練周期: 1 [640/1802 (43%)]\tTotal Loss: 0.72\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 53.72%\t校驗正確率: 48.33%\n",
      "(tensor(85), 180)\n",
      "訓練周期: 1 [960/1802 (65%)]\tTotal Loss: 0.72\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 51.81%\t校驗正確率: 47.22%\n",
      "(tensor(82), 180)\n",
      "訓練周期: 1 [1280/1802 (87%)]\tTotal Loss: 0.72\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 50.69%\t校驗正確率: 45.56%\n",
      "(tensor(79), 180)\n",
      "訓練周期: 2 [0/1802 (0%)]\tTotal Loss: 0.73\ttraining Loss: 0.81\tval Loss: 0.69\t訓練正確率: 43.75%\t校驗正確率: 43.89%\n",
      "(tensor(83), 180)\n",
      "訓練周期: 2 [320/1802 (22%)]\tTotal Loss: 0.72\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 48.01%\t校驗正確率: 46.11%\n",
      "(tensor(91), 180)\n",
      "訓練周期: 2 [640/1802 (43%)]\tTotal Loss: 0.72\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 48.07%\t校驗正確率: 50.56%\n",
      "(tensor(79), 180)\n",
      "訓練周期: 2 [960/1802 (65%)]\tTotal Loss: 0.72\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 48.69%\t校驗正確率: 43.89%\n",
      "(tensor(88), 180)\n",
      "訓練周期: 2 [1280/1802 (87%)]\tTotal Loss: 0.72\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 48.17%\t校驗正確率: 48.89%\n",
      "(tensor(87), 180)\n",
      "訓練周期: 3 [0/1802 (0%)]\tTotal Loss: 0.72\ttraining Loss: 0.75\tval Loss: 0.69\t訓練正確率: 46.88%\t校驗正確率: 48.33%\n",
      "(tensor(86), 180)\n",
      "訓練周期: 3 [320/1802 (22%)]\tTotal Loss: 0.72\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 51.42%\t校驗正確率: 47.78%\n",
      "(tensor(79), 180)\n",
      "訓練周期: 3 [640/1802 (43%)]\tTotal Loss: 0.72\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 49.70%\t校驗正確率: 43.89%\n",
      "(tensor(107), 180)\n",
      "訓練周期: 3 [960/1802 (65%)]\tTotal Loss: 0.72\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 48.59%\t校驗正確率: 59.44%\n",
      "(tensor(85), 180)\n",
      "訓練周期: 3 [1280/1802 (87%)]\tTotal Loss: 0.72\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 49.39%\t校驗正確率: 47.22%\n",
      "(tensor(79), 180)\n",
      "訓練周期: 4 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.63\tval Loss: 0.70\t訓練正確率: 62.50%\t校驗正確率: 43.89%\n",
      "(tensor(85), 180)\n",
      "訓練周期: 4 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.69\t訓練正確率: 48.01%\t校驗正確率: 47.22%\n",
      "(tensor(90), 180)\n",
      "訓練周期: 4 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.70\t訓練正確率: 49.11%\t校驗正確率: 50.00%\n",
      "(tensor(90), 180)\n",
      "訓練周期: 4 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.69\t訓練正確率: 49.60%\t校驗正確率: 50.00%\n",
      "(tensor(89), 180)\n",
      "訓練周期: 4 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.70\t訓練正確率: 50.08%\t校驗正確率: 49.44%\n",
      "(tensor(91), 180)\n",
      "訓練周期: 5 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.81\tval Loss: 0.69\t訓練正確率: 40.62%\t校驗正確率: 50.56%\n",
      "(tensor(87), 180)\n",
      "訓練周期: 5 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 50.57%\t校驗正確率: 48.33%\n",
      "(tensor(85), 180)\n",
      "訓練周期: 5 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 52.53%\t校驗正確率: 47.22%\n",
      "(tensor(91), 180)\n",
      "訓練周期: 5 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 50.60%\t校驗正確率: 50.56%\n",
      "(tensor(92), 180)\n",
      "訓練周期: 5 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 50.99%\t校驗正確率: 51.11%\n",
      "(tensor(85), 180)\n",
      "訓練周期: 6 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.82\tval Loss: 0.69\t訓練正確率: 40.62%\t校驗正確率: 47.22%\n",
      "(tensor(84), 180)\n",
      "訓練周期: 6 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 48.86%\t校驗正確率: 46.67%\n",
      "(tensor(93), 180)\n",
      "訓練周期: 6 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 50.15%\t校驗正確率: 51.67%\n",
      "(tensor(88), 180)\n",
      "訓練周期: 6 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 50.81%\t校驗正確率: 48.89%\n",
      "(tensor(89), 180)\n",
      "訓練周期: 6 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 51.30%\t校驗正確率: 49.44%\n",
      "(tensor(91), 180)\n",
      "訓練周期: 7 [0/1802 (0%)]\tTotal Loss: 0.72\ttraining Loss: 0.80\tval Loss: 0.69\t訓練正確率: 31.25%\t校驗正確率: 50.56%\n",
      "(tensor(85), 180)\n",
      "訓練周期: 7 [320/1802 (22%)]\tTotal Loss: 0.72\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 49.43%\t校驗正確率: 47.22%\n",
      "(tensor(87), 180)\n",
      "訓練周期: 7 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 51.93%\t校驗正確率: 48.33%\n",
      "(tensor(87), 180)\n",
      "訓練周期: 7 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 51.01%\t校驗正確率: 48.33%\n",
      "(tensor(84), 180)\n",
      "訓練周期: 7 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 51.22%\t校驗正確率: 46.67%\n",
      "(tensor(95), 180)\n",
      "訓練周期: 8 [0/1802 (0%)]\tTotal Loss: 0.72\ttraining Loss: 0.82\tval Loss: 0.69\t訓練正確率: 46.88%\t校驗正確率: 52.78%\n",
      "(tensor(92), 180)\n",
      "訓練周期: 8 [320/1802 (22%)]\tTotal Loss: 0.72\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 52.27%\t校驗正確率: 51.11%\n",
      "(tensor(92), 180)\n",
      "訓練周期: 8 [640/1802 (43%)]\tTotal Loss: 0.72\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 49.70%\t校驗正確率: 51.11%\n",
      "(tensor(95), 180)\n",
      "訓練周期: 8 [960/1802 (65%)]\tTotal Loss: 0.72\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 49.80%\t校驗正確率: 52.78%\n",
      "(tensor(88), 180)\n",
      "訓練周期: 8 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 48.78%\t校驗正確率: 48.89%\n",
      "(tensor(80), 180)\n",
      "訓練周期: 9 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.68\tval Loss: 0.70\t訓練正確率: 56.25%\t校驗正確率: 44.44%\n",
      "(tensor(96), 180)\n",
      "訓練周期: 9 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.69\t訓練正確率: 48.58%\t校驗正確率: 53.33%\n",
      "(tensor(97), 180)\n",
      "訓練周期: 9 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.69\t訓練正確率: 48.66%\t校驗正確率: 53.89%\n",
      "(tensor(90), 180)\n",
      "訓練周期: 9 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.69\t訓練正確率: 48.89%\t校驗正確率: 50.00%\n",
      "(tensor(87), 180)\n",
      "訓練周期: 9 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.70\t訓練正確率: 48.48%\t校驗正確率: 48.33%\n",
      "(tensor(86), 180)\n",
      "訓練周期: 10 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.80\tval Loss: 0.70\t訓練正確率: 46.88%\t校驗正確率: 47.78%\n",
      "(tensor(77), 180)\n",
      "訓練周期: 10 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 50.57%\t校驗正確率: 42.78%\n",
      "(tensor(86), 180)\n",
      "訓練周期: 10 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 50.15%\t校驗正確率: 47.78%\n",
      "(tensor(88), 180)\n",
      "訓練周期: 10 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 50.50%\t校驗正確率: 48.89%\n",
      "(tensor(86), 180)\n",
      "訓練周期: 10 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 50.84%\t校驗正確率: 47.78%\n",
      "(tensor(106), 180)\n",
      "訓練周期: 11 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.80\tval Loss: 0.69\t訓練正確率: 43.75%\t校驗正確率: 58.89%\n",
      "(tensor(83), 180)\n",
      "訓練周期: 11 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 51.14%\t校驗正確率: 46.11%\n",
      "(tensor(88), 180)\n",
      "訓練周期: 11 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 47.47%\t校驗正確率: 48.89%\n",
      "(tensor(88), 180)\n",
      "訓練周期: 11 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 47.38%\t校驗正確率: 48.89%\n",
      "(tensor(88), 180)\n",
      "訓練周期: 11 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 47.64%\t校驗正確率: 48.89%\n",
      "(tensor(90), 180)\n",
      "訓練周期: 12 [0/1802 (0%)]\tTotal Loss: 0.72\ttraining Loss: 0.81\tval Loss: 0.69\t訓練正確率: 40.62%\t校驗正確率: 50.00%\n",
      "(tensor(82), 180)\n",
      "訓練周期: 12 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 49.15%\t校驗正確率: 45.56%\n",
      "(tensor(94), 180)\n",
      "訓練周期: 12 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 49.70%\t校驗正確率: 52.22%\n",
      "(tensor(89), 180)\n",
      "訓練周期: 12 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 50.40%\t校驗正確率: 49.44%\n",
      "(tensor(91), 180)\n",
      "訓練周期: 12 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 50.00%\t校驗正確率: 50.56%\n",
      "(tensor(88), 180)\n",
      "訓練周期: 13 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.66\tval Loss: 0.70\t訓練正確率: 56.25%\t校驗正確率: 48.89%\n",
      "(tensor(86), 180)\n",
      "訓練周期: 13 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 48.58%\t校驗正確率: 47.78%\n",
      "(tensor(97), 180)\n",
      "訓練周期: 13 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 49.11%\t校驗正確率: 53.89%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(100), 180)\n",
      "訓練周期: 13 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 49.80%\t校驗正確率: 55.56%\n",
      "(tensor(95), 180)\n",
      "訓練周期: 13 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 49.77%\t校驗正確率: 52.78%\n",
      "(tensor(90), 180)\n",
      "訓練周期: 14 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.78\tval Loss: 0.69\t訓練正確率: 46.88%\t校驗正確率: 50.00%\n",
      "(tensor(88), 180)\n",
      "訓練周期: 14 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 49.15%\t校驗正確率: 48.89%\n",
      "(tensor(97), 180)\n",
      "訓練周期: 14 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 48.81%\t校驗正確率: 53.89%\n",
      "(tensor(95), 180)\n",
      "訓練周期: 14 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 47.58%\t校驗正確率: 52.78%\n",
      "(tensor(96), 180)\n",
      "訓練周期: 14 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 48.17%\t校驗正確率: 53.33%\n",
      "(tensor(94), 180)\n",
      "訓練周期: 15 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.75\tval Loss: 0.69\t訓練正確率: 40.62%\t校驗正確率: 52.22%\n",
      "(tensor(89), 180)\n",
      "訓練周期: 15 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 49.43%\t校驗正確率: 49.44%\n",
      "(tensor(93), 180)\n",
      "訓練周期: 15 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 51.19%\t校驗正確率: 51.67%\n",
      "(tensor(102), 180)\n",
      "訓練周期: 15 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.69\t訓練正確率: 51.41%\t校驗正確率: 56.67%\n",
      "(tensor(86), 180)\n",
      "訓練周期: 15 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.70\t訓練正確率: 50.99%\t校驗正確率: 47.78%\n",
      "(tensor(93), 180)\n",
      "訓練周期: 16 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.74\tval Loss: 0.69\t訓練正確率: 56.25%\t校驗正確率: 51.67%\n",
      "(tensor(80), 180)\n",
      "訓練周期: 16 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 50.85%\t校驗正確率: 44.44%\n",
      "(tensor(92), 180)\n",
      "訓練周期: 16 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 49.70%\t校驗正確率: 51.11%\n",
      "(tensor(81), 180)\n",
      "訓練周期: 16 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 48.79%\t校驗正確率: 45.00%\n",
      "(tensor(101), 180)\n",
      "訓練周期: 16 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 49.09%\t校驗正確率: 56.11%\n",
      "(tensor(99), 180)\n",
      "訓練周期: 17 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.72\tval Loss: 0.68\t訓練正確率: 59.38%\t校驗正確率: 55.00%\n",
      "(tensor(90), 180)\n",
      "訓練周期: 17 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 52.27%\t校驗正確率: 50.00%\n",
      "(tensor(96), 180)\n",
      "訓練周期: 17 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 49.55%\t校驗正確率: 53.33%\n",
      "(tensor(93), 180)\n",
      "訓練周期: 17 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 50.10%\t校驗正確率: 51.67%\n",
      "(tensor(81), 180)\n",
      "訓練周期: 17 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 50.69%\t校驗正確率: 45.00%\n",
      "(tensor(94), 180)\n",
      "訓練周期: 18 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.79\tval Loss: 0.69\t訓練正確率: 37.50%\t校驗正確率: 52.22%\n",
      "(tensor(87), 180)\n",
      "訓練周期: 18 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.71\t訓練正確率: 50.85%\t校驗正確率: 48.33%\n",
      "(tensor(93), 180)\n",
      "訓練周期: 18 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 51.04%\t校驗正確率: 51.67%\n",
      "(tensor(98), 180)\n",
      "訓練周期: 18 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 50.20%\t校驗正確率: 54.44%\n",
      "(tensor(98), 180)\n",
      "訓練周期: 18 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 49.54%\t校驗正確率: 54.44%\n",
      "(tensor(91), 180)\n",
      "訓練周期: 19 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.73\tval Loss: 0.70\t訓練正確率: 62.50%\t校驗正確率: 50.56%\n",
      "(tensor(88), 180)\n",
      "訓練周期: 19 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 52.84%\t校驗正確率: 48.89%\n",
      "(tensor(87), 180)\n",
      "訓練周期: 19 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.69\t訓練正確率: 53.57%\t校驗正確率: 48.33%\n",
      "(tensor(94), 180)\n",
      "訓練周期: 19 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.69\t訓練正確率: 53.53%\t校驗正確率: 52.22%\n",
      "(tensor(85), 180)\n",
      "訓練周期: 19 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.70\t訓練正確率: 53.28%\t校驗正確率: 47.22%\n",
      "(tensor(103), 180)\n",
      "訓練周期: 20 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.73\tval Loss: 0.69\t訓練正確率: 50.00%\t校驗正確率: 57.22%\n",
      "(tensor(88), 180)\n",
      "訓練周期: 20 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.72\t訓練正確率: 53.98%\t校驗正確率: 48.89%\n",
      "(tensor(86), 180)\n",
      "訓練周期: 20 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 52.38%\t校驗正確率: 47.78%\n",
      "(tensor(89), 180)\n",
      "訓練周期: 20 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 50.30%\t校驗正確率: 49.44%\n",
      "(tensor(91), 180)\n",
      "訓練周期: 20 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 51.22%\t校驗正確率: 50.56%\n",
      "(tensor(88), 180)\n",
      "訓練周期: 21 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.76\tval Loss: 0.70\t訓練正確率: 56.25%\t校驗正確率: 48.89%\n",
      "(tensor(93), 180)\n",
      "訓練周期: 21 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 50.57%\t校驗正確率: 51.67%\n",
      "(tensor(89), 180)\n",
      "訓練周期: 21 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 48.81%\t校驗正確率: 49.44%\n",
      "(tensor(88), 180)\n",
      "訓練周期: 21 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 50.20%\t校驗正確率: 48.89%\n",
      "(tensor(88), 180)\n",
      "訓練周期: 21 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 50.99%\t校驗正確率: 48.89%\n",
      "(tensor(99), 180)\n",
      "訓練周期: 22 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.76\tval Loss: 0.69\t訓練正確率: 50.00%\t校驗正確率: 55.00%\n",
      "(tensor(99), 180)\n",
      "訓練周期: 22 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 55.68%\t校驗正確率: 55.00%\n",
      "(tensor(95), 180)\n",
      "訓練周期: 22 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 51.34%\t校驗正確率: 52.78%\n",
      "(tensor(85), 180)\n",
      "訓練周期: 22 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 51.41%\t校驗正確率: 47.22%\n",
      "(tensor(86), 180)\n",
      "訓練周期: 22 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 50.69%\t校驗正確率: 47.78%\n",
      "(tensor(89), 180)\n",
      "訓練周期: 23 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.65\tval Loss: 0.70\t訓練正確率: 65.62%\t校驗正確率: 49.44%\n",
      "(tensor(90), 180)\n",
      "訓練周期: 23 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.70\t訓練正確率: 50.28%\t校驗正確率: 50.00%\n",
      "(tensor(108), 180)\n",
      "訓練周期: 23 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 48.81%\t校驗正確率: 60.00%\n",
      "(tensor(90), 180)\n",
      "訓練周期: 23 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 47.98%\t校驗正確率: 50.00%\n",
      "(tensor(100), 180)\n",
      "訓練周期: 23 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 48.93%\t校驗正確率: 55.56%\n",
      "(tensor(90), 180)\n",
      "訓練周期: 24 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.73\tval Loss: 0.70\t訓練正確率: 53.12%\t校驗正確率: 50.00%\n",
      "(tensor(98), 180)\n",
      "訓練周期: 24 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.69\t訓練正確率: 53.41%\t校驗正確率: 54.44%\n",
      "(tensor(92), 180)\n",
      "訓練周期: 24 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 51.34%\t校驗正確率: 51.11%\n",
      "(tensor(97), 180)\n",
      "訓練周期: 24 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 49.40%\t校驗正確率: 53.89%\n",
      "(tensor(86), 180)\n",
      "訓練周期: 24 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 49.85%\t校驗正確率: 47.78%\n",
      "(tensor(82), 180)\n",
      "訓練周期: 25 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.71\tval Loss: 0.71\t訓練正確率: 50.00%\t校驗正確率: 45.56%\n",
      "(tensor(86), 180)\n",
      "訓練周期: 25 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.70\t訓練正確率: 51.70%\t校驗正確率: 47.78%\n",
      "(tensor(94), 180)\n",
      "訓練周期: 25 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 50.15%\t校驗正確率: 52.22%\n",
      "(tensor(87), 180)\n",
      "訓練周期: 25 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 49.09%\t校驗正確率: 48.33%\n",
      "(tensor(89), 180)\n",
      "訓練周期: 25 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 49.77%\t校驗正確率: 49.44%\n",
      "(tensor(89), 180)\n",
      "訓練周期: 26 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.71\tval Loss: 0.70\t訓練正確率: 46.88%\t校驗正確率: 49.44%\n",
      "(tensor(100), 180)\n",
      "訓練周期: 26 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 50.57%\t校驗正確率: 55.56%\n",
      "(tensor(94), 180)\n",
      "訓練周期: 26 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 49.11%\t校驗正確率: 52.22%\n",
      "(tensor(87), 180)\n",
      "訓練周期: 26 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 48.79%\t校驗正確率: 48.33%\n",
      "(tensor(90), 180)\n",
      "訓練周期: 26 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 48.78%\t校驗正確率: 50.00%\n",
      "(tensor(92), 180)\n",
      "訓練周期: 27 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.70\t訓練正確率: 53.12%\t校驗正確率: 51.11%\n",
      "(tensor(89), 180)\n",
      "訓練周期: 27 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 48.58%\t校驗正確率: 49.44%\n",
      "(tensor(96), 180)\n",
      "訓練周期: 27 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 49.40%\t校驗正確率: 53.33%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(84), 180)\n",
      "訓練周期: 27 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 47.38%\t校驗正確率: 46.67%\n",
      "(tensor(77), 180)\n",
      "訓練周期: 27 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 48.09%\t校驗正確率: 42.78%\n",
      "(tensor(94), 180)\n",
      "訓練周期: 28 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.75\tval Loss: 0.69\t訓練正確率: 53.12%\t校驗正確率: 52.22%\n",
      "(tensor(89), 180)\n",
      "訓練周期: 28 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 51.42%\t校驗正確率: 49.44%\n",
      "(tensor(85), 180)\n",
      "訓練周期: 28 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 48.81%\t校驗正確率: 47.22%\n",
      "(tensor(90), 180)\n",
      "訓練周期: 28 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 49.70%\t校驗正確率: 50.00%\n",
      "(tensor(85), 180)\n",
      "訓練周期: 28 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 49.62%\t校驗正確率: 47.22%\n",
      "(tensor(94), 180)\n",
      "訓練周期: 29 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.66\tval Loss: 0.69\t訓練正確率: 50.00%\t校驗正確率: 52.22%\n",
      "(tensor(89), 180)\n",
      "訓練周期: 29 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 49.72%\t校驗正確率: 49.44%\n",
      "(tensor(84), 180)\n",
      "訓練周期: 29 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 49.70%\t校驗正確率: 46.67%\n",
      "(tensor(84), 180)\n",
      "訓練周期: 29 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 50.50%\t校驗正確率: 46.67%\n",
      "(tensor(84), 180)\n",
      "訓練周期: 29 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 49.31%\t校驗正確率: 46.67%\n",
      "(tensor(87), 180)\n",
      "訓練周期: 30 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.80\tval Loss: 0.70\t訓練正確率: 40.62%\t校驗正確率: 48.33%\n",
      "(tensor(87), 180)\n",
      "訓練周期: 30 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 50.00%\t校驗正確率: 48.33%\n",
      "(tensor(81), 180)\n",
      "訓練周期: 30 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 50.74%\t校驗正確率: 45.00%\n",
      "(tensor(90), 180)\n",
      "訓練周期: 30 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 51.71%\t校驗正確率: 50.00%\n",
      "(tensor(87), 180)\n",
      "訓練周期: 30 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 51.45%\t校驗正確率: 48.33%\n",
      "(tensor(93), 180)\n",
      "訓練周期: 31 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.64\tval Loss: 0.69\t訓練正確率: 59.38%\t校驗正確率: 51.67%\n",
      "(tensor(85), 180)\n",
      "訓練周期: 31 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.71\t訓練正確率: 53.69%\t校驗正確率: 47.22%\n",
      "(tensor(89), 180)\n",
      "訓練周期: 31 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 49.40%\t校驗正確率: 49.44%\n",
      "(tensor(86), 180)\n",
      "訓練周期: 31 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 50.00%\t校驗正確率: 47.78%\n",
      "(tensor(91), 180)\n",
      "訓練周期: 31 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 50.08%\t校驗正確率: 50.56%\n",
      "(tensor(89), 180)\n",
      "訓練周期: 32 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.74\tval Loss: 0.70\t訓練正確率: 43.75%\t校驗正確率: 49.44%\n",
      "(tensor(92), 180)\n",
      "訓練周期: 32 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 53.98%\t校驗正確率: 51.11%\n",
      "(tensor(97), 180)\n",
      "訓練周期: 32 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 51.34%\t校驗正確率: 53.89%\n",
      "(tensor(91), 180)\n",
      "訓練周期: 32 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 51.11%\t校驗正確率: 50.56%\n",
      "(tensor(103), 180)\n",
      "訓練周期: 32 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 51.68%\t校驗正確率: 57.22%\n",
      "(tensor(91), 180)\n",
      "訓練周期: 33 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.73\tval Loss: 0.69\t訓練正確率: 56.25%\t校驗正確率: 50.56%\n",
      "(tensor(90), 180)\n",
      "訓練周期: 33 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 48.01%\t校驗正確率: 50.00%\n",
      "(tensor(93), 180)\n",
      "訓練周期: 33 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.70\t訓練正確率: 49.26%\t校驗正確率: 51.67%\n",
      "(tensor(104), 180)\n",
      "訓練周期: 33 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 50.30%\t校驗正確率: 57.78%\n",
      "(tensor(90), 180)\n",
      "訓練周期: 33 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 49.54%\t校驗正確率: 50.00%\n",
      "(tensor(91), 180)\n",
      "訓練周期: 34 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 56.25%\t校驗正確率: 50.56%\n",
      "(tensor(92), 180)\n",
      "訓練周期: 34 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 48.01%\t校驗正確率: 51.11%\n",
      "(tensor(96), 180)\n",
      "訓練周期: 34 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.70\t訓練正確率: 52.23%\t校驗正確率: 53.33%\n",
      "(tensor(81), 180)\n",
      "訓練周期: 34 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.71\t訓練正確率: 51.61%\t校驗正確率: 45.00%\n",
      "(tensor(86), 180)\n",
      "訓練周期: 34 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.70\t訓練正確率: 51.83%\t校驗正確率: 47.78%\n",
      "(tensor(95), 180)\n",
      "訓練周期: 35 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.74\tval Loss: 0.69\t訓練正確率: 50.00%\t校驗正確率: 52.78%\n",
      "(tensor(98), 180)\n",
      "訓練周期: 35 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 51.14%\t校驗正確率: 54.44%\n",
      "(tensor(88), 180)\n",
      "訓練周期: 35 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 51.64%\t校驗正確率: 48.89%\n",
      "(tensor(96), 180)\n",
      "訓練周期: 35 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 50.50%\t校驗正確率: 53.33%\n",
      "(tensor(87), 180)\n",
      "訓練周期: 35 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.70\t訓練正確率: 51.45%\t校驗正確率: 48.33%\n",
      "(tensor(96), 180)\n",
      "訓練周期: 36 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.79\tval Loss: 0.70\t訓練正確率: 31.25%\t校驗正確率: 53.33%\n",
      "(tensor(97), 180)\n",
      "訓練周期: 36 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 47.44%\t校驗正確率: 53.89%\n",
      "(tensor(88), 180)\n",
      "訓練周期: 36 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 48.81%\t校驗正確率: 48.89%\n",
      "(tensor(93), 180)\n",
      "訓練周期: 36 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 50.00%\t校驗正確率: 51.67%\n",
      "(tensor(86), 180)\n",
      "訓練周期: 36 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 50.15%\t校驗正確率: 47.78%\n",
      "(tensor(98), 180)\n",
      "訓練周期: 37 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.73\tval Loss: 0.69\t訓練正確率: 40.62%\t校驗正確率: 54.44%\n",
      "(tensor(89), 180)\n",
      "訓練周期: 37 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 51.42%\t校驗正確率: 49.44%\n",
      "(tensor(92), 180)\n",
      "訓練周期: 37 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 48.07%\t校驗正確率: 51.11%\n",
      "(tensor(88), 180)\n",
      "訓練周期: 37 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 47.88%\t校驗正確率: 48.89%\n",
      "(tensor(93), 180)\n",
      "訓練周期: 37 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 47.94%\t校驗正確率: 51.67%\n",
      "(tensor(84), 180)\n",
      "訓練周期: 38 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.87\tval Loss: 0.70\t訓練正確率: 28.12%\t校驗正確率: 46.67%\n",
      "(tensor(91), 180)\n",
      "訓練周期: 38 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.71\tval Loss: 0.69\t訓練正確率: 49.72%\t校驗正確率: 50.56%\n",
      "(tensor(94), 180)\n",
      "訓練周期: 38 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.71\tval Loss: 0.69\t訓練正確率: 48.07%\t校驗正確率: 52.22%\n",
      "(tensor(78), 180)\n",
      "訓練周期: 38 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.71\t訓練正確率: 48.99%\t校驗正確率: 43.33%\n",
      "(tensor(98), 180)\n",
      "訓練周期: 38 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 49.92%\t校驗正確率: 54.44%\n",
      "(tensor(84), 180)\n",
      "訓練周期: 39 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 53.12%\t校驗正確率: 46.67%\n",
      "(tensor(92), 180)\n",
      "訓練周期: 39 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 51.42%\t校驗正確率: 51.11%\n",
      "(tensor(86), 180)\n",
      "訓練周期: 39 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 49.11%\t校驗正確率: 47.78%\n",
      "(tensor(82), 180)\n",
      "訓練周期: 39 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 50.60%\t校驗正確率: 45.56%\n",
      "(tensor(79), 180)\n",
      "訓練周期: 39 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 51.37%\t校驗正確率: 43.89%\n",
      "(tensor(86), 180)\n",
      "訓練周期: 40 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.83\tval Loss: 0.70\t訓練正確率: 37.50%\t校驗正確率: 47.78%\n",
      "(tensor(92), 180)\n",
      "訓練周期: 40 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.71\tval Loss: 0.69\t訓練正確率: 51.14%\t校驗正確率: 51.11%\n",
      "(tensor(89), 180)\n",
      "訓練周期: 40 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 50.15%\t校驗正確率: 49.44%\n",
      "(tensor(84), 180)\n",
      "訓練周期: 40 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 48.89%\t校驗正確率: 46.67%\n",
      "(tensor(82), 180)\n",
      "訓練周期: 40 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 49.47%\t校驗正確率: 45.56%\n",
      "(tensor(94), 180)\n",
      "訓練周期: 41 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.67\tval Loss: 0.70\t訓練正確率: 56.25%\t校驗正確率: 52.22%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(89), 180)\n",
      "訓練周期: 41 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 44.89%\t校驗正確率: 49.44%\n",
      "(tensor(80), 180)\n",
      "訓練周期: 41 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.71\t訓練正確率: 46.13%\t校驗正確率: 44.44%\n",
      "(tensor(85), 180)\n",
      "訓練周期: 41 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 46.57%\t校驗正確率: 47.22%\n",
      "(tensor(89), 180)\n",
      "訓練周期: 41 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 47.41%\t校驗正確率: 49.44%\n",
      "(tensor(88), 180)\n",
      "訓練周期: 42 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.79\tval Loss: 0.69\t訓練正確率: 40.62%\t校驗正確率: 48.89%\n",
      "(tensor(89), 180)\n",
      "訓練周期: 42 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.71\tval Loss: 0.70\t訓練正確率: 46.31%\t校驗正確率: 49.44%\n",
      "(tensor(90), 180)\n",
      "訓練周期: 42 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 48.36%\t校驗正確率: 50.00%\n",
      "(tensor(87), 180)\n",
      "訓練周期: 42 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 49.29%\t校驗正確率: 48.33%\n",
      "(tensor(87), 180)\n",
      "訓練周期: 42 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 49.77%\t校驗正確率: 48.33%\n",
      "(tensor(85), 180)\n",
      "訓練周期: 43 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.65\tval Loss: 0.70\t訓練正確率: 56.25%\t校驗正確率: 47.22%\n",
      "(tensor(93), 180)\n",
      "訓練周期: 43 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.69\t訓練正確率: 50.00%\t校驗正確率: 51.67%\n",
      "(tensor(86), 180)\n",
      "訓練周期: 43 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.70\t訓練正確率: 50.30%\t校驗正確率: 47.78%\n",
      "(tensor(83), 180)\n",
      "訓練周期: 43 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.71\t訓練正確率: 50.40%\t校驗正確率: 46.11%\n",
      "(tensor(86), 180)\n",
      "訓練周期: 43 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.70\t訓練正確率: 51.07%\t校驗正確率: 47.78%\n",
      "(tensor(91), 180)\n",
      "訓練周期: 44 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 59.38%\t校驗正確率: 50.56%\n",
      "(tensor(89), 180)\n",
      "訓練周期: 44 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 49.72%\t校驗正確率: 49.44%\n",
      "(tensor(96), 180)\n",
      "訓練周期: 44 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.69\t訓練正確率: 51.19%\t校驗正確率: 53.33%\n",
      "(tensor(100), 180)\n",
      "訓練周期: 44 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 50.40%\t校驗正確率: 55.56%\n",
      "(tensor(95), 180)\n",
      "訓練周期: 44 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 49.24%\t校驗正確率: 52.78%\n",
      "(tensor(92), 180)\n",
      "訓練周期: 45 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.72\tval Loss: 0.69\t訓練正確率: 56.25%\t校驗正確率: 51.11%\n",
      "(tensor(88), 180)\n",
      "訓練周期: 45 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 47.44%\t校驗正確率: 48.89%\n",
      "(tensor(88), 180)\n",
      "訓練周期: 45 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 49.40%\t校驗正確率: 48.89%\n",
      "(tensor(94), 180)\n",
      "訓練周期: 45 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 50.30%\t校驗正確率: 52.22%\n",
      "(tensor(91), 180)\n",
      "訓練周期: 45 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.69\t訓練正確率: 50.91%\t校驗正確率: 50.56%\n",
      "(tensor(84), 180)\n",
      "訓練周期: 46 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.75\tval Loss: 0.69\t訓練正確率: 53.12%\t校驗正確率: 46.67%\n",
      "(tensor(89), 180)\n",
      "訓練周期: 46 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.71\t訓練正確率: 56.53%\t校驗正確率: 49.44%\n",
      "(tensor(85), 180)\n",
      "訓練周期: 46 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.71\t訓練正確率: 53.57%\t校驗正確率: 47.22%\n",
      "(tensor(94), 180)\n",
      "訓練周期: 46 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 50.91%\t校驗正確率: 52.22%\n",
      "(tensor(97), 180)\n",
      "訓練周期: 46 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 50.76%\t校驗正確率: 53.89%\n",
      "(tensor(94), 180)\n",
      "訓練周期: 47 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.68\tval Loss: 0.69\t訓練正確率: 62.50%\t校驗正確率: 52.22%\n",
      "(tensor(91), 180)\n",
      "訓練周期: 47 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.70\t訓練正確率: 50.28%\t校驗正確率: 50.56%\n",
      "(tensor(95), 180)\n",
      "訓練周期: 47 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 49.26%\t校驗正確率: 52.78%\n",
      "(tensor(94), 180)\n",
      "訓練周期: 47 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 49.40%\t校驗正確率: 52.22%\n",
      "(tensor(95), 180)\n",
      "訓練周期: 47 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.69\t訓練正確率: 50.61%\t校驗正確率: 52.78%\n",
      "(tensor(90), 180)\n",
      "訓練周期: 48 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.66\tval Loss: 0.70\t訓練正確率: 62.50%\t校驗正確率: 50.00%\n",
      "(tensor(86), 180)\n",
      "訓練周期: 48 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 50.57%\t校驗正確率: 47.78%\n",
      "(tensor(78), 180)\n",
      "訓練周期: 48 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.71\t訓練正確率: 51.04%\t校驗正確率: 43.33%\n",
      "(tensor(92), 180)\n",
      "訓練周期: 48 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 50.20%\t校驗正確率: 51.11%\n",
      "(tensor(85), 180)\n",
      "訓練周期: 48 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 50.53%\t校驗正確率: 47.22%\n",
      "(tensor(87), 180)\n",
      "訓練周期: 49 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.78\tval Loss: 0.70\t訓練正確率: 46.88%\t校驗正確率: 48.33%\n",
      "(tensor(96), 180)\n",
      "訓練周期: 49 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.71\tval Loss: 0.69\t訓練正確率: 51.99%\t校驗正確率: 53.33%\n",
      "(tensor(85), 180)\n",
      "訓練周期: 49 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 51.19%\t校驗正確率: 47.22%\n",
      "(tensor(92), 180)\n",
      "訓練周期: 49 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 49.70%\t校驗正確率: 51.11%\n",
      "(tensor(89), 180)\n",
      "訓練周期: 49 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 49.54%\t校驗正確率: 49.44%\n",
      "(tensor(90), 180)\n",
      "訓練周期: 50 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.73\tval Loss: 0.69\t訓練正確率: 53.12%\t校驗正確率: 50.00%\n",
      "(tensor(89), 180)\n",
      "訓練周期: 50 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 50.57%\t校驗正確率: 49.44%\n",
      "(tensor(84), 180)\n",
      "訓練周期: 50 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 48.21%\t校驗正確率: 46.67%\n",
      "(tensor(94), 180)\n",
      "訓練周期: 50 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 47.48%\t校驗正確率: 52.22%\n",
      "(tensor(88), 180)\n",
      "訓練周期: 50 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 47.64%\t校驗正確率: 48.89%\n",
      "(tensor(102), 180)\n",
      "訓練周期: 51 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.73\tval Loss: 0.69\t訓練正確率: 40.62%\t校驗正確率: 56.67%\n",
      "(tensor(87), 180)\n",
      "訓練周期: 51 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 50.57%\t校驗正確率: 48.33%\n",
      "(tensor(92), 180)\n",
      "訓練周期: 51 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 49.11%\t校驗正確率: 51.11%\n",
      "(tensor(91), 180)\n",
      "訓練周期: 51 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 48.39%\t校驗正確率: 50.56%\n",
      "(tensor(89), 180)\n",
      "訓練周期: 51 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 49.70%\t校驗正確率: 49.44%\n",
      "(tensor(79), 180)\n",
      "訓練周期: 52 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.73\tval Loss: 0.70\t訓練正確率: 40.62%\t校驗正確率: 43.89%\n",
      "(tensor(94), 180)\n",
      "訓練周期: 52 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 50.00%\t校驗正確率: 52.22%\n",
      "(tensor(99), 180)\n",
      "訓練周期: 52 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 49.70%\t校驗正確率: 55.00%\n",
      "(tensor(93), 180)\n",
      "訓練周期: 52 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 50.40%\t校驗正確率: 51.67%\n",
      "(tensor(93), 180)\n",
      "訓練周期: 52 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 50.99%\t校驗正確率: 51.67%\n",
      "(tensor(90), 180)\n",
      "訓練周期: 53 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.75\tval Loss: 0.70\t訓練正確率: 37.50%\t校驗正確率: 50.00%\n",
      "(tensor(88), 180)\n",
      "訓練周期: 53 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 50.57%\t校驗正確率: 48.89%\n",
      "(tensor(102), 180)\n",
      "訓練周期: 53 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 48.21%\t校驗正確率: 56.67%\n",
      "(tensor(86), 180)\n",
      "訓練周期: 53 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 48.39%\t校驗正確率: 47.78%\n",
      "(tensor(85), 180)\n",
      "訓練周期: 53 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 49.01%\t校驗正確率: 47.22%\n",
      "(tensor(91), 180)\n",
      "訓練周期: 54 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.64\tval Loss: 0.69\t訓練正確率: 59.38%\t校驗正確率: 50.56%\n",
      "(tensor(89), 180)\n",
      "訓練周期: 54 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.69\t訓練正確率: 53.69%\t校驗正確率: 49.44%\n",
      "(tensor(83), 180)\n",
      "訓練周期: 54 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.70\t訓練正確率: 49.85%\t校驗正確率: 46.11%\n",
      "(tensor(91), 180)\n",
      "訓練周期: 54 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.69\t訓練正確率: 50.71%\t校驗正確率: 50.56%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(85), 180)\n",
      "訓練周期: 54 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.70\t訓練正確率: 49.77%\t校驗正確率: 47.22%\n",
      "(tensor(76), 180)\n",
      "訓練周期: 55 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.74\tval Loss: 0.70\t訓練正確率: 31.25%\t校驗正確率: 42.22%\n",
      "(tensor(84), 180)\n",
      "訓練周期: 55 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 46.88%\t校驗正確率: 46.67%\n",
      "(tensor(90), 180)\n",
      "訓練周期: 55 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 49.55%\t校驗正確率: 50.00%\n",
      "(tensor(89), 180)\n",
      "訓練周期: 55 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 48.79%\t校驗正確率: 49.44%\n",
      "(tensor(89), 180)\n",
      "訓練周期: 55 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 47.94%\t校驗正確率: 49.44%\n",
      "(tensor(80), 180)\n",
      "訓練周期: 56 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.78\tval Loss: 0.70\t訓練正確率: 56.25%\t校驗正確率: 44.44%\n",
      "(tensor(89), 180)\n",
      "訓練周期: 56 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.71\tval Loss: 0.70\t訓練正確率: 47.44%\t校驗正確率: 49.44%\n",
      "(tensor(99), 180)\n",
      "訓練周期: 56 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 47.77%\t校驗正確率: 55.00%\n",
      "(tensor(94), 180)\n",
      "訓練周期: 56 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 48.59%\t校驗正確率: 52.22%\n",
      "(tensor(83), 180)\n",
      "訓練周期: 56 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 48.70%\t校驗正確率: 46.11%\n",
      "(tensor(91), 180)\n",
      "訓練周期: 57 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.73\tval Loss: 0.70\t訓練正確率: 56.25%\t校驗正確率: 50.56%\n",
      "(tensor(86), 180)\n",
      "訓練周期: 57 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 49.72%\t校驗正確率: 47.78%\n",
      "(tensor(81), 180)\n",
      "訓練周期: 57 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 49.26%\t校驗正確率: 45.00%\n",
      "(tensor(81), 180)\n",
      "訓練周期: 57 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.71\t訓練正確率: 50.10%\t校驗正確率: 45.00%\n",
      "(tensor(99), 180)\n",
      "訓練周期: 57 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 50.99%\t校驗正確率: 55.00%\n",
      "(tensor(87), 180)\n",
      "訓練周期: 58 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.74\tval Loss: 0.70\t訓練正確率: 53.12%\t校驗正確率: 48.33%\n",
      "(tensor(92), 180)\n",
      "訓練周期: 58 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 50.85%\t校驗正確率: 51.11%\n",
      "(tensor(71), 180)\n",
      "訓練周期: 58 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.71\t訓練正確率: 50.60%\t校驗正確率: 39.44%\n",
      "(tensor(85), 180)\n",
      "訓練周期: 58 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.71\t訓練正確率: 50.60%\t校驗正確率: 47.22%\n",
      "(tensor(103), 180)\n",
      "訓練周期: 58 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 50.38%\t校驗正確率: 57.22%\n",
      "(tensor(83), 180)\n",
      "訓練周期: 59 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.67\tval Loss: 0.70\t訓練正確率: 53.12%\t校驗正確率: 46.11%\n",
      "(tensor(87), 180)\n",
      "訓練周期: 59 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 49.43%\t校驗正確率: 48.33%\n",
      "(tensor(98), 180)\n",
      "訓練周期: 59 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.69\t訓練正確率: 50.15%\t校驗正確率: 54.44%\n",
      "(tensor(91), 180)\n",
      "訓練周期: 59 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.69\t訓練正確率: 50.30%\t校驗正確率: 50.56%\n",
      "(tensor(90), 180)\n",
      "訓練周期: 59 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 50.46%\t校驗正確率: 50.00%\n",
      "(tensor(90), 180)\n",
      "訓練周期: 60 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.66\tval Loss: 0.69\t訓練正確率: 53.12%\t校驗正確率: 50.00%\n",
      "(tensor(76), 180)\n",
      "訓練周期: 60 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.70\t訓練正確率: 51.70%\t校驗正確率: 42.22%\n",
      "(tensor(88), 180)\n",
      "訓練周期: 60 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.70\t訓練正確率: 51.79%\t校驗正確率: 48.89%\n",
      "(tensor(79), 180)\n",
      "訓練周期: 60 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.71\t訓練正確率: 50.40%\t校驗正確率: 43.89%\n",
      "(tensor(81), 180)\n",
      "訓練周期: 60 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.70\t訓練正確率: 49.62%\t校驗正確率: 45.00%\n",
      "(tensor(85), 180)\n",
      "訓練周期: 61 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.78\tval Loss: 0.70\t訓練正確率: 50.00%\t校驗正確率: 47.22%\n",
      "(tensor(88), 180)\n",
      "訓練周期: 61 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 51.42%\t校驗正確率: 48.89%\n",
      "(tensor(95), 180)\n",
      "訓練周期: 61 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 50.00%\t校驗正確率: 52.78%\n",
      "(tensor(98), 180)\n",
      "訓練周期: 61 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 48.99%\t校驗正確率: 54.44%\n",
      "(tensor(90), 180)\n",
      "訓練周期: 61 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 49.09%\t校驗正確率: 50.00%\n",
      "(tensor(88), 180)\n",
      "訓練周期: 62 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.82\tval Loss: 0.70\t訓練正確率: 31.25%\t校驗正確率: 48.89%\n",
      "(tensor(95), 180)\n",
      "訓練周期: 62 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 51.70%\t校驗正確率: 52.78%\n",
      "(tensor(84), 180)\n",
      "訓練周期: 62 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 51.49%\t校驗正確率: 46.67%\n",
      "(tensor(93), 180)\n",
      "訓練周期: 62 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 51.01%\t校驗正確率: 51.67%\n",
      "(tensor(97), 180)\n",
      "訓練周期: 62 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 50.84%\t校驗正確率: 53.89%\n",
      "(tensor(86), 180)\n",
      "訓練周期: 63 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.72\tval Loss: 0.69\t訓練正確率: 50.00%\t校驗正確率: 47.78%\n",
      "(tensor(91), 180)\n",
      "訓練周期: 63 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 46.02%\t校驗正確率: 50.56%\n",
      "(tensor(91), 180)\n",
      "訓練周期: 63 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.70\t訓練正確率: 49.40%\t校驗正確率: 50.56%\n",
      "(tensor(84), 180)\n",
      "訓練周期: 63 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.70\t訓練正確率: 49.40%\t校驗正確率: 46.67%\n",
      "(tensor(86), 180)\n",
      "訓練周期: 63 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.70\t訓練正確率: 50.91%\t校驗正確率: 47.78%\n",
      "(tensor(77), 180)\n",
      "訓練周期: 64 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.70\t訓練正確率: 56.25%\t校驗正確率: 42.78%\n",
      "(tensor(89), 180)\n",
      "訓練周期: 64 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.70\t訓練正確率: 55.40%\t校驗正確率: 49.44%\n",
      "(tensor(92), 180)\n",
      "訓練周期: 64 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.70\t訓練正確率: 52.38%\t校驗正確率: 51.11%\n",
      "(tensor(81), 180)\n",
      "訓練周期: 64 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.71\t訓練正確率: 51.31%\t校驗正確率: 45.00%\n",
      "(tensor(82), 180)\n",
      "訓練周期: 64 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 50.23%\t校驗正確率: 45.56%\n",
      "(tensor(100), 180)\n",
      "訓練周期: 65 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.76\tval Loss: 0.69\t訓練正確率: 43.75%\t校驗正確率: 55.56%\n",
      "(tensor(94), 180)\n",
      "訓練周期: 65 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 52.27%\t校驗正確率: 52.22%\n",
      "(tensor(98), 180)\n",
      "訓練周期: 65 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.69\t訓練正確率: 53.87%\t校驗正確率: 54.44%\n",
      "(tensor(92), 180)\n",
      "訓練周期: 65 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 52.42%\t校驗正確率: 51.11%\n",
      "(tensor(91), 180)\n",
      "訓練周期: 65 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 51.60%\t校驗正確率: 50.56%\n",
      "(tensor(94), 180)\n",
      "訓練周期: 66 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.67\tval Loss: 0.69\t訓練正確率: 59.38%\t校驗正確率: 52.22%\n",
      "(tensor(90), 180)\n",
      "訓練周期: 66 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.70\t訓練正確率: 53.98%\t校驗正確率: 50.00%\n",
      "(tensor(97), 180)\n",
      "訓練周期: 66 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.69\t訓練正確率: 51.34%\t校驗正確率: 53.89%\n",
      "(tensor(88), 180)\n",
      "訓練周期: 66 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 49.40%\t校驗正確率: 48.89%\n",
      "(tensor(100), 180)\n",
      "訓練周期: 66 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 49.77%\t校驗正確率: 55.56%\n",
      "(tensor(84), 180)\n",
      "訓練周期: 67 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.73\tval Loss: 0.69\t訓練正確率: 56.25%\t校驗正確率: 46.67%\n",
      "(tensor(92), 180)\n",
      "訓練周期: 67 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 51.99%\t校驗正確率: 51.11%\n",
      "(tensor(91), 180)\n",
      "訓練周期: 67 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 48.81%\t校驗正確率: 50.56%\n",
      "(tensor(94), 180)\n",
      "訓練周期: 67 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 48.69%\t校驗正確率: 52.22%\n",
      "(tensor(87), 180)\n",
      "訓練周期: 67 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 49.01%\t校驗正確率: 48.33%\n",
      "(tensor(77), 180)\n",
      "訓練周期: 68 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.71\t訓練正確率: 46.88%\t校驗正確率: 42.78%\n",
      "(tensor(91), 180)\n",
      "訓練周期: 68 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 52.27%\t校驗正確率: 50.56%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(87), 180)\n",
      "訓練周期: 68 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 50.15%\t校驗正確率: 48.33%\n",
      "(tensor(85), 180)\n",
      "訓練周期: 68 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 49.60%\t校驗正確率: 47.22%\n",
      "(tensor(89), 180)\n",
      "訓練周期: 68 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 49.92%\t校驗正確率: 49.44%\n",
      "(tensor(96), 180)\n",
      "訓練周期: 69 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.77\tval Loss: 0.69\t訓練正確率: 37.50%\t校驗正確率: 53.33%\n",
      "(tensor(87), 180)\n",
      "訓練周期: 69 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 48.30%\t校驗正確率: 48.33%\n",
      "(tensor(93), 180)\n",
      "訓練周期: 69 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 48.96%\t校驗正確率: 51.67%\n",
      "(tensor(102), 180)\n",
      "訓練周期: 69 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 49.40%\t校驗正確率: 56.67%\n",
      "(tensor(80), 180)\n",
      "訓練周期: 69 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 49.77%\t校驗正確率: 44.44%\n",
      "(tensor(90), 180)\n",
      "訓練周期: 70 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.74\tval Loss: 0.70\t訓練正確率: 46.88%\t校驗正確率: 50.00%\n",
      "(tensor(89), 180)\n",
      "訓練周期: 70 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 51.70%\t校驗正確率: 49.44%\n",
      "(tensor(90), 180)\n",
      "訓練周期: 70 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 50.89%\t校驗正確率: 50.00%\n",
      "(tensor(84), 180)\n",
      "訓練周期: 70 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 50.91%\t校驗正確率: 46.67%\n",
      "(tensor(100), 180)\n",
      "訓練周期: 70 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 50.46%\t校驗正確率: 55.56%\n",
      "(tensor(101), 180)\n",
      "訓練周期: 71 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.78\tval Loss: 0.69\t訓練正確率: 34.38%\t校驗正確率: 56.11%\n",
      "(tensor(94), 180)\n",
      "訓練周期: 71 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.71\tval Loss: 0.69\t訓練正確率: 46.88%\t校驗正確率: 52.22%\n",
      "(tensor(93), 180)\n",
      "訓練周期: 71 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 48.07%\t校驗正確率: 51.67%\n",
      "(tensor(86), 180)\n",
      "訓練周期: 71 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 48.19%\t校驗正確率: 47.78%\n",
      "(tensor(95), 180)\n",
      "訓練周期: 71 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 48.93%\t校驗正確率: 52.78%\n",
      "(tensor(93), 180)\n",
      "訓練周期: 72 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.70\t訓練正確率: 50.00%\t校驗正確率: 51.67%\n",
      "(tensor(85), 180)\n",
      "訓練周期: 72 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 49.43%\t校驗正確率: 47.22%\n",
      "(tensor(101), 180)\n",
      "訓練周期: 72 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 49.11%\t校驗正確率: 56.11%\n",
      "(tensor(83), 180)\n",
      "訓練周期: 72 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.70\t訓練正確率: 50.20%\t校驗正確率: 46.11%\n",
      "(tensor(93), 180)\n",
      "訓練周期: 72 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.69\t訓練正確率: 50.99%\t校驗正確率: 51.67%\n",
      "(tensor(87), 180)\n",
      "訓練周期: 73 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.75\tval Loss: 0.70\t訓練正確率: 50.00%\t校驗正確率: 48.33%\n",
      "(tensor(91), 180)\n",
      "訓練周期: 73 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 51.14%\t校驗正確率: 50.56%\n",
      "(tensor(90), 180)\n",
      "訓練周期: 73 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 50.45%\t校驗正確率: 50.00%\n",
      "(tensor(84), 180)\n",
      "訓練周期: 73 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 49.19%\t校驗正確率: 46.67%\n",
      "(tensor(97), 180)\n",
      "訓練周期: 73 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 48.93%\t校驗正確率: 53.89%\n",
      "(tensor(104), 180)\n",
      "訓練周期: 74 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.75\tval Loss: 0.69\t訓練正確率: 46.88%\t校驗正確率: 57.78%\n",
      "(tensor(103), 180)\n",
      "訓練周期: 74 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 49.15%\t校驗正確率: 57.22%\n",
      "(tensor(90), 180)\n",
      "訓練周期: 74 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 49.70%\t校驗正確率: 50.00%\n",
      "(tensor(81), 180)\n",
      "訓練周期: 74 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 50.50%\t校驗正確率: 45.00%\n",
      "(tensor(92), 180)\n",
      "訓練周期: 74 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 50.76%\t校驗正確率: 51.11%\n",
      "(tensor(89), 180)\n",
      "訓練周期: 75 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.81\tval Loss: 0.69\t訓練正確率: 34.38%\t校驗正確率: 49.44%\n",
      "(tensor(87), 180)\n",
      "訓練周期: 75 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 52.27%\t校驗正確率: 48.33%\n",
      "(tensor(86), 180)\n",
      "訓練周期: 75 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 53.27%\t校驗正確率: 47.78%\n",
      "(tensor(93), 180)\n",
      "訓練周期: 75 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 52.62%\t校驗正確率: 51.67%\n",
      "(tensor(95), 180)\n",
      "訓練周期: 75 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 51.37%\t校驗正確率: 52.78%\n",
      "(tensor(93), 180)\n",
      "訓練周期: 76 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.73\tval Loss: 0.69\t訓練正確率: 40.62%\t校驗正確率: 51.67%\n",
      "(tensor(89), 180)\n",
      "訓練周期: 76 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 48.01%\t校驗正確率: 49.44%\n",
      "(tensor(96), 180)\n",
      "訓練周期: 76 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 47.77%\t校驗正確率: 53.33%\n",
      "(tensor(88), 180)\n",
      "訓練周期: 76 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 47.18%\t校驗正確率: 48.89%\n",
      "(tensor(94), 180)\n",
      "訓練周期: 76 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 47.79%\t校驗正確率: 52.22%\n",
      "(tensor(89), 180)\n",
      "訓練周期: 77 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.71\tval Loss: 0.69\t訓練正確率: 56.25%\t校驗正確率: 49.44%\n",
      "(tensor(91), 180)\n",
      "訓練周期: 77 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 49.15%\t校驗正確率: 50.56%\n",
      "(tensor(90), 180)\n",
      "訓練周期: 77 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 49.85%\t校驗正確率: 50.00%\n",
      "(tensor(99), 180)\n",
      "訓練周期: 77 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 49.09%\t校驗正確率: 55.00%\n",
      "(tensor(89), 180)\n",
      "訓練周期: 77 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 49.70%\t校驗正確率: 49.44%\n",
      "(tensor(89), 180)\n",
      "訓練周期: 78 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.73\tval Loss: 0.70\t訓練正確率: 37.50%\t校驗正確率: 49.44%\n",
      "(tensor(88), 180)\n",
      "訓練周期: 78 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 48.58%\t校驗正確率: 48.89%\n",
      "(tensor(89), 180)\n",
      "訓練周期: 78 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 47.02%\t校驗正確率: 49.44%\n",
      "(tensor(87), 180)\n",
      "訓練周期: 78 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 48.89%\t校驗正確率: 48.33%\n",
      "(tensor(93), 180)\n",
      "訓練周期: 78 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 48.86%\t校驗正確率: 51.67%\n",
      "(tensor(93), 180)\n",
      "訓練周期: 79 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.74\tval Loss: 0.69\t訓練正確率: 46.88%\t校驗正確率: 51.67%\n",
      "(tensor(90), 180)\n",
      "訓練周期: 79 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 54.55%\t校驗正確率: 50.00%\n",
      "(tensor(91), 180)\n",
      "訓練周期: 79 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 49.70%\t校驗正確率: 50.56%\n",
      "(tensor(82), 180)\n",
      "訓練周期: 79 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 50.10%\t校驗正確率: 45.56%\n",
      "(tensor(85), 180)\n",
      "訓練周期: 79 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.71\t訓練正確率: 50.38%\t校驗正確率: 47.22%\n",
      "(tensor(95), 180)\n",
      "訓練周期: 80 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.68\tval Loss: 0.69\t訓練正確率: 50.00%\t校驗正確率: 52.78%\n",
      "(tensor(93), 180)\n",
      "訓練周期: 80 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.71\t訓練正確率: 50.28%\t校驗正確率: 51.67%\n",
      "(tensor(93), 180)\n",
      "訓練周期: 80 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 50.15%\t校驗正確率: 51.67%\n",
      "(tensor(78), 180)\n",
      "訓練周期: 80 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 50.20%\t校驗正確率: 43.33%\n",
      "(tensor(92), 180)\n",
      "訓練周期: 80 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 50.08%\t校驗正確率: 51.11%\n",
      "(tensor(95), 180)\n",
      "訓練周期: 81 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.66\tval Loss: 0.70\t訓練正確率: 62.50%\t校驗正確率: 52.78%\n",
      "(tensor(87), 180)\n",
      "訓練周期: 81 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.70\t訓練正確率: 49.72%\t校驗正確率: 48.33%\n",
      "(tensor(86), 180)\n",
      "訓練周期: 81 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.70\t訓練正確率: 49.85%\t校驗正確率: 47.78%\n",
      "(tensor(99), 180)\n",
      "訓練周期: 81 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.69\t訓練正確率: 50.00%\t校驗正確率: 55.00%\n",
      "(tensor(96), 180)\n",
      "訓練周期: 81 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.69\t訓練正確率: 50.69%\t校驗正確率: 53.33%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(92), 180)\n",
      "訓練周期: 82 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.76\tval Loss: 0.69\t訓練正確率: 46.88%\t校驗正確率: 51.11%\n",
      "(tensor(80), 180)\n",
      "訓練周期: 82 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 48.86%\t校驗正確率: 44.44%\n",
      "(tensor(82), 180)\n",
      "訓練周期: 82 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 50.60%\t校驗正確率: 45.56%\n",
      "(tensor(82), 180)\n",
      "訓練周期: 82 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 50.40%\t校驗正確率: 45.56%\n",
      "(tensor(100), 180)\n",
      "訓練周期: 82 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 49.77%\t校驗正確率: 55.56%\n",
      "(tensor(100), 180)\n",
      "訓練周期: 83 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.69\t訓練正確率: 53.12%\t校驗正確率: 55.56%\n",
      "(tensor(104), 180)\n",
      "訓練周期: 83 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.69\t訓練正確率: 51.70%\t校驗正確率: 57.78%\n",
      "(tensor(88), 180)\n",
      "訓練周期: 83 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.70\t訓練正確率: 51.79%\t校驗正確率: 48.89%\n",
      "(tensor(92), 180)\n",
      "訓練周期: 83 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.69\t訓練正確率: 50.81%\t校驗正確率: 51.11%\n",
      "(tensor(85), 180)\n",
      "訓練周期: 83 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.70\t訓練正確率: 49.54%\t校驗正確率: 47.22%\n",
      "(tensor(90), 180)\n",
      "訓練周期: 84 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.78\tval Loss: 0.70\t訓練正確率: 40.62%\t校驗正確率: 50.00%\n",
      "(tensor(91), 180)\n",
      "訓練周期: 84 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 49.15%\t校驗正確率: 50.56%\n",
      "(tensor(82), 180)\n",
      "訓練周期: 84 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 46.88%\t校驗正確率: 45.56%\n",
      "(tensor(90), 180)\n",
      "訓練周期: 84 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 47.18%\t校驗正確率: 50.00%\n",
      "(tensor(95), 180)\n",
      "訓練周期: 84 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 48.55%\t校驗正確率: 52.78%\n",
      "(tensor(89), 180)\n",
      "訓練周期: 85 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.67\tval Loss: 0.70\t訓練正確率: 53.12%\t校驗正確率: 49.44%\n",
      "(tensor(101), 180)\n",
      "訓練周期: 85 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.70\t訓練正確率: 47.73%\t校驗正確率: 56.11%\n",
      "(tensor(84), 180)\n",
      "訓練周期: 85 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 47.92%\t校驗正確率: 46.67%\n",
      "(tensor(92), 180)\n",
      "訓練周期: 85 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 47.58%\t校驗正確率: 51.11%\n",
      "(tensor(99), 180)\n",
      "訓練周期: 85 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 48.09%\t校驗正確率: 55.00%\n",
      "(tensor(88), 180)\n",
      "訓練周期: 86 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.71\tval Loss: 0.70\t訓練正確率: 43.75%\t校驗正確率: 48.89%\n",
      "(tensor(90), 180)\n",
      "訓練周期: 86 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 50.85%\t校驗正確率: 50.00%\n",
      "(tensor(100), 180)\n",
      "訓練周期: 86 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 51.34%\t校驗正確率: 55.56%\n",
      "(tensor(79), 180)\n",
      "訓練周期: 86 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 50.91%\t校驗正確率: 43.89%\n",
      "(tensor(93), 180)\n",
      "訓練周期: 86 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 49.24%\t校驗正確率: 51.67%\n",
      "(tensor(90), 180)\n",
      "訓練周期: 87 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.71\tval Loss: 0.69\t訓練正確率: 53.12%\t校驗正確率: 50.00%\n",
      "(tensor(87), 180)\n",
      "訓練周期: 87 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 47.16%\t校驗正確率: 48.33%\n",
      "(tensor(94), 180)\n",
      "訓練周期: 87 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 46.73%\t校驗正確率: 52.22%\n",
      "(tensor(89), 180)\n",
      "訓練周期: 87 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 47.48%\t校驗正確率: 49.44%\n",
      "(tensor(91), 180)\n",
      "訓練周期: 87 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 47.71%\t校驗正確率: 50.56%\n",
      "(tensor(86), 180)\n",
      "訓練周期: 88 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.65\tval Loss: 0.70\t訓練正確率: 62.50%\t校驗正確率: 47.78%\n",
      "(tensor(99), 180)\n",
      "訓練周期: 88 [320/1802 (22%)]\tTotal Loss: 0.70\ttraining Loss: 0.69\tval Loss: 0.69\t訓練正確率: 51.70%\t校驗正確率: 55.00%\n",
      "(tensor(90), 180)\n",
      "訓練周期: 88 [640/1802 (43%)]\tTotal Loss: 0.70\ttraining Loss: 0.69\tval Loss: 0.69\t訓練正確率: 50.74%\t校驗正確率: 50.00%\n",
      "(tensor(87), 180)\n",
      "訓練周期: 88 [960/1802 (65%)]\tTotal Loss: 0.70\ttraining Loss: 0.69\tval Loss: 0.70\t訓練正確率: 51.01%\t校驗正確率: 48.33%\n",
      "(tensor(92), 180)\n",
      "訓練周期: 88 [1280/1802 (87%)]\tTotal Loss: 0.70\ttraining Loss: 0.69\tval Loss: 0.70\t訓練正確率: 50.61%\t校驗正確率: 51.11%\n",
      "(tensor(101), 180)\n",
      "訓練周期: 89 [0/1802 (0%)]\tTotal Loss: 0.70\ttraining Loss: 0.74\tval Loss: 0.69\t訓練正確率: 53.12%\t校驗正確率: 56.11%\n",
      "(tensor(95), 180)\n",
      "訓練周期: 89 [320/1802 (22%)]\tTotal Loss: 0.70\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 48.58%\t校驗正確率: 52.78%\n",
      "(tensor(98), 180)\n",
      "訓練周期: 89 [640/1802 (43%)]\tTotal Loss: 0.70\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 48.66%\t校驗正確率: 54.44%\n",
      "(tensor(89), 180)\n",
      "訓練周期: 89 [960/1802 (65%)]\tTotal Loss: 0.70\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 49.40%\t校驗正確率: 49.44%\n",
      "(tensor(97), 180)\n",
      "訓練周期: 89 [1280/1802 (87%)]\tTotal Loss: 0.70\ttraining Loss: 0.70\tval Loss: 0.68\t訓練正確率: 50.08%\t校驗正確率: 53.89%\n",
      "(tensor(85), 180)\n",
      "訓練周期: 90 [0/1802 (0%)]\tTotal Loss: 0.70\ttraining Loss: 0.72\tval Loss: 0.69\t訓練正確率: 50.00%\t校驗正確率: 47.22%\n",
      "(tensor(91), 180)\n",
      "訓練周期: 90 [320/1802 (22%)]\tTotal Loss: 0.70\ttraining Loss: 0.69\tval Loss: 0.71\t訓練正確率: 54.83%\t校驗正確率: 50.56%\n",
      "(tensor(100), 180)\n",
      "訓練周期: 90 [640/1802 (43%)]\tTotal Loss: 0.70\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 48.96%\t校驗正確率: 55.56%\n",
      "(tensor(80), 180)\n",
      "訓練周期: 90 [960/1802 (65%)]\tTotal Loss: 0.70\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 48.59%\t校驗正確率: 44.44%\n",
      "(tensor(92), 180)\n",
      "訓練周期: 90 [1280/1802 (87%)]\tTotal Loss: 0.70\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 48.09%\t校驗正確率: 51.11%\n",
      "(tensor(104), 180)\n",
      "訓練周期: 91 [0/1802 (0%)]\tTotal Loss: 0.70\ttraining Loss: 0.71\tval Loss: 0.69\t訓練正確率: 53.12%\t校驗正確率: 57.78%\n",
      "(tensor(95), 180)\n",
      "訓練周期: 91 [320/1802 (22%)]\tTotal Loss: 0.70\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 44.03%\t校驗正確率: 52.78%\n",
      "(tensor(96), 180)\n",
      "訓練周期: 91 [640/1802 (43%)]\tTotal Loss: 0.70\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 46.43%\t校驗正確率: 53.33%\n",
      "(tensor(89), 180)\n",
      "訓練周期: 91 [960/1802 (65%)]\tTotal Loss: 0.70\ttraining Loss: 0.69\tval Loss: 0.70\t訓練正確率: 49.80%\t校驗正確率: 49.44%\n",
      "(tensor(96), 180)\n",
      "訓練周期: 91 [1280/1802 (87%)]\tTotal Loss: 0.70\ttraining Loss: 0.69\tval Loss: 0.70\t訓練正確率: 49.70%\t校驗正確率: 53.33%\n",
      "(tensor(96), 180)\n",
      "訓練周期: 92 [0/1802 (0%)]\tTotal Loss: 0.70\ttraining Loss: 0.64\tval Loss: 0.69\t訓練正確率: 71.88%\t校驗正確率: 53.33%\n",
      "(tensor(92), 180)\n",
      "訓練周期: 92 [320/1802 (22%)]\tTotal Loss: 0.70\ttraining Loss: 0.69\tval Loss: 0.70\t訓練正確率: 51.99%\t校驗正確率: 51.11%\n",
      "(tensor(97), 180)\n",
      "訓練周期: 92 [640/1802 (43%)]\tTotal Loss: 0.70\ttraining Loss: 0.69\tval Loss: 0.69\t訓練正確率: 51.79%\t校驗正確率: 53.89%\n",
      "(tensor(83), 180)\n",
      "訓練周期: 92 [960/1802 (65%)]\tTotal Loss: 0.70\ttraining Loss: 0.69\tval Loss: 0.70\t訓練正確率: 51.51%\t校驗正確率: 46.11%\n",
      "(tensor(81), 180)\n",
      "訓練周期: 92 [1280/1802 (87%)]\tTotal Loss: 0.70\ttraining Loss: 0.69\tval Loss: 0.70\t訓練正確率: 51.37%\t校驗正確率: 45.00%\n",
      "(tensor(102), 180)\n",
      "訓練周期: 93 [0/1802 (0%)]\tTotal Loss: 0.70\ttraining Loss: 0.71\tval Loss: 0.70\t訓練正確率: 56.25%\t校驗正確率: 56.67%\n",
      "(tensor(95), 180)\n",
      "訓練周期: 93 [320/1802 (22%)]\tTotal Loss: 0.70\ttraining Loss: 0.69\tval Loss: 0.69\t訓練正確率: 51.42%\t校驗正確率: 52.78%\n",
      "(tensor(89), 180)\n",
      "訓練周期: 93 [640/1802 (43%)]\tTotal Loss: 0.70\ttraining Loss: 0.69\tval Loss: 0.70\t訓練正確率: 52.08%\t校驗正確率: 49.44%\n",
      "(tensor(93), 180)\n",
      "訓練周期: 93 [960/1802 (65%)]\tTotal Loss: 0.70\ttraining Loss: 0.69\tval Loss: 0.69\t訓練正確率: 51.51%\t校驗正確率: 51.67%\n",
      "(tensor(83), 180)\n",
      "訓練周期: 93 [1280/1802 (87%)]\tTotal Loss: 0.70\ttraining Loss: 0.69\tval Loss: 0.70\t訓練正確率: 50.61%\t校驗正確率: 46.11%\n",
      "(tensor(81), 180)\n",
      "訓練周期: 94 [0/1802 (0%)]\tTotal Loss: 0.70\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 50.00%\t校驗正確率: 45.00%\n",
      "(tensor(90), 180)\n",
      "訓練周期: 94 [320/1802 (22%)]\tTotal Loss: 0.70\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 50.28%\t校驗正確率: 50.00%\n",
      "(tensor(85), 180)\n",
      "訓練周期: 94 [640/1802 (43%)]\tTotal Loss: 0.70\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 49.70%\t校驗正確率: 47.22%\n",
      "(tensor(86), 180)\n",
      "訓練周期: 94 [960/1802 (65%)]\tTotal Loss: 0.70\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 48.99%\t校驗正確率: 47.78%\n",
      "(tensor(92), 180)\n",
      "訓練周期: 94 [1280/1802 (87%)]\tTotal Loss: 0.70\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 48.93%\t校驗正確率: 51.11%\n",
      "(tensor(88), 180)\n",
      "訓練周期: 95 [0/1802 (0%)]\tTotal Loss: 0.70\ttraining Loss: 0.64\tval Loss: 0.70\t訓練正確率: 59.38%\t校驗正確率: 48.89%\n",
      "(tensor(89), 180)\n",
      "訓練周期: 95 [320/1802 (22%)]\tTotal Loss: 0.70\ttraining Loss: 0.69\tval Loss: 0.70\t訓練正確率: 53.12%\t校驗正確率: 49.44%\n",
      "(tensor(88), 180)\n",
      "訓練周期: 95 [640/1802 (43%)]\tTotal Loss: 0.70\ttraining Loss: 0.69\tval Loss: 0.70\t訓練正確率: 52.23%\t校驗正確率: 48.89%\n",
      "(tensor(93), 180)\n",
      "訓練周期: 95 [960/1802 (65%)]\tTotal Loss: 0.70\ttraining Loss: 0.69\tval Loss: 0.69\t訓練正確率: 52.72%\t校驗正確率: 51.67%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(87), 180)\n",
      "訓練周期: 95 [1280/1802 (87%)]\tTotal Loss: 0.70\ttraining Loss: 0.69\tval Loss: 0.70\t訓練正確率: 51.83%\t校驗正確率: 48.33%\n",
      "(tensor(79), 180)\n",
      "訓練周期: 96 [0/1802 (0%)]\tTotal Loss: 0.70\ttraining Loss: 0.71\tval Loss: 0.70\t訓練正確率: 56.25%\t校驗正確率: 43.89%\n",
      "(tensor(91), 180)\n",
      "訓練周期: 96 [320/1802 (22%)]\tTotal Loss: 0.70\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 47.44%\t校驗正確率: 50.56%\n",
      "(tensor(90), 180)\n",
      "訓練周期: 96 [640/1802 (43%)]\tTotal Loss: 0.70\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 49.40%\t校驗正確率: 50.00%\n",
      "(tensor(88), 180)\n",
      "訓練周期: 96 [960/1802 (65%)]\tTotal Loss: 0.70\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 48.89%\t校驗正確率: 48.89%\n",
      "(tensor(77), 180)\n",
      "訓練周期: 96 [1280/1802 (87%)]\tTotal Loss: 0.70\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 48.86%\t校驗正確率: 42.78%\n",
      "(tensor(76), 180)\n",
      "訓練周期: 97 [0/1802 (0%)]\tTotal Loss: 0.70\ttraining Loss: 0.73\tval Loss: 0.70\t訓練正確率: 53.12%\t校驗正確率: 42.22%\n",
      "(tensor(84), 180)\n",
      "訓練周期: 97 [320/1802 (22%)]\tTotal Loss: 0.70\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 49.15%\t校驗正確率: 46.67%\n",
      "(tensor(85), 180)\n",
      "訓練周期: 97 [640/1802 (43%)]\tTotal Loss: 0.70\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 50.60%\t校驗正確率: 47.22%\n",
      "(tensor(86), 180)\n",
      "訓練周期: 97 [960/1802 (65%)]\tTotal Loss: 0.70\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 50.20%\t校驗正確率: 47.78%\n",
      "(tensor(92), 180)\n",
      "訓練周期: 97 [1280/1802 (87%)]\tTotal Loss: 0.70\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 49.16%\t校驗正確率: 51.11%\n",
      "(tensor(81), 180)\n",
      "訓練周期: 98 [0/1802 (0%)]\tTotal Loss: 0.70\ttraining Loss: 0.73\tval Loss: 0.70\t訓練正確率: 46.88%\t校驗正確率: 45.00%\n",
      "(tensor(90), 180)\n",
      "訓練周期: 98 [320/1802 (22%)]\tTotal Loss: 0.70\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 50.28%\t校驗正確率: 50.00%\n",
      "(tensor(81), 180)\n",
      "訓練周期: 98 [640/1802 (43%)]\tTotal Loss: 0.70\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 48.96%\t校驗正確率: 45.00%\n",
      "(tensor(93), 180)\n",
      "訓練周期: 98 [960/1802 (65%)]\tTotal Loss: 0.70\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 50.10%\t校驗正確率: 51.67%\n",
      "(tensor(93), 180)\n",
      "訓練周期: 98 [1280/1802 (87%)]\tTotal Loss: 0.70\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 50.38%\t校驗正確率: 51.67%\n",
      "(tensor(93), 180)\n",
      "訓練周期: 99 [0/1802 (0%)]\tTotal Loss: 0.70\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 59.38%\t校驗正確率: 51.67%\n",
      "(tensor(76), 180)\n",
      "訓練周期: 99 [320/1802 (22%)]\tTotal Loss: 0.70\ttraining Loss: 0.70\tval Loss: 0.71\t訓練正確率: 50.28%\t校驗正確率: 42.22%\n",
      "(tensor(82), 180)\n",
      "訓練周期: 99 [640/1802 (43%)]\tTotal Loss: 0.70\ttraining Loss: 0.70\tval Loss: 0.71\t訓練正確率: 48.96%\t校驗正確率: 45.56%\n",
      "(tensor(88), 180)\n",
      "訓練周期: 99 [960/1802 (65%)]\tTotal Loss: 0.70\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 47.38%\t校驗正確率: 48.89%\n",
      "(tensor(87), 180)\n",
      "訓練周期: 99 [1280/1802 (87%)]\tTotal Loss: 0.70\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 47.87%\t校驗正確率: 48.33%\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "record = []\n",
    "losses = []\n",
    "records = []\n",
    "for epoch in range(num_epochs):\n",
    "    train_losses = []\n",
    "    train_rights = []\n",
    "    model.train()\n",
    "    for batch_idx, train in enumerate(zip(train_loader_train, train_loader_labels)):\n",
    "        x, y = train\n",
    "        \n",
    "        \n",
    "        x = torch.tensor(x, requires_grad = True, dtype = torch.float)   # x 最後會被轉成 [0-1] 之間的數\n",
    "\n",
    "        y = torch.tensor(np.array([z for z in y ]), dtype = torch.long)  # 所以 y 必須是llong 而不是\n",
    "        \n",
    "        #np.array([z for z in y ]) 因為np.array只能轉一個值，若要list裡面全部的值，需改成這樣\n",
    "        \n",
    "        # 清空梯度\n",
    "        optimizer.zero_grad()\n",
    "        # 模型預測\n",
    "        predict = model(x)\n",
    "        # 計算損失函數\n",
    "        loss = criterion(predict, y)\n",
    "        # 將損失函數數值加入到列表中\n",
    "        train_losses.append(loss.data.numpy())\n",
    "        # 開始進行梯度反傳\n",
    "        loss.backward()\n",
    "        # 開始對參數進行一步優化\n",
    "        optimizer.step()\n",
    "        #計算準確率所需數值，返回數值為（正確樣例數，總樣本數）\n",
    "        right = rightness(predict, y)\n",
    "        #將計算結果裝到列表容器train_rights中\n",
    "        train_rights.append(right)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # 每隔200步，跑一下校驗數據集的數據，輸出臨時結果\n",
    "        if batch_idx % 10 == 0:\n",
    "        \n",
    "            losses.append(np.mean(train_losses))\n",
    "            model.eval()\n",
    "            val_losses = []\n",
    "            val_rights = []\n",
    "            # 在所有校驗數據集上實驗\n",
    "            with torch.no_grad():\n",
    "                \n",
    "                for j, val in enumerate(zip(validation_loader_test, validation_loader_labels)):\n",
    "                    x, y = val\n",
    "                    x = torch.tensor(x, requires_grad = True, dtype = torch.float)\n",
    "                    y = torch.tensor(np.array([z for z in y ]), dtype = torch.long)\n",
    "                    predict = model(x)\n",
    "                    # 調用rightness函數計算準確度\n",
    "                    right = rightness(predict, y)\n",
    "                    val_rights.append(right)\n",
    "                    loss = criterion(predict, y)\n",
    "                    val_losses.append(loss.data.numpy())\n",
    "\n",
    "\n",
    "\n",
    "                # 分別計算在目前已經計算過的測試數據集，以及全部校驗集上模型的表現：分類準確率\n",
    "                #train_r為一個二元組，分別記錄目前已經經歷過的所有訓練集中分類正確的數量和該集合中總的樣本數，\n",
    "                #train_r[0]/train_r[1]就是訓練集的分類準確度，同樣，val_r[0]/val_r[1]就是校驗集上的分類準確度\n",
    "                train_r = (sum([tup[0] for tup in train_rights]), sum([tup[1] for tup in train_rights]))\n",
    "                #val_r為一個二元組，分別記錄校驗集中分類正確的數量和該集合中總的樣本數\n",
    "                val_r = (sum([tup[0] for tup in val_rights]), sum([tup[1] for tup in val_rights]))\n",
    "                #打印準確率等數值，其中正確率為本訓練周期Epoch開始後到目前撮的正確率的平均值\n",
    "                print(val_r)\n",
    "                print('訓練周期: {} [{}/{} ({:.0f}%)]\\tTotal Loss: {:.2f}\\ttraining Loss: {:.2f}\\tval Loss: {:.2f}\\t訓練正確率: {:.2f}%\\t校驗正確率: {:.2f}%'.format(\n",
    "                    epoch, batch_idx * batch_size, len(dataset),\n",
    "                    100. * batch_idx / len(train_loader_train), \n",
    "                    np.mean(losses),\n",
    "                    np.mean(train_losses),\n",
    "                    np.mean(val_losses),\n",
    "                    100. * train_r[0].numpy() / train_r[1], \n",
    "                    100. * val_r[0].numpy() / val_r[1]))\n",
    "                #將準確率和權重等數值加載到容器中，以方便後續處理\n",
    "                record.append((100 - 100. * train_r[0] / train_r[1], 100 - 100. * val_r[0] / val_r[1]))\n",
    "                records.append([np.mean(train_losses), np.mean(val_losses), train_r, val_r, losses])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### label 2名稱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#繪制訓練過程的誤差曲線，校驗集和測試集上的錯誤率。\n",
    "plt.figure(figsize = (10, 7))\n",
    "plt.plot(record, label = 'train_acc') #record記載了每一個打印周期記錄的訓練和校驗數據集上的準確度\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Error rate')\n",
    "plt.legend()\n",
    "plt.ylim(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records.append([np.mean(train_losses), np.mean(val_losses), train_r, val_r, losses])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 繪制誤差曲線\n",
    "a = [i[0] for i in records]\n",
    "b = [i[1] for i in records]\n",
    "c = [i[2] for i in records]\n",
    "d = [i[3] for i in records]\n",
    "e = [i[4] for i in records]\n",
    "plt.plot(a, label = 'Train Loss')\n",
    "plt.plot(b, label = 'Valid Loss')\n",
    "plt.plot(c, label = 'Train Accuracy')\n",
    "plt.plot(d, label = 'Valid Accuracy')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss & Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,'bow.mdl')\n",
    "model = torch.load('bow.mdl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#在測試集上分批運行，並計算總的正確率\n",
    "vals = [] #記錄準確率所用列表\n",
    "\n",
    "#對測試數據集進行循環\n",
    "for data, target in zip(test_data, test_label):\n",
    "    data, target = torch.tensor(data, dtype = torch.float).view(1,-1), torch.tensor(np.array([target]), dtype = torch.long)\n",
    "    output = model(data) #將特征數據喂入網絡，得到分類的輸出\n",
    "    val = rightness(output, target) #獲得正確樣本數以及總樣本數\n",
    "    vals.append(val) #記錄結果\n",
    "\n",
    "#計算準確率\n",
    "rights = (sum([tup[0] for tup in vals]), sum([tup[1] for tup in vals]))\n",
    "right_rate = 1.0 * rights[0].data.numpy() / rights[1]\n",
    "right_rate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
