{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>[-2.89027214e-01 -4.38273013e-01 -3.22299331e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0</td>\n",
       "      <td>[-7.12146819e-01 -4.24583733e-01 -1.29917473e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>1</td>\n",
       "      <td>[-2.12954760e-01 -8.21731985e-02 -2.26242959e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>1</td>\n",
       "      <td>[-5.63706942e-02 -3.41074973e-01 -1.33537129e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>0</td>\n",
       "      <td>[-4.71603841e-01 -6.57357454e-01  1.23730779e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>1</td>\n",
       "      <td>[ 1.25624493e-01 -1.17772870e-01  2.84849796e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>1</td>\n",
       "      <td>[-2.85503119e-01 -2.00217754e-01 -7.87503868e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>1</td>\n",
       "      <td>[-1.12773709e-01 -4.28319186e-01 -1.97886527e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>1</td>\n",
       "      <td>[-1.75341040e-01  8.72757733e-02 -1.16240516e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>[-1.70210615e-01 -2.48357415e-01 -4.19242419e-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1802 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0                                                  1\n",
       "25   1  [-2.89027214e-01 -4.38273013e-01 -3.22299331e-...\n",
       "89   0  [-7.12146819e-01 -4.24583733e-01 -1.29917473e-...\n",
       "597  1  [-2.12954760e-01 -8.21731985e-02 -2.26242959e-...\n",
       "153  1  [-5.63706942e-02 -3.41074973e-01 -1.33537129e-...\n",
       "711  0  [-4.71603841e-01 -6.57357454e-01  1.23730779e-...\n",
       "..  ..                                                ...\n",
       "601  1  [ 1.25624493e-01 -1.17772870e-01  2.84849796e-...\n",
       "613  1  [-2.85503119e-01 -2.00217754e-01 -7.87503868e-...\n",
       "492  1  [-1.12773709e-01 -4.28319186e-01 -1.97886527e-...\n",
       "609  1  [-1.75341040e-01  8.72757733e-02 -1.16240516e-...\n",
       "12   0  [-1.70210615e-01 -2.48357415e-01 -4.19242419e-...\n",
       "\n",
       "[1802 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1024)\n",
    "pos_data = pd.read_csv(r'sentence_embedding_list.csv', header=None)\n",
    "neg_data = pd.read_csv(r'sentence_embedding_list_negative.csv', header=None)\n",
    "com_data = pos_data.append(neg_data)\n",
    "raw_data = shuffle(com_data)\n",
    "raw_data.to_csv('suffle.csv', encoding = 'utf-8', header = None, index = False)\n",
    "labels_dataset = raw_data[0]\n",
    "labels_dataset = labels_dataset.tolist()\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv(r'suffle.csv', header=None)\n",
    "dataset = []\n",
    "for data in raw[1].tolist() :\n",
    "    num = re.findall('[0-9e.-0-9+]+',data)\n",
    "    np_num = np.array([float(i) for i in num])\n",
    "    dataset.append(np_num) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=8)\n",
    "train, test = skf.split(dataset, labels_dataset)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for train, test in skf.split(dataset, labels_dataset):\n",
    "    print('Train: %s | test: %s' % (train, test))\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32  #一個撮（批次）的大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先，我們定義索引陣列indices，它相當於對所有dataset中數據的編碼\n",
    "# 然後定義索引indices_train表示測試級的索引，indices_val來表示校驗集數據的索引，indices_test表示測試集的索引\n",
    "indices = range(len(dataset))\n",
    "data_size = len(dataset) // 10\n",
    "indices_train = indices[2 * data_size :]\n",
    "indices_val = indices[: data_size]\n",
    "indices_test = indices[data_size : 2 * data_size]\n",
    "\n",
    "# 根據這些索引，構造三個數據集的SubsetRandomSampler採樣器，它會對索引進行採樣\n",
    "sampler_train = torch.utils.data.sampler.SubsetRandomSampler(indices_train)\n",
    "sampler_val = torch.utils.data.sampler.SubsetRandomSampler(indices_val)\n",
    "sampler_test = torch.utils.data.sampler.SubsetRandomSampler(indices_test)\n",
    "\n",
    "# 根據三個採樣器來定義加載器，注意將sampler_train、sampler_val和sampler_test分別賦值給了train_loader、validation_loader和test_loader\n",
    "#注意:labels集只需用相同定義的sampler就可以採樣\n",
    "\n",
    "train_loader_train = torch.utils.data.DataLoader(dataset= dataset, \n",
    "                                           batch_size= batch_size, \n",
    "                                           sampler = sampler_train)\n",
    "train_loader_labels = torch.utils.data.DataLoader(dataset= labels_dataset, \n",
    "                                           batch_size= batch_size, \n",
    "                                           sampler = sampler_train)\n",
    "\n",
    "validation_loader_test = torch.utils.data.DataLoader(dataset = dataset,\n",
    "                                                batch_size = batch_size,\n",
    "                                                sampler = sampler_val)\n",
    "validation_loader_labels = torch.utils.data.DataLoader(dataset =labels_dataset,\n",
    "                                                batch_size = batch_size,\n",
    "                                                sampler = sampler_val)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          sampler = sampler_test)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          sampler = sampler_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1442"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sampler_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2  #標簽的種類數\n",
    "num_epochs = 100  #訓練的總循環周期\n",
    "\n",
    "size = 768\n",
    "hidden1 = 100\n",
    "hidden2 = 100\n",
    "out = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, size, hidden1, hidden2, num_classes):\n",
    "        # 該函數在創建一個NN對象的時候，即調用如下語句：model=NN()，就會被調用\n",
    "        # 首先調用父類相應的構造函數\n",
    "        super(NN, self).__init__()\n",
    "        \n",
    "        # 其次構造NN需要用到的各個神經模塊。\n",
    "        '''注意，定義組件並沒有真正搭建這些組件，只是把基本建築磚塊先找好'''\n",
    "        \n",
    "        # 全連線層\n",
    "        self.fc1 = nn.Linear(size, hidden1)\n",
    "        self.fc2 = nn.Linear(hidden1, hidden2)\n",
    "        self.fc3 = nn.Linear(hidden2, num_classes) \n",
    "        \n",
    "        #BN\n",
    "        self.bn1 = nn.BatchNorm1d(hidden1)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden2)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = F.dropout(x, training  = self.training)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(self.bn2(x))\n",
    "        x = F.dropout(x, training  = self.training)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        x = F.log_softmax(x, dim = 1)#輸出層為log_softmax，即概率對數值log(p(x))。采用log_softmax可以使得後面的交叉熵計算更快\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN(\n",
      "  (fc1): Linear(in_features=768, out_features=100, bias=True)\n",
      "  (fc2): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (fc3): Linear(in_features=100, out_features=2, bias=True)\n",
      "  (bn1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NN(size, hidden1, hidden2, num_classes)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "引數:  [Parameter containing:\n",
      "tensor([[-0.0155, -0.0040,  0.0133,  ..., -0.0107, -0.0243, -0.0225],\n",
      "        [-0.0117,  0.0182, -0.0018,  ..., -0.0293,  0.0232, -0.0172],\n",
      "        [-0.0344,  0.0313, -0.0194,  ..., -0.0020,  0.0220, -0.0322],\n",
      "        ...,\n",
      "        [-0.0261, -0.0081, -0.0140,  ...,  0.0080,  0.0263, -0.0232],\n",
      "        [ 0.0252,  0.0156,  0.0067,  ...,  0.0114,  0.0248, -0.0108],\n",
      "        [-0.0112, -0.0182, -0.0244,  ...,  0.0333,  0.0208, -0.0037]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0069, -0.0108, -0.0270, -0.0338, -0.0323,  0.0059,  0.0319,  0.0064,\n",
      "         0.0259, -0.0031,  0.0068,  0.0319, -0.0304, -0.0189, -0.0337,  0.0025,\n",
      "         0.0087,  0.0280,  0.0201, -0.0244, -0.0131, -0.0186,  0.0247, -0.0306,\n",
      "        -0.0167,  0.0247, -0.0056,  0.0135,  0.0356, -0.0340, -0.0261,  0.0312,\n",
      "         0.0223, -0.0291, -0.0038, -0.0133,  0.0082,  0.0091, -0.0037, -0.0149,\n",
      "        -0.0027, -0.0055,  0.0091, -0.0304, -0.0230,  0.0345,  0.0122,  0.0028,\n",
      "         0.0155, -0.0068, -0.0149,  0.0261, -0.0146, -0.0085, -0.0163,  0.0352,\n",
      "         0.0216, -0.0044, -0.0221, -0.0211,  0.0091,  0.0182,  0.0041,  0.0237,\n",
      "         0.0262, -0.0067,  0.0197,  0.0092, -0.0232, -0.0008,  0.0173,  0.0302,\n",
      "        -0.0307, -0.0273,  0.0338, -0.0129, -0.0257,  0.0158,  0.0314, -0.0065,\n",
      "         0.0066, -0.0172, -0.0188,  0.0360, -0.0037,  0.0307, -0.0341,  0.0022,\n",
      "        -0.0236, -0.0148, -0.0273, -0.0241,  0.0289,  0.0307,  0.0105,  0.0221,\n",
      "        -0.0134,  0.0066, -0.0231, -0.0023], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0727, -0.0382, -0.0379,  ...,  0.0823, -0.0548, -0.0921],\n",
      "        [ 0.0252, -0.0501,  0.0391,  ..., -0.0208, -0.0745, -0.0081],\n",
      "        [-0.0443,  0.0428,  0.0441,  ..., -0.0237,  0.0796,  0.0218],\n",
      "        ...,\n",
      "        [-0.0500,  0.0841, -0.0560,  ...,  0.0959, -0.0375,  0.0967],\n",
      "        [ 0.0121, -0.0745, -0.0941,  ...,  0.0975,  0.0214, -0.0038],\n",
      "        [ 0.0687,  0.0149,  0.0945,  ..., -0.0420, -0.0707, -0.0027]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0884, -0.0547, -0.0579, -0.0601, -0.0777, -0.0814,  0.0975, -0.0975,\n",
      "        -0.0369,  0.0672, -0.0046, -0.0585,  0.0183, -0.0228,  0.0476, -0.0050,\n",
      "         0.0070, -0.0653,  0.0519,  0.0574,  0.0691, -0.0149, -0.0502,  0.0667,\n",
      "         0.0302,  0.0394, -0.0362,  0.0754,  0.0363, -0.0712,  0.0754, -0.0545,\n",
      "        -0.0196, -0.0121,  0.0195,  0.0064,  0.0005, -0.0410,  0.0614, -0.0238,\n",
      "         0.0169, -0.0443, -0.0155,  0.0502,  0.0099, -0.0229, -0.0373,  0.0589,\n",
      "         0.0815,  0.0747, -0.0517, -0.0438,  0.0338, -0.0367, -0.0644,  0.0146,\n",
      "         0.0694,  0.0422, -0.0855,  0.0051,  0.0306,  0.0686,  0.0522,  0.0158,\n",
      "        -0.0447, -0.0573, -0.0475, -0.0556,  0.0386,  0.0598,  0.0059,  0.0954,\n",
      "         0.0988, -0.0242, -0.0431,  0.0015, -0.0560, -0.0969, -0.0678, -0.0795,\n",
      "         0.0745, -0.0017,  0.0297,  0.0879, -0.0288,  0.0177, -0.0943, -0.0674,\n",
      "         0.0934,  0.0080,  0.0200, -0.0124,  0.0729, -0.0464,  0.0623,  0.0920,\n",
      "        -0.0273,  0.0508, -0.0075,  0.0785], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0896, -0.0557, -0.0505, -0.0947, -0.0064, -0.0444, -0.0444, -0.0049,\n",
      "         -0.0443, -0.0254,  0.0988, -0.0260, -0.0473,  0.0289, -0.0618, -0.0959,\n",
      "          0.0486, -0.0320, -0.0552,  0.0362, -0.0374,  0.0429, -0.0874, -0.0140,\n",
      "          0.0493, -0.0499,  0.0724,  0.0039, -0.0140,  0.0350,  0.0259, -0.0946,\n",
      "          0.0519,  0.0043,  0.0056,  0.0934,  0.0586, -0.0627,  0.0058,  0.0628,\n",
      "          0.0311, -0.0049,  0.0980,  0.0336,  0.0434, -0.0688,  0.0181,  0.0075,\n",
      "         -0.0247,  0.0013, -0.0423,  0.0473, -0.0154,  0.0934, -0.0498,  0.0333,\n",
      "          0.0070,  0.0305,  0.0674, -0.0516,  0.0120, -0.0264,  0.0141, -0.0396,\n",
      "          0.0695,  0.0480, -0.0598, -0.0687,  0.0894,  0.0735,  0.0273,  0.0538,\n",
      "         -0.0959,  0.0865,  0.0415, -0.0105, -0.0108,  0.0863, -0.0278,  0.0125,\n",
      "         -0.0511,  0.0883, -0.0336, -0.0292,  0.0177,  0.0517, -0.0864, -0.0945,\n",
      "         -0.0017,  0.0599, -0.0598,  0.0964,  0.0818, -0.0467,  0.0581,  0.0113,\n",
      "         -0.0557,  0.0049, -0.0914, -0.0767],\n",
      "        [ 0.0986,  0.0311,  0.0357,  0.0771, -0.0665,  0.0346, -0.0342,  0.0308,\n",
      "         -0.0758,  0.0068, -0.0818, -0.0472, -0.0787, -0.0980, -0.0512, -0.0346,\n",
      "          0.0828,  0.0547,  0.0867,  0.0315, -0.0677, -0.0514, -0.0937,  0.0438,\n",
      "         -0.0802,  0.0840, -0.0604, -0.0739,  0.0985,  0.0120,  0.0935,  0.0147,\n",
      "         -0.0356,  0.0282, -0.0870, -0.0589, -0.1000,  0.0286,  0.0280, -0.0879,\n",
      "         -0.0675, -0.0537, -0.0508,  0.0752, -0.0962,  0.0290, -0.0653, -0.0357,\n",
      "         -0.0199, -0.0864,  0.0423,  0.0566, -0.0605, -0.0774,  0.0689, -0.0988,\n",
      "         -0.0444,  0.0485, -0.0542,  0.0725, -0.0937,  0.0103,  0.0536,  0.0281,\n",
      "         -0.0703,  0.0776, -0.0427, -0.0413,  0.0792,  0.0400,  0.0298, -0.0016,\n",
      "          0.0776,  0.0463,  0.0590,  0.0260, -0.0681, -0.0736, -0.0909,  0.0332,\n",
      "         -0.0859,  0.0952,  0.0734, -0.0142, -0.0137,  0.0331, -0.0276, -0.0781,\n",
      "          0.0634, -0.0383, -0.0965, -0.0721, -0.0479,  0.0803,  0.0119, -0.0679,\n",
      "          0.0713,  0.0453, -0.0380, -0.0077]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0899, -0.0120], requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.], requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.], requires_grad=True)]\n",
      "第一個引數大小:  torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "params = list(model.parameters())\n",
    "print('引數: ', params)\n",
    "# conv1.weight\n",
    "print('第一個引數大小: ', params[-1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN(size, hidden1, hidden2, num_classes)\n",
    "\n",
    "# 損失函數為交叉熵\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# 優化算法為Adam，可以自動調節學習率\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
    "\n",
    "\n",
    "\n",
    "def rightness(predictions, labels):\n",
    "    \"\"\"计算预测错误率的函数，其中predictions是模型给出的一组预测结果，batch_size行num_classes列的矩阵，labels是数据之中的正确答案\"\"\"\n",
    "    pred = torch.max(predictions.data, 1)[1] # 对于任意一行（一个样本）的输出值的第1个维度，求最大，得到每一行的最大元素的下标\n",
    "    rights = pred.eq(labels.data.view_as(pred)).sum() #将下标与labels中包含的类别进行比较，并累计得到比较正确的数量\n",
    "    return rights, len(labels) #返回正确的数量和这一次一共比较了多少元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5468, -0.8646],\n",
       "        [-1.2829, -0.3247]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, data in enumerate(zip(train_loader_train, train_loader_labels)):\n",
    "    x, y = data\n",
    "    z = torch.tensor(x, requires_grad = True, dtype = torch.float) \n",
    "    \n",
    "model(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2533,  0.1856,  0.3003,  ..., -0.2644,  0.3201,  0.5865],\n",
      "        [-0.1071,  0.0285, -0.2822,  ...,  0.1530, -0.1541,  0.5235],\n",
      "        [-0.3505, -0.1567,  0.0972,  ...,  0.5291,  0.2423,  0.2224],\n",
      "        ...,\n",
      "        [-0.9522, -0.4808, -0.6104,  ..., -0.4280,  0.4121, -0.1257],\n",
      "        [-0.0512, -0.1326, -0.1711,  ..., -0.1748,  0.1237,  0.0227],\n",
      "        [-0.0658, -0.0026, -0.2920,  ..., -0.5041,  0.4575, -0.0334]],\n",
      "       dtype=torch.float64) tensor([1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "        1, 0, 1, 0, 0, 1, 0, 0])\n",
      "tensor([[-0.2569, -0.2388, -0.2662,  ..., -0.3022,  0.0228,  0.8991],\n",
      "        [-0.0481, -0.0033,  0.2663,  ...,  0.0056, -0.0894,  0.5069],\n",
      "        [ 0.0183, -0.3482, -0.3320,  ...,  0.0327,  0.1526,  0.4150],\n",
      "        ...,\n",
      "        [-0.7733, -0.1829,  0.0613,  ..., -0.1642,  0.4151,  0.7047],\n",
      "        [-0.2603,  0.1095,  0.0656,  ...,  0.0616, -0.0529,  0.5853],\n",
      "        [-0.1469, -0.3186, -0.1479,  ...,  0.4047,  0.2063,  0.6078]],\n",
      "       dtype=torch.float64) tensor([0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 1, 1, 1, 0, 0])\n",
      "tensor([[-0.2138, -0.3072, -0.0432,  ...,  0.2663,  0.0377,  0.7271],\n",
      "        [ 0.2357, -0.6819,  0.0313,  ...,  0.0672, -0.1873,  0.4315],\n",
      "        [-0.0710,  0.0610,  0.5924,  ...,  0.5420,  0.0207,  0.2299],\n",
      "        ...,\n",
      "        [-0.3253,  0.1004,  0.3457,  ..., -0.0009,  0.1670, -0.0583],\n",
      "        [ 0.0919, -0.4238,  0.0648,  ...,  0.2925, -0.0217,  0.4628],\n",
      "        [-0.2199,  0.0881, -0.6829,  ..., -0.2804,  0.0435,  0.6504]],\n",
      "       dtype=torch.float64) tensor([0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "        1, 1, 0, 1, 0, 0, 1, 0])\n",
      "tensor([[-0.4013, -0.1149, -0.1196,  ..., -0.3115,  0.0006,  0.4803],\n",
      "        [-0.2396,  0.2412, -0.5420,  ...,  0.2193,  0.0813,  0.5696],\n",
      "        [-0.3601, -0.2578, -0.0858,  ..., -0.0875, -0.0583, -0.0985],\n",
      "        ...,\n",
      "        [-0.1629, -0.0557, -0.5274,  ...,  0.2925, -0.0755,  0.4241],\n",
      "        [-0.5039, -0.2559,  0.2545,  ...,  0.1465,  0.1005,  0.3828],\n",
      "        [-0.5428, -0.4108, -0.4121,  ...,  0.2723,  0.0122,  0.2570]],\n",
      "       dtype=torch.float64) tensor([0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
      "        1, 0, 0, 0, 1, 1, 1, 0])\n",
      "tensor([[-0.1941, -0.0922,  0.1953,  ..., -0.6151,  0.4049,  0.3753],\n",
      "        [-0.1014,  0.1050,  0.4991,  ...,  0.0236, -0.0851,  0.4348],\n",
      "        [ 0.0049,  0.0385, -0.0785,  ..., -0.2003,  0.0316,  0.6547],\n",
      "        ...,\n",
      "        [-0.2918,  0.0449, -0.1786,  ..., -0.2373,  0.4775,  0.4095],\n",
      "        [-0.3949,  0.0848,  0.3192,  ...,  0.0295, -0.1630,  0.4651],\n",
      "        [-0.1625, -0.0592,  0.2260,  ..., -0.2099,  0.1359,  0.5550]],\n",
      "       dtype=torch.float64) tensor([1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0,\n",
      "        1, 1, 0, 0, 0, 0, 0, 1])\n",
      "tensor([[-0.1172,  0.0952,  0.0346,  ..., -0.0941, -0.1719,  0.3393],\n",
      "        [-0.3243, -0.5384, -0.1734,  ..., -0.3751,  0.1187,  0.3155],\n",
      "        [-0.4809, -0.0644, -0.1849,  ..., -0.0746,  0.0069,  0.3703],\n",
      "        ...,\n",
      "        [-0.1312, -0.3100, -0.3725,  ..., -0.0355,  0.1358,  0.2309],\n",
      "        [-0.1308, -0.5092, -0.3478,  ...,  0.0858, -0.1538,  0.1742],\n",
      "        [-0.4579, -0.3359, -0.0897,  ..., -0.3245,  0.0893,  0.9237]],\n",
      "       dtype=torch.float64) tensor([1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1,\n",
      "        0, 1, 1, 1, 0, 0, 0, 0])\n",
      "tensor([[-0.1992, -0.4721,  0.1887,  ...,  0.3977,  0.0297,  0.4858],\n",
      "        [-0.1309, -0.2603, -0.2482,  ..., -0.0942, -0.2204,  0.4028],\n",
      "        [-0.2036, -0.2415, -0.6535,  ..., -0.0980,  0.1555,  0.4675],\n",
      "        ...,\n",
      "        [-0.3075, -0.1323, -0.2233,  ..., -0.0474, -0.0086,  0.5182],\n",
      "        [-0.1626, -0.2149, -0.1847,  ...,  0.3321, -0.2027,  0.7652],\n",
      "        [-0.1104, -0.2342, -0.0808,  ..., -0.0859,  0.1640,  0.5258]],\n",
      "       dtype=torch.float64) tensor([0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
      "        1, 0, 0, 1, 1, 0, 1, 1])\n",
      "tensor([[-0.4852, -0.4237, -0.3598,  ..., -0.2687, -0.3061,  0.6627],\n",
      "        [-0.3766,  0.0316,  0.0044,  ..., -0.0631,  0.1387,  0.4277],\n",
      "        [-0.1128, -0.4283, -0.1979,  ...,  0.2046,  0.2148,  0.6772],\n",
      "        ...,\n",
      "        [-0.2433, -0.1034, -0.1696,  ..., -0.1421,  0.2529,  0.2133],\n",
      "        [-0.1640, -0.0943, -0.2322,  ..., -0.0465,  0.0203,  0.4170],\n",
      "        [-0.3606, -0.0870, -0.1246,  ..., -0.2522,  0.2817,  0.1528]],\n",
      "       dtype=torch.float64) tensor([0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 1, 1, 1, 1, 1])\n",
      "tensor([[-0.2508, -0.4267, -0.5357,  ..., -0.6010,  0.3721,  0.0322],\n",
      "        [-0.1080, -0.0704,  0.0228,  ...,  0.7456,  0.0709,  0.3616],\n",
      "        [-0.4479, -0.6783, -0.9012,  ..., -0.0966,  0.4042,  0.0678],\n",
      "        ...,\n",
      "        [-0.0378,  0.0347, -0.0178,  ...,  0.0404, -0.3202,  1.2625],\n",
      "        [-0.1047,  0.1785, -0.1828,  ...,  0.1052, -0.3749,  0.6096],\n",
      "        [-0.0832, -0.0981, -0.2942,  ...,  0.0252,  0.1778,  0.3963]],\n",
      "       dtype=torch.float64) tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n",
      "        0, 1, 1, 0, 1, 1, 1, 1])\n",
      "tensor([[-0.3775,  0.0111, -0.5049,  ...,  0.0966, -0.1481,  0.6922],\n",
      "        [-0.0153, -0.3126, -0.8399,  ...,  0.0145, -0.1578,  0.3082],\n",
      "        [-0.3293,  0.0504,  0.0554,  ..., -0.1119,  0.2303,  0.3405],\n",
      "        ...,\n",
      "        [-0.5527, -0.1858,  0.3861,  ..., -0.2126, -0.1058,  0.6249],\n",
      "        [-0.5430, -0.1591, -0.3605,  ..., -0.3567,  0.0821,  0.6063],\n",
      "        [-0.4364, -0.0605, -0.0480,  ...,  0.0550, -0.3173,  0.9199]],\n",
      "       dtype=torch.float64) tensor([0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
      "        1, 0, 0, 1, 1, 0, 0, 0])\n",
      "tensor([[-0.1317,  0.1631, -0.6256,  ..., -0.4219,  0.0606,  0.7780],\n",
      "        [-0.1956,  0.0712, -0.5828,  ..., -0.0498, -0.1996,  0.5980],\n",
      "        [ 0.0648, -0.1491, -0.2482,  ..., -0.1136,  0.1006,  0.3250],\n",
      "        ...,\n",
      "        [-0.1635,  0.1429, -0.1578,  ..., -0.1344, -0.0631,  0.4102],\n",
      "        [-0.6264, -0.4169, -0.2032,  ..., -0.1497,  0.3641,  0.5037],\n",
      "        [ 0.0624, -0.3868,  0.0935,  ..., -0.4832, -0.1552,  0.3266]],\n",
      "       dtype=torch.float64) tensor([0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
      "        1, 1, 0, 0, 0, 0, 0, 1])\n",
      "tensor([[-1.7172e-03, -1.0762e-01, -3.4993e-01,  ...,  1.4035e-02,\n",
      "          2.3387e-01,  1.1433e-01],\n",
      "        [-5.7020e-01, -1.5983e-01, -9.0426e-02,  ..., -1.7933e-01,\n",
      "         -1.2268e-01,  6.1592e-01],\n",
      "        [-2.0054e-01, -6.3938e-02, -2.1197e-04,  ..., -1.8469e-01,\n",
      "         -2.8353e-02,  2.0094e-01],\n",
      "        ...,\n",
      "        [-9.5450e-01,  1.6288e-03, -2.2078e-01,  ...,  1.4890e-01,\n",
      "          5.5566e-02,  1.0733e+00],\n",
      "        [-2.0524e-01, -2.9608e-01, -3.6359e-01,  ..., -1.8252e-01,\n",
      "          6.6277e-01, -7.1620e-02],\n",
      "        [-5.3124e-01, -1.5345e-01, -2.7971e-01,  ..., -6.6020e-02,\n",
      "          4.1976e-02,  5.2133e-01]], dtype=torch.float64) tensor([1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1,\n",
      "        0, 1, 1, 1, 0, 1, 0, 0])\n",
      "tensor([[-0.1933, -0.2832, -0.1305,  ..., -0.2703,  0.1955,  0.3915],\n",
      "        [-0.3390, -0.0674,  0.2454,  ...,  0.4103,  0.0673,  0.5784],\n",
      "        [-0.4556, -0.2981, -0.2218,  ..., -0.3264,  0.2067,  0.2816],\n",
      "        ...,\n",
      "        [-0.4801,  0.0583,  0.0135,  ..., -0.2830,  0.0358,  0.5595],\n",
      "        [-0.2883, -0.2399, -0.2337,  ..., -0.1975,  0.0811,  0.5695],\n",
      "        [ 0.0034, -0.1811, -0.0875,  ...,  0.1190,  0.2564,  0.2723]],\n",
      "       dtype=torch.float64) tensor([1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1,\n",
      "        0, 1, 1, 1, 1, 1, 0, 0])\n",
      "tensor([[-0.0052,  0.1394, -0.3903,  ...,  0.2407, -0.0407,  0.6779],\n",
      "        [ 0.1729, -0.2124,  0.0384,  ...,  0.1061,  0.0878,  0.8358],\n",
      "        [ 0.0040, -0.2259, -0.0362,  ..., -0.2472, -0.1490,  0.2917],\n",
      "        ...,\n",
      "        [-0.9479, -0.1786, -0.7479,  ..., -0.1181, -0.0145,  0.8103],\n",
      "        [-0.0665, -0.3241,  0.1973,  ..., -0.4244,  0.2528,  0.7034],\n",
      "        [ 0.1063, -0.2251, -0.1881,  ...,  0.4256, -0.2343,  0.6222]],\n",
      "       dtype=torch.float64) tensor([0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
      "        0, 0, 1, 1, 0, 1, 0, 0])\n",
      "tensor([[-0.4735,  0.0865, -0.3996,  ..., -0.0650,  0.0447,  0.5008],\n",
      "        [-0.2323,  0.0365, -0.1225,  ...,  0.0852,  0.0695,  0.2214],\n",
      "        [-0.1051, -0.3583, -0.2703,  ...,  0.1869,  0.0349,  0.5967],\n",
      "        ...,\n",
      "        [-0.0869, -0.0140,  0.1661,  ..., -0.2859,  0.0438,  0.0048],\n",
      "        [-0.1406, -0.1097,  0.1045,  ..., -0.1084, -0.2762,  0.6351],\n",
      "        [-0.4336, -0.3200, -0.1050,  ..., -0.0660,  0.1953,  0.7537]],\n",
      "       dtype=torch.float64) tensor([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "        1, 1, 0, 0, 0, 1, 0, 0])\n",
      "tensor([[-0.1604, -0.1261, -0.2457,  ..., -0.2932, -0.0411,  0.3050],\n",
      "        [-0.4688, -0.2991, -0.0094,  ..., -0.4383, -0.0101,  0.4324],\n",
      "        [-0.0989, -0.1985,  0.1777,  ...,  0.2462,  0.0932,  0.1239],\n",
      "        ...,\n",
      "        [-0.1936, -0.0458,  0.2955,  ...,  0.0902, -0.2808,  0.6051],\n",
      "        [ 0.0996,  0.1152,  0.0405,  ..., -0.2411,  0.0783,  0.3126],\n",
      "        [-0.3702, -0.2199, -0.6718,  ..., -0.1471,  0.2719,  0.3884]],\n",
      "       dtype=torch.float64) tensor([0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
      "        0, 1, 0, 1, 0, 1, 1, 0])\n",
      "tensor([[-0.3850, -0.4682,  0.2535,  ..., -0.0760,  0.1846,  0.2591],\n",
      "        [-0.0643, -0.1008, -0.1545,  ..., -0.2813, -0.0909,  0.2869],\n",
      "        [-0.3874,  0.0433, -0.2553,  ..., -0.3947,  0.1920, -0.2351],\n",
      "        ...,\n",
      "        [-0.3011, -0.1146, -0.2996,  ..., -0.2521,  0.0141,  0.0316],\n",
      "        [-0.3650, -0.1828, -0.2569,  ..., -0.3479,  0.2811,  0.1871],\n",
      "        [-0.1329, -0.0503, -0.1033,  ..., -0.1725, -0.3134,  0.5189]],\n",
      "       dtype=torch.float64) tensor([1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
      "        0, 1, 0, 1, 1, 0, 1, 1])\n",
      "tensor([[-0.3615, -0.4070, -0.6869,  ..., -0.3295, -0.0241,  0.4263],\n",
      "        [-0.1737,  0.0291, -0.2861,  ..., -0.3209, -0.1266,  0.2521],\n",
      "        [-0.5512, -0.1033, -0.0695,  ..., -0.3351, -0.0405,  0.7348],\n",
      "        ...,\n",
      "        [-0.2675, -0.4859, -0.0411,  ..., -0.0272, -0.0434,  0.7674],\n",
      "        [-0.7695, -0.5163, -0.1088,  ..., -0.4199, -0.0587,  0.4472],\n",
      "        [ 0.0181, -0.1643,  0.3309,  ...,  0.3933,  0.0131,  0.5277]],\n",
      "       dtype=torch.float64) tensor([1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
      "        0, 1, 1, 1, 0, 0, 1, 0])\n",
      "tensor([[-0.4354,  0.1090,  0.1946,  ..., -0.0497, -0.2041,  0.7608],\n",
      "        [ 0.0717, -0.0365,  0.0188,  ..., -0.2161,  0.1090,  0.2024],\n",
      "        [-0.2091, -0.2878, -0.1051,  ...,  0.0458, -0.0523,  0.5290],\n",
      "        ...,\n",
      "        [-0.3070, -0.6225, -0.6945,  ..., -0.3191,  0.3427,  0.1608],\n",
      "        [ 0.1185,  0.5993, -0.0337,  ..., -0.1572, -0.1994,  0.6431],\n",
      "        [-0.3572, -0.0598, -0.6395,  ..., -0.3231,  0.3497,  0.1873]],\n",
      "       dtype=torch.float64) tensor([0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 1, 1, 0, 1, 1, 0])\n",
      "tensor([[-0.6158, -0.3647, -0.3767,  ..., -0.5640,  0.0834,  0.2526],\n",
      "        [-0.0252, -0.1767,  0.2798,  ...,  0.2367, -0.3210,  0.7312],\n",
      "        [-0.1923, -0.9419,  0.0346,  ...,  0.1122,  0.6335,  0.5834],\n",
      "        ...,\n",
      "        [ 0.0900, -0.2979, -0.2224,  ...,  0.5980,  0.0204,  0.3771],\n",
      "        [ 0.0096, -0.3582, -0.2976,  ..., -0.2824,  0.3604,  0.5794],\n",
      "        [ 0.3463, -0.3601, -0.0365,  ...,  0.4264, -0.2381,  1.0057]],\n",
      "       dtype=torch.float64) tensor([1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n",
      "        1, 1, 1, 0, 1, 1, 0, 1])\n",
      "tensor([[-0.1014, -0.1673, -0.1960,  ..., -0.2474, -0.0421,  0.0728],\n",
      "        [ 0.0845, -0.3591, -0.1536,  ..., -0.1894,  0.0414,  0.1772],\n",
      "        [-0.4521, -0.2005, -0.4036,  ..., -0.0838,  0.0014,  0.1141],\n",
      "        ...,\n",
      "        [-0.1842, -0.0949,  0.0183,  ...,  0.0110,  0.0228,  0.8531],\n",
      "        [-0.3887, -0.3810, -0.1404,  ...,  0.0755,  0.1596,  0.6169],\n",
      "        [-0.3654, -0.2207,  0.0539,  ..., -0.1658, -0.2398,  0.0704]],\n",
      "       dtype=torch.float64) tensor([1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0,\n",
      "        1, 0, 1, 1, 0, 1, 1, 0])\n",
      "tensor([[-0.6146, -0.3410, -0.8191,  ..., -0.4437, -0.1850,  0.1329],\n",
      "        [ 0.0541,  0.1043,  0.0620,  ..., -0.0315,  0.0949,  0.9428],\n",
      "        [-0.0812, -0.4025, -0.0219,  ...,  0.3247, -0.4129,  0.5217],\n",
      "        ...,\n",
      "        [-0.0633, -0.0237, -0.0245,  ..., -0.0050, -0.0962,  0.3572],\n",
      "        [-0.4044, -0.1815, -0.2414,  ...,  0.4297,  0.0397,  0.6297],\n",
      "        [-0.5035, -0.2203, -0.0549,  ..., -0.1425,  0.0811,  0.2382]],\n",
      "       dtype=torch.float64) tensor([1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0])\n",
      "tensor([[-3.1490e-01, -1.6579e-01, -1.6402e-01,  ..., -3.2896e-01,\n",
      "          6.4268e-04,  2.8075e-01],\n",
      "        [-2.0151e-01, -2.7487e-01,  2.0632e-01,  ..., -1.2017e-01,\n",
      "         -1.4699e-01,  7.6651e-01],\n",
      "        [ 1.7899e-02, -7.6084e-01, -8.0091e-01,  ..., -2.2212e-01,\n",
      "          2.5961e-01,  3.8343e-01],\n",
      "        ...,\n",
      "        [-2.4095e-01, -7.6981e-02,  7.7606e-01,  ..., -1.0838e-01,\n",
      "         -1.0671e-01,  5.2152e-01],\n",
      "        [-3.0906e-02, -5.5539e-01, -1.3946e-01,  ...,  8.9468e-02,\n",
      "          1.7006e-01,  5.6960e-01],\n",
      "        [-1.5804e-01, -9.8013e-02, -2.5473e-01,  ...,  5.8147e-02,\n",
      "          4.9685e-02,  5.6065e-01]], dtype=torch.float64) tensor([0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0,\n",
      "        1, 0, 0, 1, 0, 1, 0, 1])\n",
      "tensor([[-0.1124, -0.6162, -0.2621,  ..., -0.0647, -0.0582,  0.0433],\n",
      "        [-0.3998, -0.6353,  0.1712,  ..., -0.1096, -0.1206,  0.4168],\n",
      "        [-0.4399, -0.5014, -0.1805,  ..., -0.2928, -0.0373,  0.2859],\n",
      "        ...,\n",
      "        [-0.2030, -0.5999, -0.2935,  ..., -0.0961,  0.3396,  0.2604],\n",
      "        [-0.1469, -0.2352, -0.0522,  ..., -0.3680,  0.0861,  0.5263],\n",
      "        [-0.1515, -0.4885, -0.0282,  ...,  0.0158,  0.1853,  0.8324]],\n",
      "       dtype=torch.float64) tensor([1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1,\n",
      "        0, 0, 1, 0, 0, 0, 0, 1])\n",
      "tensor([[-0.4804,  0.0510, -0.7865,  ..., -0.0885,  0.2372,  0.1703],\n",
      "        [-0.3679, -0.3126, -0.1972,  ..., -0.7341,  0.0071,  0.3186],\n",
      "        [-0.2204, -0.1016, -0.2346,  ..., -0.0266,  0.1260,  0.1071],\n",
      "        ...,\n",
      "        [-0.1503, -0.3963, -0.7441,  ...,  0.1200, -0.1063,  0.5036],\n",
      "        [-0.7910, -0.3656,  0.0925,  ..., -0.0370,  0.1464,  0.6381],\n",
      "        [-0.4257,  0.1596, -0.1380,  ...,  0.1147,  0.1529,  0.4810]],\n",
      "       dtype=torch.float64) tensor([1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1,\n",
      "        1, 1, 0, 1, 1, 1, 1, 0])\n",
      "tensor([[-0.0331, -0.4579,  0.1138,  ...,  0.3272,  0.3121,  0.2786],\n",
      "        [-0.0778, -0.3875, -0.0768,  ..., -0.6303,  0.2630,  0.2488],\n",
      "        [-0.5955, -0.4033, -0.2095,  ..., -0.3596,  0.0522,  0.2685],\n",
      "        ...,\n",
      "        [-0.2060,  0.0209,  0.0651,  ..., -0.4083,  0.2643, -0.0050],\n",
      "        [-0.3810, -0.2880, -0.1457,  ..., -0.4021, -0.1221, -0.0794],\n",
      "        [-0.4262, -0.3163, -0.1185,  ..., -0.1041,  0.3343,  0.4125]],\n",
      "       dtype=torch.float64) tensor([0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
      "        1, 0, 0, 1, 0, 0, 1, 1])\n",
      "tensor([[-0.6539, -0.0504, -0.6002,  ..., -0.2609,  0.2901,  0.4002],\n",
      "        [-0.4194, -0.2552, -0.0606,  ..., -0.1651,  0.0923,  0.6049],\n",
      "        [-0.7986, -0.4145, -0.3967,  ..., -0.2091, -0.1028,  0.7032],\n",
      "        ...,\n",
      "        [-0.2224, -0.3044,  0.5227,  ...,  0.0348, -0.6837,  0.4910],\n",
      "        [ 0.0719,  0.0961, -0.4359,  ...,  0.0553, -0.1595,  0.6278],\n",
      "        [ 0.0510,  0.0993,  0.1331,  ...,  0.1665,  0.0091,  0.4320]],\n",
      "       dtype=torch.float64) tensor([0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1,\n",
      "        0, 1, 1, 1, 1, 1, 0, 0])\n",
      "tensor([[ 0.3703,  0.0125, -0.0272,  ...,  0.6181,  0.1982,  0.6999],\n",
      "        [-0.2542, -0.5673, -0.6421,  ..., -0.1170,  0.2566,  0.2727],\n",
      "        [-0.2403, -0.0817, -0.0692,  ..., -0.2444,  0.4130,  0.0669],\n",
      "        ...,\n",
      "        [-0.5241, -0.5823, -0.4411,  ..., -0.4466,  0.0708,  0.4609],\n",
      "        [ 0.0074, -0.5182,  0.8444,  ...,  0.2802, -0.1626,  0.5911],\n",
      "        [-0.5401, -0.5097, -0.0219,  ..., -0.0308,  0.2703,  0.7497]],\n",
      "       dtype=torch.float64) tensor([1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
      "        0, 0, 0, 1, 1, 1, 0, 0])\n",
      "tensor([[ 0.0154,  0.0934,  0.0197,  ..., -0.2600,  0.1421,  0.1341],\n",
      "        [-0.4115,  0.1867, -0.6660,  ..., -0.2391,  0.2860,  0.7592],\n",
      "        [ 0.1234, -0.2312, -0.2447,  ...,  0.2374, -0.0136,  0.7395],\n",
      "        ...,\n",
      "        [-0.4691, -0.2713, -0.1313,  ..., -0.1273, -0.1605,  1.0756],\n",
      "        [-0.3002,  0.1406,  0.1464,  ...,  0.1318, -0.3889,  0.4883],\n",
      "        [ 0.0214, -0.2801,  0.1182,  ...,  0.2813, -0.4339,  0.5981]],\n",
      "       dtype=torch.float64) tensor([1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0,\n",
      "        1, 1, 1, 0, 1, 1, 1, 1])\n",
      "tensor([[ 0.1790,  0.3554, -0.1737,  ...,  0.3647, -0.3847,  0.6383],\n",
      "        [ 0.0612, -0.0415, -0.4614,  ..., -0.1247,  0.2766,  0.1647],\n",
      "        [ 0.6264,  0.0325,  0.4606,  ...,  0.4041, -0.8114,  0.5931],\n",
      "        ...,\n",
      "        [-0.2222,  0.0074, -0.4254,  ...,  0.1636, -0.0762,  0.4352],\n",
      "        [-0.2179, -0.1557, -0.0231,  ...,  0.2840,  0.3979,  0.5877],\n",
      "        [-0.3781, -0.4231, -0.3909,  ..., -0.1175,  0.0287,  0.5256]],\n",
      "       dtype=torch.float64) tensor([1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
      "        1, 1, 0, 0, 0, 1, 0, 0])\n",
      "tensor([[-0.3095, -0.1505, -0.0363,  ..., -0.1347,  0.0564,  0.2657],\n",
      "        [-0.2109, -0.1538, -0.1847,  ..., -0.0815,  0.4250,  0.4856],\n",
      "        [-0.3504, -0.1801, -0.0773,  ...,  0.0657,  0.2823,  0.1863],\n",
      "        ...,\n",
      "        [-0.1384,  0.1509,  0.0429,  ...,  0.1386,  0.0347,  0.8260],\n",
      "        [-0.4455, -0.2354,  0.3590,  ..., -0.2159,  0.3207,  0.6645],\n",
      "        [-0.4061, -0.0229, -0.6250,  ..., -0.1593,  0.2409,  0.1129]],\n",
      "       dtype=torch.float64) tensor([1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1,\n",
      "        1, 0, 1, 0, 1, 0, 1, 1])\n",
      "tensor([[-0.2503, -0.3553, -0.4048,  ...,  0.4678, -0.4549,  0.4954],\n",
      "        [-0.2917,  0.3376,  0.1027,  ..., -0.2757, -0.0816,  0.9890],\n",
      "        [ 0.0614, -0.5078,  0.3226,  ...,  0.4098, -0.2121,  0.4774],\n",
      "        ...,\n",
      "        [-0.2690, -0.1087, -0.1713,  ..., -0.3546,  0.0579,  0.5463],\n",
      "        [-0.5758,  0.2587, -0.6208,  ..., -0.1779,  0.5594,  0.3351],\n",
      "        [-0.1249, -0.0607,  0.0403,  ...,  0.1632,  0.1608,  0.1811]],\n",
      "       dtype=torch.float64) tensor([0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 1, 0, 0, 0, 1, 1])\n",
      "tensor([[-0.3505, -0.2201, -0.0383,  ...,  0.0773,  0.1621,  0.5318],\n",
      "        [ 0.0793,  0.2993, -0.1959,  ..., -0.0957, -0.0801,  0.3510],\n",
      "        [-0.3559,  0.1318, -0.0099,  ..., -0.2972, -0.2549,  0.3456],\n",
      "        ...,\n",
      "        [-0.1766, -0.1368, -0.3406,  ...,  0.0424, -0.2615,  0.8296],\n",
      "        [ 0.1955, -0.0817,  0.1018,  ...,  0.7755, -0.0664,  0.9798],\n",
      "        [-0.1755, -0.0309,  0.1110,  ..., -0.1252, -0.1182,  0.3453]],\n",
      "       dtype=torch.float64) tensor([1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
      "        1, 1, 0, 0, 0, 0, 1, 0])\n",
      "tensor([[-0.4954, -0.2704,  0.1708,  ..., -0.2691,  0.1852,  0.0577],\n",
      "        [-0.5159, -0.3975, -0.4030,  ...,  0.0182,  0.5335,  0.6494],\n",
      "        [-0.1233, -0.1440,  0.1402,  ..., -0.4322,  0.4759,  0.4872],\n",
      "        ...,\n",
      "        [-0.0539, -0.3340, -0.3727,  ..., -0.0664, -0.0104,  0.7820],\n",
      "        [-0.4554, -0.4873, -0.2059,  ..., -0.2105,  0.5871,  0.0969],\n",
      "        [-0.3390, -0.0229, -0.1286,  ...,  0.0250,  0.4006,  0.2725]],\n",
      "       dtype=torch.float64) tensor([1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
      "        1, 1, 0, 0, 0, 1, 0, 0])\n",
      "tensor([[-0.4222, -0.4053, -0.0078,  ..., -0.1336,  0.2343,  0.4102],\n",
      "        [ 0.1366,  0.0429,  0.2895,  ...,  0.2000, -0.2003,  0.5596],\n",
      "        [-0.3559, -0.3054,  0.2338,  ...,  0.2489, -0.3040,  0.8319],\n",
      "        ...,\n",
      "        [-0.4986, -0.0817, -0.1686,  ..., -0.4192,  0.0221,  0.3466],\n",
      "        [ 0.0435, -0.2213, -0.7307,  ..., -0.5114, -0.1385,  0.3635],\n",
      "        [-0.7899, -0.3052, -0.3667,  ..., -0.2863, -0.0371,  0.6936]],\n",
      "       dtype=torch.float64) tensor([1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1,\n",
      "        0, 0, 1, 1, 1, 1, 0, 1])\n",
      "tensor([[-0.1556,  0.0938, -0.3322,  ...,  0.0883, -0.1857,  0.4607],\n",
      "        [-0.1350,  0.0793, -0.1311,  ..., -0.1854,  0.2471,  0.1275],\n",
      "        [ 0.0548, -0.0022,  0.0746,  ..., -0.0522, -0.1037,  0.6016],\n",
      "        ...,\n",
      "        [-0.4773, -0.4657, -0.2977,  ..., -0.2446, -0.1128,  0.4333],\n",
      "        [-0.3958, -0.3621, -0.4149,  ..., -0.5043,  0.1295,  0.3599],\n",
      "        [-0.2641, -0.2292, -0.2286,  ..., -0.2030, -0.2166,  0.7518]],\n",
      "       dtype=torch.float64) tensor([0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0,\n",
      "        1, 0, 0, 1, 0, 1, 1, 1])\n",
      "tensor([[-0.7718, -0.0884, -0.1332,  ...,  0.0408,  0.1201,  0.3483],\n",
      "        [-0.2005,  0.0338, -0.1642,  ..., -0.0088, -0.0932,  0.3675],\n",
      "        [-0.5411, -0.1949, -0.0252,  ...,  0.3610, -0.2986,  0.8137],\n",
      "        ...,\n",
      "        [-0.1859, -0.0226,  0.0867,  ..., -0.1461,  0.0697,  0.4816],\n",
      "        [-0.1205, -0.3005, -0.3237,  ...,  0.1670,  0.0319,  0.3982],\n",
      "        [-0.2956, -0.1465, -0.0722,  ...,  0.0590, -0.2557,  0.5036]],\n",
      "       dtype=torch.float64) tensor([1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 1])\n",
      "tensor([[-0.0688, -0.4124, -0.1129,  ..., -0.2713,  0.0961,  0.2527],\n",
      "        [-0.4970, -0.4986, -0.0738,  ..., -0.2705,  0.6092,  0.3385],\n",
      "        [-0.1105, -0.0329,  0.1319,  ..., -0.6199,  0.3831,  0.1271],\n",
      "        ...,\n",
      "        [-0.4249,  0.0290,  0.2039,  ..., -0.0109, -0.1677,  0.9892],\n",
      "        [-0.3309, -0.2759, -0.7043,  ..., -0.1269,  0.0281,  0.5385],\n",
      "        [-0.3238, -0.1485, -0.4485,  ..., -0.1617,  0.3095,  0.1485]],\n",
      "       dtype=torch.float64) tensor([1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1,\n",
      "        1, 0, 0, 1, 1, 1, 1, 1])\n",
      "tensor([[-0.2993, -0.0417, -0.1601,  ...,  0.1508,  0.1615,  0.2414],\n",
      "        [-0.1848, -0.4053, -0.6713,  ..., -0.0551,  0.3424,  0.4188],\n",
      "        [-0.3102,  0.2605, -0.2611,  ...,  0.4830,  0.2683,  0.0937],\n",
      "        ...,\n",
      "        [-0.5551, -0.8224, -0.6883,  ..., -0.4670,  0.3601,  0.5612],\n",
      "        [-0.3726, -0.1228, -0.2594,  ..., -0.2547,  0.0145,  0.3357],\n",
      "        [-0.1533, -0.0666, -0.3578,  ...,  0.3682, -0.1029,  0.7006]],\n",
      "       dtype=torch.float64) tensor([0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0,\n",
      "        1, 1, 1, 0, 0, 0, 1, 1])\n",
      "tensor([[-0.3416, -0.1810, -0.3338,  ..., -0.6630,  0.3803,  0.2218],\n",
      "        [-0.1212,  0.1558, -0.2377,  ..., -0.1978, -0.3018,  0.6127],\n",
      "        [-0.1232, -0.3180, -0.1069,  ..., -0.4928, -0.0958,  0.2248],\n",
      "        ...,\n",
      "        [-0.1053, -0.0181,  0.0752,  ..., -0.2265, -0.0400,  0.3135],\n",
      "        [-0.2312,  0.0502,  0.1142,  ...,  0.1394, -0.2157,  0.8674],\n",
      "        [-0.1493,  0.2909,  0.2079,  ...,  0.1866, -0.2777,  0.6360]],\n",
      "       dtype=torch.float64) tensor([1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1,\n",
      "        0, 1, 0, 0, 0, 1, 1, 1])\n",
      "tensor([[-4.0503e-01, -7.0355e-01, -1.0909e-01,  ...,  3.1157e-01,\n",
      "          1.1438e-01,  4.2613e-01],\n",
      "        [-7.2857e-01, -4.8204e-01,  4.7477e-02,  ..., -2.5389e-01,\n",
      "         -3.6847e-03,  7.0343e-01],\n",
      "        [-2.9891e-01, -4.3911e-02, -3.7479e-01,  ..., -9.8144e-02,\n",
      "          1.6765e-01,  2.4793e-01],\n",
      "        ...,\n",
      "        [-2.3200e-01, -6.4776e-02,  1.1604e-01,  ...,  3.7548e-01,\n",
      "         -7.9364e-02,  7.7145e-01],\n",
      "        [-2.1003e-01, -5.2800e-01, -2.7478e-01,  ..., -4.3516e-01,\n",
      "         -1.1475e-01,  3.7538e-01],\n",
      "        [-1.4140e-02, -1.5408e-01, -6.5255e-04,  ..., -3.4447e-02,\n",
      "         -1.6640e-01,  3.2023e-01]], dtype=torch.float64) tensor([1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
      "        1, 0, 0, 0, 1, 0, 1, 0])\n",
      "tensor([[-0.4920, -0.2300, -0.1125,  ...,  0.1252, -0.2000, -0.0239],\n",
      "        [-0.2751, -0.4832, -0.0808,  ..., -0.1577,  0.3303,  0.0928],\n",
      "        [-0.1306, -0.3950, -0.3908,  ..., -0.2753,  0.3243,  0.2079],\n",
      "        ...,\n",
      "        [-0.1654, -0.4406, -0.2885,  ..., -0.5012,  0.1677,  0.0222],\n",
      "        [-0.3494, -0.3068, -0.4350,  ...,  0.0296,  0.1770,  0.2948],\n",
      "        [-0.2805,  0.1293, -0.5256,  ..., -0.0861,  0.3638,  0.4981]],\n",
      "       dtype=torch.float64) tensor([1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1,\n",
      "        1, 0, 1, 1, 1, 0, 1, 1])\n",
      "tensor([[-0.1939, -0.1910, -0.0444,  ...,  0.5230,  0.0402,  0.6939],\n",
      "        [ 0.2746, -0.1690,  0.5713,  ...,  0.1286,  0.6878,  0.2906],\n",
      "        [ 0.0984, -0.1236,  0.0217,  ...,  0.1759, -0.0761,  0.6120],\n",
      "        ...,\n",
      "        [ 0.0021,  0.0068, -0.0984,  ..., -0.1702, -0.1720,  0.5583],\n",
      "        [-0.1825, -0.1554,  0.2128,  ..., -0.0588,  0.2570,  0.4530],\n",
      "        [ 0.2617,  0.0403, -0.0008,  ..., -0.2943,  0.2615,  0.1186]],\n",
      "       dtype=torch.float64) tensor([1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1,\n",
      "        0, 1, 0, 1, 1, 1, 0, 1])\n",
      "tensor([[-0.5639, -0.0724, -0.1055,  ..., -0.2227,  0.0648,  0.2572],\n",
      "        [-0.4860,  0.2006, -0.5517,  ..., -0.6530, -0.0138,  0.3599],\n",
      "        [-0.2736,  0.0618, -0.1813,  ..., -0.2175, -0.2189,  0.7881],\n",
      "        ...,\n",
      "        [-0.2093, -0.3818, -0.1030,  ..., -0.0461,  0.0551,  0.8045],\n",
      "        [-0.1538, -0.1557, -0.2916,  ..., -0.0678,  0.1356, -0.0697],\n",
      "        [-0.1622, -0.5023, -0.3807,  ...,  0.1526,  0.1927,  0.5469]],\n",
      "       dtype=torch.float64) tensor([0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1,\n",
      "        1, 1, 0, 0, 1, 1, 0, 0])\n",
      "tensor([[-0.2273,  0.0927, -0.1107,  ...,  0.2020, -0.0699,  0.7114],\n",
      "        [-0.5180, -0.3294,  0.0913,  ..., -0.0303, -0.0287,  0.2180],\n",
      "        [-0.3649, -0.2655, -0.1934,  ..., -0.3114, -0.1897,  0.3923],\n",
      "        ...,\n",
      "        [-0.2153, -0.5622, -0.6275,  ..., -0.4424,  0.4157,  0.0446],\n",
      "        [-0.0206,  0.1141, -0.3137,  ..., -0.0608,  0.2932,  0.2563],\n",
      "        [-0.5612, -0.2897, -0.4817,  ..., -0.1781, -0.4786,  0.6020]],\n",
      "       dtype=torch.float64) tensor([0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
      "        0, 1, 0, 0, 1, 1, 0, 1])\n",
      "tensor([[-0.4207, -0.0921, -0.4978,  ..., -0.6638,  0.1149,  0.3442],\n",
      "        [-0.2609,  0.0130, -0.2112,  ...,  0.1194,  0.1002,  0.0696]],\n",
      "       dtype=torch.float64) tensor([1, 0])\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(zip(train_loader_train, train_loader_labels)):\n",
    "    x, y = data\n",
    "    print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(92), 180)\n",
      "訓練周期: 0 [0/1802 (0%)]\tTotal Loss: 0.74\ttraining Loss: 0.74\tval Loss: 0.69\t訓練正確率: 53.12%\t校驗正確率: 51.11%\n",
      "(tensor(86), 180)\n",
      "訓練周期: 0 [320/1802 (22%)]\tTotal Loss: 0.72\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 48.58%\t校驗正確率: 47.78%\n",
      "(tensor(87), 180)\n",
      "訓練周期: 0 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 48.51%\t校驗正確率: 48.33%\n",
      "(tensor(88), 180)\n",
      "訓練周期: 0 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 48.59%\t校驗正確率: 48.89%\n",
      "(tensor(86), 180)\n",
      "訓練周期: 0 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 49.16%\t校驗正確率: 47.78%\n",
      "(tensor(82), 180)\n",
      "訓練周期: 1 [0/1802 (0%)]\tTotal Loss: 0.72\ttraining Loss: 0.78\tval Loss: 0.70\t訓練正確率: 40.62%\t校驗正確率: 45.56%\n",
      "(tensor(85), 180)\n",
      "訓練周期: 1 [320/1802 (22%)]\tTotal Loss: 0.72\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 49.43%\t校驗正確率: 47.22%\n",
      "(tensor(90), 180)\n",
      "訓練周期: 1 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 51.79%\t校驗正確率: 50.00%\n",
      "(tensor(92), 180)\n",
      "訓練周期: 1 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 50.71%\t校驗正確率: 51.11%\n",
      "(tensor(89), 180)\n",
      "訓練周期: 1 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 49.77%\t校驗正確率: 49.44%\n",
      "(tensor(92), 180)\n",
      "訓練周期: 2 [0/1802 (0%)]\tTotal Loss: 0.72\ttraining Loss: 0.77\tval Loss: 0.69\t訓練正確率: 46.88%\t校驗正確率: 51.11%\n",
      "(tensor(94), 180)\n",
      "訓練周期: 2 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 46.31%\t校驗正確率: 52.22%\n",
      "(tensor(96), 180)\n",
      "訓練周期: 2 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 46.73%\t校驗正確率: 53.33%\n",
      "(tensor(91), 180)\n",
      "訓練周期: 2 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 47.38%\t校驗正確率: 50.56%\n",
      "(tensor(91), 180)\n",
      "訓練周期: 2 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 48.02%\t校驗正確率: 50.56%\n",
      "(tensor(93), 180)\n",
      "訓練周期: 3 [0/1802 (0%)]\tTotal Loss: 0.72\ttraining Loss: 0.77\tval Loss: 0.69\t訓練正確率: 56.25%\t校驗正確率: 51.67%\n",
      "(tensor(91), 180)\n",
      "訓練周期: 3 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 53.41%\t校驗正確率: 50.56%\n",
      "(tensor(94), 180)\n",
      "訓練周期: 3 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 52.83%\t校驗正確率: 52.22%\n",
      "(tensor(92), 180)\n",
      "訓練周期: 3 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 51.81%\t校驗正確率: 51.11%\n",
      "(tensor(87), 180)\n",
      "訓練周期: 3 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 50.69%\t校驗正確率: 48.33%\n",
      "(tensor(71), 180)\n",
      "訓練周期: 4 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.72\tval Loss: 0.70\t訓練正確率: 53.12%\t校驗正確率: 39.44%\n",
      "(tensor(83), 180)\n",
      "訓練周期: 4 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 49.43%\t校驗正確率: 46.11%\n",
      "(tensor(89), 180)\n",
      "訓練周期: 4 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.69\t訓練正確率: 48.51%\t校驗正確率: 49.44%\n",
      "(tensor(95), 180)\n",
      "訓練周期: 4 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.69\t訓練正確率: 49.09%\t校驗正確率: 52.78%\n",
      "(tensor(81), 180)\n",
      "訓練周期: 4 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.69\t訓練正確率: 48.63%\t校驗正確率: 45.00%\n",
      "(tensor(86), 180)\n",
      "訓練周期: 5 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.71\tval Loss: 0.70\t訓練正確率: 62.50%\t校驗正確率: 47.78%\n",
      "(tensor(95), 180)\n",
      "訓練周期: 5 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 49.15%\t校驗正確率: 52.78%\n",
      "(tensor(100), 180)\n",
      "訓練周期: 5 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.69\t訓練正確率: 49.11%\t校驗正確率: 55.56%\n",
      "(tensor(99), 180)\n",
      "訓練周期: 5 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.69\t訓練正確率: 48.99%\t校驗正確率: 55.00%\n",
      "(tensor(86), 180)\n",
      "訓練周期: 5 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.69\t訓練正確率: 49.16%\t校驗正確率: 47.78%\n",
      "(tensor(91), 180)\n",
      "訓練周期: 6 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.72\tval Loss: 0.70\t訓練正確率: 53.12%\t校驗正確率: 50.56%\n",
      "(tensor(87), 180)\n",
      "訓練周期: 6 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 46.31%\t校驗正確率: 48.33%\n",
      "(tensor(101), 180)\n",
      "訓練周期: 6 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 44.94%\t校驗正確率: 56.11%\n",
      "(tensor(88), 180)\n",
      "訓練周期: 6 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 46.17%\t校驗正確率: 48.89%\n",
      "(tensor(84), 180)\n",
      "訓練周期: 6 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 46.80%\t校驗正確率: 46.67%\n",
      "(tensor(92), 180)\n",
      "訓練周期: 7 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.79\tval Loss: 0.70\t訓練正確率: 46.88%\t校驗正確率: 51.11%\n",
      "(tensor(90), 180)\n",
      "訓練周期: 7 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.71\tval Loss: 0.69\t訓練正確率: 46.88%\t校驗正確率: 50.00%\n",
      "(tensor(90), 180)\n",
      "訓練周期: 7 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 49.11%\t校驗正確率: 50.00%\n",
      "(tensor(93), 180)\n",
      "訓練周期: 7 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 50.10%\t校驗正確率: 51.67%\n",
      "(tensor(83), 180)\n",
      "訓練周期: 7 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 50.23%\t校驗正確率: 46.11%\n",
      "(tensor(84), 180)\n",
      "訓練周期: 8 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.82\tval Loss: 0.70\t訓練正確率: 43.75%\t校驗正確率: 46.67%\n",
      "(tensor(83), 180)\n",
      "訓練周期: 8 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 50.57%\t校驗正確率: 46.11%\n",
      "(tensor(82), 180)\n",
      "訓練周期: 8 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 48.81%\t校驗正確率: 45.56%\n",
      "(tensor(87), 180)\n",
      "訓練周期: 8 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 49.50%\t校驗正確率: 48.33%\n",
      "(tensor(90), 180)\n",
      "訓練周期: 8 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 49.01%\t校驗正確率: 50.00%\n",
      "(tensor(90), 180)\n",
      "訓練周期: 9 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.73\tval Loss: 0.69\t訓練正確率: 56.25%\t校驗正確率: 50.00%\n",
      "(tensor(91), 180)\n",
      "訓練周期: 9 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 51.99%\t校驗正確率: 50.56%\n",
      "(tensor(83), 180)\n",
      "訓練周期: 9 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 47.62%\t校驗正確率: 46.11%\n",
      "(tensor(99), 180)\n",
      "訓練周期: 9 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 49.09%\t校驗正確率: 55.00%\n",
      "(tensor(83), 180)\n",
      "訓練周期: 9 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 49.85%\t校驗正確率: 46.11%\n",
      "(tensor(91), 180)\n",
      "訓練周期: 10 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.78\tval Loss: 0.69\t訓練正確率: 40.62%\t校驗正確率: 50.56%\n",
      "(tensor(88), 180)\n",
      "訓練周期: 10 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 50.00%\t校驗正確率: 48.89%\n",
      "(tensor(92), 180)\n",
      "訓練周期: 10 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 51.79%\t校驗正確率: 51.11%\n",
      "(tensor(92), 180)\n",
      "訓練周期: 10 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 51.41%\t校驗正確率: 51.11%\n",
      "(tensor(95), 180)\n",
      "訓練周期: 10 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 50.61%\t校驗正確率: 52.78%\n",
      "(tensor(84), 180)\n",
      "訓練周期: 11 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.76\tval Loss: 0.70\t訓練正確率: 56.25%\t校驗正確率: 46.67%\n",
      "(tensor(95), 180)\n",
      "訓練周期: 11 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 46.31%\t校驗正確率: 52.78%\n",
      "(tensor(90), 180)\n",
      "訓練周期: 11 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 47.62%\t校驗正確率: 50.00%\n",
      "(tensor(90), 180)\n",
      "訓練周期: 11 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 46.98%\t校驗正確率: 50.00%\n",
      "(tensor(88), 180)\n",
      "訓練周期: 11 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 48.32%\t校驗正確率: 48.89%\n",
      "(tensor(93), 180)\n",
      "訓練周期: 12 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.65\tval Loss: 0.69\t訓練正確率: 59.38%\t校驗正確率: 51.67%\n",
      "(tensor(93), 180)\n",
      "訓練周期: 12 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.70\t訓練正確率: 49.43%\t校驗正確率: 51.67%\n",
      "(tensor(91), 180)\n",
      "訓練周期: 12 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.69\t訓練正確率: 49.26%\t校驗正確率: 50.56%\n",
      "(tensor(95), 180)\n",
      "訓練周期: 12 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 48.29%\t校驗正確率: 52.78%\n",
      "(tensor(97), 180)\n",
      "訓練周期: 12 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.69\t訓練正確率: 48.63%\t校驗正確率: 53.89%\n",
      "(tensor(88), 180)\n",
      "訓練周期: 13 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 65.62%\t校驗正確率: 48.89%\n",
      "(tensor(85), 180)\n",
      "訓練周期: 13 [320/1802 (22%)]\tTotal Loss: 0.71\ttraining Loss: 0.70\tval Loss: 0.70\t訓練正確率: 51.70%\t校驗正確率: 47.22%\n",
      "(tensor(84), 180)\n",
      "訓練周期: 13 [640/1802 (43%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.69\t訓練正確率: 52.38%\t校驗正確率: 46.67%\n",
      "(tensor(92), 180)\n",
      "訓練周期: 13 [960/1802 (65%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.69\t訓練正確率: 53.43%\t校驗正確率: 51.11%\n",
      "(tensor(80), 180)\n",
      "訓練周期: 13 [1280/1802 (87%)]\tTotal Loss: 0.71\ttraining Loss: 0.69\tval Loss: 0.70\t訓練正確率: 52.97%\t校驗正確率: 44.44%\n",
      "(tensor(93), 180)\n",
      "訓練周期: 14 [0/1802 (0%)]\tTotal Loss: 0.71\ttraining Loss: 0.78\tval Loss: 0.69\t訓練正確率: 34.38%\t校驗正確率: 51.67%\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "record = []\n",
    "losses = []\n",
    "records = []\n",
    "for epoch in range(num_epochs):\n",
    "    train_losses = []\n",
    "    train_rights = []\n",
    "    model.train()\n",
    "    for batch_idx, train in enumerate(zip(train_loader_train, train_loader_labels)):\n",
    "        x, y = train\n",
    "        \n",
    "        \n",
    "        x = torch.tensor(x, requires_grad = True, dtype = torch.float)   # x 最後會被轉成 [0-1] 之間的數\n",
    "\n",
    "        y = torch.tensor(np.array([z for z in y ]), dtype = torch.long)  # 所以 y 必須是llong 而不是\n",
    "        \n",
    "        #np.array([z for z in y ]) 因為np.array只能轉一個值，若要list裡面全部的值，需改成這樣\n",
    "        \n",
    "        # 清空梯度\n",
    "        optimizer.zero_grad()\n",
    "        # 模型預測\n",
    "        predict = model(x)\n",
    "        # 計算損失函數\n",
    "        loss = criterion(predict, y)\n",
    "        # 將損失函數數值加入到列表中\n",
    "        train_losses.append(loss.data.numpy())\n",
    "        # 開始進行梯度反傳\n",
    "        loss.backward()\n",
    "        # 開始對參數進行一步優化\n",
    "        optimizer.step()\n",
    "        #計算準確率所需數值，返回數值為（正確樣例數，總樣本數）\n",
    "        right = rightness(predict, y)\n",
    "        #將計算結果裝到列表容器train_rights中\n",
    "        train_rights.append(right)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # 每隔200步，跑一下校驗數據集的數據，輸出臨時結果\n",
    "        if batch_idx % 10 == 0:\n",
    "        \n",
    "            losses.append(np.mean(train_losses))\n",
    "            model.eval()\n",
    "            val_losses = []\n",
    "            val_rights = []\n",
    "            # 在所有校驗數據集上實驗\n",
    "            with torch.no_grad():\n",
    "                \n",
    "                for j, val in enumerate(zip(validation_loader_test, validation_loader_labels)):\n",
    "                    x, y = val\n",
    "                    x = torch.tensor(x, requires_grad = True, dtype = torch.float)\n",
    "                    y = torch.tensor(np.array([z for z in y ]), dtype = torch.long)\n",
    "                    predict = model(x)\n",
    "                    # 調用rightness函數計算準確度\n",
    "                    right = rightness(predict, y)\n",
    "                    val_rights.append(right)\n",
    "                    loss = criterion(predict, y)\n",
    "                    val_losses.append(loss.data.numpy())\n",
    "\n",
    "\n",
    "\n",
    "                # 分別計算在目前已經計算過的測試數據集，以及全部校驗集上模型的表現：分類準確率\n",
    "                #train_r為一個二元組，分別記錄目前已經經歷過的所有訓練集中分類正確的數量和該集合中總的樣本數，\n",
    "                #train_r[0]/train_r[1]就是訓練集的分類準確度，同樣，val_r[0]/val_r[1]就是校驗集上的分類準確度\n",
    "                train_r = (sum([tup[0] for tup in train_rights]), sum([tup[1] for tup in train_rights]))\n",
    "                #val_r為一個二元組，分別記錄校驗集中分類正確的數量和該集合中總的樣本數\n",
    "                val_r = (sum([tup[0] for tup in val_rights]), sum([tup[1] for tup in val_rights]))\n",
    "                #打印準確率等數值，其中正確率為本訓練周期Epoch開始後到目前撮的正確率的平均值\n",
    "                print(val_r)\n",
    "                print('訓練周期: {} [{}/{} ({:.0f}%)]\\tTotal Loss: {:.2f}\\ttraining Loss: {:.2f}\\tval Loss: {:.2f}\\t訓練正確率: {:.2f}%\\t校驗正確率: {:.2f}%'.format(\n",
    "                    epoch, batch_idx * batch_size, len(dataset),\n",
    "                    100. * batch_idx / len(train_loader_train), \n",
    "                    np.mean(losses),\n",
    "                    np.mean(train_losses),\n",
    "                    np.mean(val_losses),\n",
    "                    100. * train_r[0].numpy() / train_r[1], \n",
    "                    100. * val_r[0].numpy() / val_r[1]))\n",
    "                #將準確率和權重等數值加載到容器中，以方便後續處理\n",
    "                record.append((100 - 100. * train_r[0] / train_r[1], 100 - 100. * val_r[0] / val_r[1]))\n",
    "                records.append([np.mean(train_losses), np.mean(val_losses), train_r, val_r, losses])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### label 2名稱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#繪制訓練過程的誤差曲線，校驗集和測試集上的錯誤率。\n",
    "plt.figure(figsize = (10, 7))\n",
    "plt.plot(record, label = 'train_acc') #record記載了每一個打印周期記錄的訓練和校驗數據集上的準確度\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Error rate')\n",
    "plt.legend()\n",
    "plt.ylim(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records.append([np.mean(train_losses), np.mean(val_losses), train_r, val_r, losses])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 繪制誤差曲線\n",
    "a = [i[0] for i in records]\n",
    "b = [i[1] for i in records]\n",
    "c = [i[2] for i in records]\n",
    "d = [i[3] for i in records]\n",
    "e = [i[4] for i in records]\n",
    "plt.plot(a, label = 'Train Loss')\n",
    "plt.plot(b, label = 'Valid Loss')\n",
    "plt.plot(c, label = 'Train Accuracy')\n",
    "plt.plot(d, label = 'Valid Accuracy')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss & Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,'bow.mdl')\n",
    "model = torch.load('bow.mdl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#在測試集上分批運行，並計算總的正確率\n",
    "vals = [] #記錄準確率所用列表\n",
    "\n",
    "#對測試數據集進行循環\n",
    "for data, target in zip(test_data, test_label):\n",
    "    data, target = torch.tensor(data, dtype = torch.float).view(1,-1), torch.tensor(np.array([target]), dtype = torch.long)\n",
    "    output = model(data) #將特征數據喂入網絡，得到分類的輸出\n",
    "    val = rightness(output, target) #獲得正確樣本數以及總樣本數\n",
    "    vals.append(val) #記錄結果\n",
    "\n",
    "#計算準確率\n",
    "rights = (sum([tup[0] for tup in vals]), sum([tup[1] for tup in vals]))\n",
    "right_rate = 1.0 * rights[0].data.numpy() / rights[1]\n",
    "right_rate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
